{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "# PheKnowLator - Data Preparation\n",
    "***\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=callahantiff@gmail.com)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Release:** **[v2.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)**\n",
    "\n",
    "**Purpose:** This notebook serves as a script to download and process data in order to generate mapping and filtering data needed to build edges for the PheKnowLator knowledge graph. For more information on the data sources utilize within this script, please see the [Data Sources](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources) Wiki page.\n",
    "\n",
    "**Assumptions:**   \n",
    "- Raw data downloads ➞ `./resources/processed_data/unprocessed_data`    \n",
    "- Processed data write location ➞ `./resources/processed_data`   \n",
    "\n",
    "**Dependencies:** This notebook utilizes several helper functions, which are stored in the [`data_preparation_helper_functions.py`](https://github.com/callahantiff/PheKnowLator/blob/master/scripts/python/data_preparation_helper_functions.py) script. Hyperlinks to all downloaded and generated data sources are provided on the [Data Sources](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources) Wiki page as well as within each source subsection of this notebook. All generated data is freely available for download from DropBox. \n",
    "\n",
    "_____\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "***\n",
    "\n",
    "### [Create Identifier Maps ](#create-identifier-maps)  \n",
    "- [HUMAN TRANSCRIPT, GENE, AND PROTEIN IDENTIFIER MAPPING](#human-transcript,-gene,-and-protein-identifier-mapping)\n",
    "  - [Ensembl Gene-Ensembl Transcript](#ensemblgene-ensembltranscript)  \n",
    "  - [Ensembl Gene-Entrez Gene](#ensemblgene-entrezgene)\n",
    "  - [Ensembl Transcript-Protein Ontology](#ensembltranscript-proteinontology)\n",
    "  - [Gene Symbol-Ensembl Transcript](#genesymbol-ensembltranscript)\n",
    "  - [Entrez Gene-Protein Ontology](#entrezgene-proteinontology)  \n",
    "  - [STRING-Protein Ontology](#string-proteinontology)  \n",
    "  - [Uniprot Accession-Protein Ontology](#uniprotaccession-proteinontology)\n",
    "\n",
    "\n",
    "- [OTHER IDENTIFIER MAPPING](#other-identifier-mapping) \n",
    "  - [ChEBI Identifiers](#mesh-chebi) \n",
    "  - [Human Disease and Phenotype Identifiers](#disease-identifiers)\n",
    "  - [Human Protein Atlas Tissue and Cell Types](#hpa-uberon)  \n",
    "\n",
    "<br>\n",
    "\n",
    "### [Create Edge Datasets](#create-edge-datasets)\n",
    "- [ONTOLOGIES](#ontologies)  \n",
    "  - [Protein Ontology](#protein-ontology)  \n",
    "  - [Relations Ontology](#relations-ontology)  \n",
    "\n",
    "\n",
    "- [LINKED DATA](#linked-data)  \n",
    "  - [Clinvar Variant-Diseases and Phenotypes](#clinvar-variant)\n",
    "  - [NCBI Gene Protein-Coding Genes and Proteins](#ncbi-protein-coding-genes)  \n",
    "  - [Reactome Chemical-Complex Data](#reactome-chemical-complex)\n",
    "  - [Reactome Complex-Complex Data](#reactome-complex-complex)\n",
    "  - [Reactome Complex-Pathway Data](#reactome-complex-pathway)\n",
    "  - [Reactome Protein-Complex Data](#reactome-protein-complex)\n",
    "  - [Uniprot Protein-Cofactor and Protein-Catalyst](#uniprot-protein-cofactorcatalyst)  \n",
    "\n",
    "<br>\n",
    "\n",
    "### [Gather Instance Data Metadata](#create-instance-metadata)  \n",
    "- [Genes/RNA](#gene-and-rna-metadata)\n",
    "- [Pathways](#pathway-metadata)\n",
    "- [Complexes](#complex-metadata)\n",
    "- [Reactions](#reaction-metadata)\n",
    "- [Variants](#variant-metadata) \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-Up Environment\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import glob\n",
    "import networkx\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from functools import reduce\n",
    "from owlready2 import subprocess\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, extras, Literal\n",
    "from rdflib.extras.external_graph_libs import *\n",
    "from reactome2py import content\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import script containing helper functions\n",
    "from scripts.python.data_preparation_helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Global Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to read unprocessed data files from\n",
    "unprocessed_data_location = 'resources/processed_data/unprocessed_data/'\n",
    "\n",
    "# directory to write processed data files to\n",
    "processed_data_location = 'resources/processed_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### CREATE MAPPING DATASETS  <a class=\"anchor\" id=\"create-identifier-maps\"></a>\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Transcript, Gene, and Protein Identifier Mapping  <a class=\"anchor\" id=\"human-transcript,-gene,-and-protein-identifier-mapping\"></a>\n",
    "***\n",
    "\n",
    "**Data Source Wiki Pages:**   \n",
    "- [Ensembl](https://uswest.ensembl.org/)  \n",
    "\n",
    "- [Uniprot Knowledgebase](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#uniprot-knowledgebase)  \n",
    "- [HGNC](ftp://ftp.ebi.ac.uk/pub/databases/genenames/new/tsv/hgnc_complete_set.txt) \n",
    "- [NCBI Gene](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#ncbi-gene) \n",
    "- [Protein Ontology](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#protein-ontology)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Purpose:** To map create protein-coding gene-protein relations and mappings between the identifiers listed below. The edges types produced from each of these mappings will be further described within each identifier mapping section:  \n",
    "- [Ensembl Gene-Ensembl Transcript](#ensemblgene-ensembltranscript)  \n",
    "- [Entrez Gene-Ensembl Transcript](#entrezgene-ensembltranscript)  \n",
    "- [Entrez Gene-Protein Ontology](#entrezgene-proteinontology)  \n",
    "- [Ensembl Gene-Entrez Gene](#ensemblgene-entrezgene)\n",
    "- [Uniprot Accession-Protein Ontology](#uniprotaccession-proteinontology)\n",
    "- [STRING-Protein Ontology](#string-proteinontology)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Output:** This script downloads and saves the following data:  \n",
    "- Human Ensembl Gene Set ➞ [`Homo_sapiens.GRCh38.99.gtf`](ftp://ftp.ensembl.org/pub/release-99/gtf/homo_sapiens/Homo_sapiens.GRCh38.99.gtf.gz)\n",
    "- Human Ensembl-UniProt Identifiers ➞ [`Homo_sapiens.GRCh38.98.uniprot.tsv`](https://www.dropbox.com/s/cesjvqz1b8c7ami/Homo_sapiens.GRCh38.98.uniprot.tsv?dl=1) \n",
    "- Human Ensembl-Entrez Identifiers ➞ [`Homo_sapiens.GRCh38.98.entrez.tsv`](https://www.dropbox.com/s/5kstw70py0azvws/Homo_sapiens.GRCh38.98.entrez.tsv?dl=1) \n",
    "- Human Gene Identifiers ➞ [`Homo_sapiens.gene_info`](https://www.dropbox.com/s/vazlmzxydgv6xzz/Homo_sapiens.gene_info?dl=1), [`hgnc_complete_set.txt`](ftp://ftp.ebi.ac.uk/pub/databases/genenames/new/tsv/hgnc_complete_set.txt)  \n",
    "- Human Protein Identifiers ➞ [`promapping.txt`](https://www.dropbox.com/s/x7wdimv6ph6bl8k/promapping.txt?dl=1) \n",
    "\n",
    "_All Merged Data Sets:_ [`Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt`](https://www.dropbox.com/s/fiek6h5rowi7dh0/Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt?dl=1)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Process Data:** `hgnc_complete_set.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from ftp server\n"
     ]
    }
   ],
   "source": [
    "url = 'ftp://ftp.ebi.ac.uk/pub/databases/genenames/new/tsv/hgnc_complete_set.txt'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>entrez_id</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>locus_group</th>\n",
       "      <th>location</th>\n",
       "      <th>alias_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HGNC:5</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>P04217</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>protein-coding gene</td>\n",
       "      <td>19q13.43</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HGNC:37133</td>\n",
       "      <td>503538</td>\n",
       "      <td>ENSG00000268895</td>\n",
       "      <td>None</td>\n",
       "      <td>A1BG-AS1</td>\n",
       "      <td>A1BG antisense RNA 1</td>\n",
       "      <td>non-coding RNA</td>\n",
       "      <td>19q13.43</td>\n",
       "      <td>FLJ23569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HGNC:24086</td>\n",
       "      <td>29974</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>Q9NQ94</td>\n",
       "      <td>A1CF</td>\n",
       "      <td>APOBEC1 complementation factor</td>\n",
       "      <td>protein-coding gene</td>\n",
       "      <td>10q11.23</td>\n",
       "      <td>ACF|ASP|ACF64|ACF65|APOBEC1CF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hgnc_id entrez_id  ensembl_gene_id uniprot_ids    symbol  \\\n",
       "0      HGNC:5         1  ENSG00000121410      P04217      A1BG   \n",
       "1  HGNC:37133    503538  ENSG00000268895        None  A1BG-AS1   \n",
       "2  HGNC:24086     29974  ENSG00000148584      Q9NQ94      A1CF   \n",
       "\n",
       "                             name          locus_group  location  \\\n",
       "0          alpha-1-B glycoprotein  protein-coding gene  19q13.43   \n",
       "1            A1BG antisense RNA 1       non-coding RNA  19q13.43   \n",
       "2  APOBEC1 complementation factor  protein-coding gene  10q11.23   \n",
       "\n",
       "                    alias_symbol  \n",
       "0                           None  \n",
       "1                       FLJ23569  \n",
       "2  ACF|ASP|ACF64|ACF65|APOBEC1CF  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in ensembl-uniprot data\n",
    "hgnc = pandas.read_csv(unprocessed_data_location + 'hgnc_complete_set.txt',\n",
    "                       header = 0,\n",
    "                       delimiter = '\\t',\n",
    "                       low_memory=False)\n",
    "\n",
    "# drop uneeded columns\n",
    "hgnc = hgnc[['hgnc_id', 'entrez_id', 'ensembl_gene_id', 'uniprot_ids', 'symbol', 'name', 'locus_group', 'location', 'alias_symbol']]\n",
    "\n",
    "# replace NaN with 'None'\n",
    "hgnc.fillna('None', inplace=True)\n",
    "\n",
    "# make data columns of type string\n",
    "hgnc['entrez_id'] = hgnc['entrez_id'].apply(lambda x: str(int(x)) if x != 'None' else 'None')\n",
    "\n",
    "# explode nested data\n",
    "explode_df_hgnc = explode(hgnc.copy(), ['entrez_id', 'ensembl_gene_id', 'uniprot_ids'], '|')\n",
    "\n",
    "# preview data\n",
    "explode_df_hgnc.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Process Data:** `Homo_sapiens.GRCh38.99.gtf.gz` + `Homo_sapiens.GRCh38.98.uniprot.tsv` + `Homo_sapiens.GRCh38.98.entrez.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gzipped data from ftp server\n",
      "Decompressing and writing gzipped data\n"
     ]
    }
   ],
   "source": [
    "# full human gene set\n",
    "url = 'ftp://ftp.ensembl.org/pub/release-99/gtf/homo_sapiens/Homo_sapiens.GRCh38.99.gtf.gz'\n",
    "data_downloader(url, unprocessed_data_location)\n",
    "\n",
    "# uniprot annotations\n",
    "url1 = 'ftp://ftp.ensembl.org/pub/release-99/tsv/homo_sapiens/Homo_sapiens.GRCh38.99.uniprot.tsv.gz'\n",
    "data_downloader(url1, unprocessed_data_location)\n",
    "\n",
    "# entrez annotations\n",
    "url2 = 'ftp://ftp.ensembl.org/pub/release-99/tsv/homo_sapiens/Homo_sapiens.GRCh38.99.entrez.tsv.gz'\n",
    "data_downloader(url2, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Read in Gene Set Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2905054/2905054 [09:10<00:00, 5281.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_source</th>\n",
       "      <th>molecule_type</th>\n",
       "      <th>gene_stable_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>exon_number</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>exon_stable_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>transcript_support_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>havana</td>\n",
       "      <td>transcript</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>None</td>\n",
       "      <td>basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>1</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENSE00002234944</td>\n",
       "      <td>basic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ensembl_source molecule_type   gene_stable_id transcript_stable_id  \\\n",
       "0         havana          gene  ENSG00000223972                 None   \n",
       "1         havana    transcript  ENSG00000223972      ENST00000456328   \n",
       "2         havana          exon  ENSG00000223972      ENST00000456328   \n",
       "\n",
       "  exon_number gene_name                           gene_type transcript_name  \\\n",
       "0        None   DDX11L1  transcribed_unprocessed_pseudogene            None   \n",
       "1        None   DDX11L1  transcribed_unprocessed_pseudogene     DDX11L1-202   \n",
       "2           1   DDX11L1  transcribed_unprocessed_pseudogene     DDX11L1-202   \n",
       "\n",
       "        transcript_type   exon_stable_id    tag transcript_support_level  \n",
       "0                  None             None   None                     None  \n",
       "1  processed_transcript             None  basic                        1  \n",
       "2  processed_transcript  ENSE00002234944  basic                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembl_geneset = pandas.read_csv(unprocessed_data_location + 'Homo_sapiens.GRCh38.99.gtf',\n",
    "                                  header = None,\n",
    "                                  delimiter = '\\t',\n",
    "                                  skiprows = 5,\n",
    "                                  low_memory=False)\n",
    "\n",
    "# iterate over the nested column and un ravel it\n",
    "column_names = ['gene_id', 'gene_version', 'transcript_id', 'transcript_version', 'exon_number', 'gene_name',\n",
    "                'gene_source', 'gene_biotype', 'transcript_name', 'transcript_source', 'transcript_biotype',\n",
    "                'exon_id', 'exon_version', 'tag', 'transcript_support_level']\n",
    "\n",
    "cleaned_column = []\n",
    "\n",
    "for idx, row in tqdm(ensembl_geneset.iterrows(), total=ensembl_geneset.shape[0]):\n",
    "    row_results, col_res = [], row[8].split(';')\n",
    "\n",
    "    for col in column_names:\n",
    "        match = [x.replace(col, '').strip().strip('\"') for x in col_res if col in x]\n",
    "        row_results.append(match[0].replace(col, '') if len(match) > 0 else 'None')\n",
    "\n",
    "    cleaned_column += [row_results]\n",
    "          \n",
    "# remove nested column\n",
    "ensembl_geneset = ensembl_geneset[[1, 2]]\n",
    "\n",
    "# add columns back to data frame\n",
    "ensembl_geneset['gene_stable_id'] = [x[0] for x in cleaned_column]\n",
    "ensembl_geneset['transcript_stable_id'] = [x[2] for x in cleaned_column]\n",
    "ensembl_geneset['exon_number'] = [x[4] for x in cleaned_column]\n",
    "ensembl_geneset['gene_name'] = [x[5] for x in cleaned_column]\n",
    "ensembl_geneset['gene_type'] = [x[7] for x in cleaned_column]\n",
    "ensembl_geneset['transcript_name'] = [x[8] for x in cleaned_column]\n",
    "ensembl_geneset['transcript_type'] = [x[10] for x in cleaned_column]\n",
    "ensembl_geneset['exon_stable_id'] = [x[11] for x in cleaned_column]\n",
    "ensembl_geneset['tag'] = [x[13] for x in cleaned_column]\n",
    "ensembl_geneset['transcript_support_level'] = [x[14] for x in cleaned_column]\n",
    "\n",
    "# rename columns\n",
    "ensembl_geneset.rename(columns={1: 'ensembl_source', 2: 'molecule_type'}, inplace=True)\n",
    "\n",
    "# replace NaN with 'None'\n",
    "ensembl_geneset.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "ensembl_geneset.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Read in Annotation Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_stable_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>protein_stable_id</th>\n",
       "      <th>xref_uniprot</th>\n",
       "      <th>xref_entrez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000186092</td>\n",
       "      <td>ENST00000641515</td>\n",
       "      <td>ENSP00000493376</td>\n",
       "      <td>A0A2U3U0J3</td>\n",
       "      <td>79501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000186092</td>\n",
       "      <td>ENST00000335137</td>\n",
       "      <td>ENSP00000334393</td>\n",
       "      <td>Q8NH21</td>\n",
       "      <td>79501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000284733</td>\n",
       "      <td>ENST00000426406</td>\n",
       "      <td>ENSP00000409316</td>\n",
       "      <td>Q6IEY1</td>\n",
       "      <td>729759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gene_stable_id transcript_stable_id protein_stable_id xref_uniprot  \\\n",
       "0  ENSG00000186092      ENST00000641515   ENSP00000493376   A0A2U3U0J3   \n",
       "1  ENSG00000186092      ENST00000335137   ENSP00000334393       Q8NH21   \n",
       "2  ENSG00000284733      ENST00000426406   ENSP00000409316       Q6IEY1   \n",
       "\n",
       "  xref_entrez  \n",
       "0       79501  \n",
       "1       79501  \n",
       "2      729759  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in ensembl-uniprot data\n",
    "ensembl1 = pandas.read_csv(unprocessed_data_location + 'Homo_sapiens.GRCh38.99.uniprot.tsv',\n",
    "                           header = 0,\n",
    "                           delimiter = '\\t',\n",
    "                           low_memory=False)\n",
    "# replace \"-\"\n",
    "ensembl1.replace('-','None', inplace=True)\n",
    "\n",
    "# read in entrez-uniprot data\n",
    "ensembl2 = pandas.read_csv(unprocessed_data_location + 'Homo_sapiens.GRCh38.99.entrez.tsv',\n",
    "                           header = 0,\n",
    "                           delimiter = '\\t',\n",
    "                           low_memory=False)\n",
    "\n",
    "# replace \"-\"\n",
    "ensembl2.replace('-','None', inplace=True)\n",
    "\n",
    "# merge annotation datasets\n",
    "ensembl_annot = pandas.merge(ensembl1[['gene_stable_id', 'transcript_stable_id', 'protein_stable_id', 'xref']],\n",
    "                             ensembl2[['gene_stable_id', 'transcript_stable_id', 'protein_stable_id', 'xref']],\n",
    "                             left_on=['gene_stable_id', 'transcript_stable_id', 'protein_stable_id'],\n",
    "                             right_on=['gene_stable_id', 'transcript_stable_id', 'protein_stable_id'],\n",
    "                             how='outer')\n",
    "\n",
    "# rename columns\n",
    "ensembl_annot.rename(columns={'xref_x': 'xref_uniprot', 'xref_y': 'xref_entrez'}, inplace=True)\n",
    "\n",
    "# replace NaN with 'None'\n",
    "ensembl_annot.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "ensembl_annot.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Merge Ensembl Annotation and Gene Set Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_source</th>\n",
       "      <th>molecule_type</th>\n",
       "      <th>gene_stable_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>exon_number</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>exon_stable_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>transcript_support_level</th>\n",
       "      <th>protein_stable_id</th>\n",
       "      <th>xref_uniprot</th>\n",
       "      <th>xref_entrez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>havana</td>\n",
       "      <td>transcript</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>None</td>\n",
       "      <td>basic</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>1</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENSE00002234944</td>\n",
       "      <td>basic</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ensembl_source molecule_type   gene_stable_id transcript_stable_id  \\\n",
       "0         havana          gene  ENSG00000223972                 None   \n",
       "1         havana    transcript  ENSG00000223972      ENST00000456328   \n",
       "2         havana          exon  ENSG00000223972      ENST00000456328   \n",
       "\n",
       "  exon_number gene_name                           gene_type transcript_name  \\\n",
       "0        None   DDX11L1  transcribed_unprocessed_pseudogene            None   \n",
       "1        None   DDX11L1  transcribed_unprocessed_pseudogene     DDX11L1-202   \n",
       "2           1   DDX11L1  transcribed_unprocessed_pseudogene     DDX11L1-202   \n",
       "\n",
       "        transcript_type   exon_stable_id    tag transcript_support_level  \\\n",
       "0                  None             None   None                     None   \n",
       "1  processed_transcript             None  basic                        1   \n",
       "2  processed_transcript  ENSE00002234944  basic                        1   \n",
       "\n",
       "  protein_stable_id xref_uniprot xref_entrez  \n",
       "0              None         None        None  \n",
       "1              None         None        None  \n",
       "2              None         None        None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge annotation data with enseble gene set\n",
    "ensembl = pandas.merge(ensembl_geneset,\n",
    "                       ensembl_annot,\n",
    "                       left_on = ['gene_stable_id', 'transcript_stable_id'],\n",
    "                       right_on = ['gene_stable_id', 'transcript_stable_id'],\n",
    "                       how='outer')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "ensembl.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "ensembl.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "**Process Data:** `Homo_sapiens.gene_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gzipped data from ftp server\n",
      "Decompressing and writing gzipped data\n"
     ]
    }
   ],
   "source": [
    "url = 'ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>dbXrefs</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>map_location</th>\n",
       "      <th>description</th>\n",
       "      <th>type_of_gene</th>\n",
       "      <th>Other_designations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>A1B|ABG|GAB|HYST2477</td>\n",
       "      <td>138670</td>\n",
       "      <td>19</td>\n",
       "      <td>19q13.43</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>A1B|ABG|GAB|HYST2477</td>\n",
       "      <td>HGNC:5</td>\n",
       "      <td>19</td>\n",
       "      <td>19q13.43</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>A1B|ABG|GAB|HYST2477</td>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>19</td>\n",
       "      <td>19q13.43</td>\n",
       "      <td>alpha-1-B glycoprotein</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GeneID Symbol              Synonyms          dbXrefs chromosome  \\\n",
       "0       1   A1BG  A1B|ABG|GAB|HYST2477           138670         19   \n",
       "1       1   A1BG  A1B|ABG|GAB|HYST2477           HGNC:5         19   \n",
       "2       1   A1BG  A1B|ABG|GAB|HYST2477  ENSG00000121410         19   \n",
       "\n",
       "  map_location             description    type_of_gene  \\\n",
       "0     19q13.43  alpha-1-B glycoprotein  protein-coding   \n",
       "1     19q13.43  alpha-1-B glycoprotein  protein-coding   \n",
       "2     19q13.43  alpha-1-B glycoprotein  protein-coding   \n",
       "\n",
       "                                  Other_designations  \n",
       "0  alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...  \n",
       "1  alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...  \n",
       "2  alpha-1B-glycoprotein|HEL-S-163pA|epididymis s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncbi_gene = pandas.read_csv(unprocessed_data_location + 'Homo_sapiens.gene_info', header = 0, delimiter = '\\t')\n",
    "\n",
    "# replace \"-\" with \"None\"\n",
    "ncbi_gene.replace('-','None', inplace=True)\n",
    "\n",
    "# explode nested data\n",
    "explode_df_ncbi_gene = explode(ncbi_gene.copy(), ['dbXrefs'], '|')\n",
    "\n",
    "# remove identifier type, which appears before ':'\n",
    "explode_df_ncbi_gene['dbXrefs'].replace('(^\\w*\\:)','', inplace=True, regex=True)\n",
    "\n",
    "# remove unneeded columns\n",
    "explode_df_ncbi_gene = explode_df_ncbi_gene[['GeneID', 'Symbol', 'Synonyms', 'dbXrefs', 'chromosome', 'map_location',\n",
    "                                             'description', 'type_of_gene', 'Other_designations']]\n",
    "\n",
    "# preview data\n",
    "explode_df_ncbi_gene.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Process Data:** `promapping.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://proconsortium.org/download/current/promapping.txt'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_id</th>\n",
       "      <th>Entry</th>\n",
       "      <th>pro_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PR:000000005</td>\n",
       "      <td>P37173</td>\n",
       "      <td>is_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PR:000000005</td>\n",
       "      <td>P38438</td>\n",
       "      <td>is_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PR:000000005</td>\n",
       "      <td>Q62312</td>\n",
       "      <td>is_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pro_id   Entry pro_mapping\n",
       "6  PR:000000005  P37173        is_a\n",
       "7  PR:000000005  P38438        is_a\n",
       "8  PR:000000005  Q62312        is_a"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_mapping = pandas.read_csv(unprocessed_data_location + 'promapping.txt',\n",
    "                              header = None,\n",
    "                              names = ['pro_id', 'Entry', 'pro_mapping'],\n",
    "                              delimiter = '\\t')\n",
    "\n",
    "# remove rows without 'UniProtKB'\n",
    "pro_mapping = pro_mapping.loc[pro_mapping['Entry'].apply(lambda x: x.startswith('UniProtKB:'))] \n",
    "\n",
    "# remove identifier type, which appears before ':'\n",
    "pro_mapping['Entry'].replace('(^\\w*\\:)','', inplace=True, regex=True)\n",
    "\n",
    "# preview data\n",
    "pro_mapping.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Merge Processed Data:** `hgnc` + `ensembl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_source</th>\n",
       "      <th>molecule_type</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>exon_number</th>\n",
       "      <th>symbol</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>exon_stable_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>transcript_support_level</th>\n",
       "      <th>protein_stable_id</th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>entrez_id</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>name</th>\n",
       "      <th>locus_group</th>\n",
       "      <th>location</th>\n",
       "      <th>alias_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>havana</td>\n",
       "      <td>transcript</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>None</td>\n",
       "      <td>basic</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>1</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENSE00002234944</td>\n",
       "      <td>basic</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ensembl_source molecule_type  ensembl_gene_id transcript_stable_id  \\\n",
       "0         havana          gene  ENSG00000223972                 None   \n",
       "1         havana    transcript  ENSG00000223972      ENST00000456328   \n",
       "2         havana          exon  ENSG00000223972      ENST00000456328   \n",
       "\n",
       "  exon_number   symbol                           gene_type transcript_name  \\\n",
       "0        None  DDX11L1  transcribed_unprocessed_pseudogene            None   \n",
       "1        None  DDX11L1  transcribed_unprocessed_pseudogene     DDX11L1-202   \n",
       "2           1  DDX11L1  transcribed_unprocessed_pseudogene     DDX11L1-202   \n",
       "\n",
       "        transcript_type   exon_stable_id    tag transcript_support_level  \\\n",
       "0                  None             None   None                     None   \n",
       "1  processed_transcript             None  basic                        1   \n",
       "2  processed_transcript  ENSE00002234944  basic                        1   \n",
       "\n",
       "  protein_stable_id uniprot_ids entrez_id hgnc_id  name locus_group location  \\\n",
       "0              None        None      None    None  None        None     None   \n",
       "1              None        None      None    None  None        None     None   \n",
       "2              None        None      None    None  None        None     None   \n",
       "\n",
       "  alias_symbol  \n",
       "0         None  \n",
       "1         None  \n",
       "2         None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns before merging\n",
    "ensembl.rename(columns={'gene_stable_id': 'ensembl_gene_id', 'xref_uniprot': 'uniprot_ids', 'xref_entrez': 'entrez_id', 'gene_name': 'symbol'}, inplace=True)\n",
    "\n",
    "# merge uniprot and ncbi data\n",
    "ensembl_hgnc_merged_data = pandas.merge(ensembl,\n",
    "                                        hgnc,\n",
    "                                        left_on=['ensembl_gene_id', 'entrez_id', 'uniprot_ids', 'symbol'],\n",
    "                                        right_on=['ensembl_gene_id', 'entrez_id', 'uniprot_ids', 'symbol'],\n",
    "                                        how='outer')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "ensembl_hgnc_merged_data.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "ensembl_hgnc_merged_data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "**Merge Processed Data:** `ensembl_hgnc_merged_data` + `Homo_sapiens.gene_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_source</th>\n",
       "      <th>molecule_type</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>exon_number</th>\n",
       "      <th>symbol</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>exon_stable_id</th>\n",
       "      <th>...</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>name</th>\n",
       "      <th>locus_group</th>\n",
       "      <th>location</th>\n",
       "      <th>alias_symbol</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>dbXrefs</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>type_of_gene</th>\n",
       "      <th>Other_designations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>havana</td>\n",
       "      <td>transcript</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>1</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENSE00002234944</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ensembl_source molecule_type  ensembl_gene_id transcript_stable_id  \\\n",
       "0         havana          gene  ENSG00000223972                 None   \n",
       "1         havana    transcript  ENSG00000223972      ENST00000456328   \n",
       "2         havana          exon  ENSG00000223972      ENST00000456328   \n",
       "\n",
       "  exon_number   symbol                       gene_type transcript_name  \\\n",
       "0        None  DDX11L1  transcribed_unprocessed_pseudo            None   \n",
       "1        None  DDX11L1  transcribed_unprocessed_pseudo     DDX11L1-202   \n",
       "2           1  DDX11L1  transcribed_unprocessed_pseudo     DDX11L1-202   \n",
       "\n",
       "        transcript_type   exon_stable_id  ... hgnc_id  name locus_group  \\\n",
       "0                  None             None  ...    None  None        None   \n",
       "1  processed_transcript             None  ...    None  None        None   \n",
       "2  processed_transcript  ENSE00002234944  ...    None  None        None   \n",
       "\n",
       "  location alias_symbol Synonyms dbXrefs chromosome type_of_gene  \\\n",
       "0     None         None     None    None       None         None   \n",
       "1     None         None     None    None       None         None   \n",
       "2     None         None     None    None       None         None   \n",
       "\n",
       "  Other_designations  \n",
       "0               None  \n",
       "1               None  \n",
       "2               None  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns before merging\n",
    "explode_df_ncbi_gene.rename(columns={'GeneID': 'entrez_id', 'Symbol': 'symbol', 'map_location': 'location', 'description': 'name'}, inplace=True)\n",
    "\n",
    "# update cell values\n",
    "ensembl_hgnc_merged_data['gene_type'].replace('protein_coding', 'protein-coding', inplace=True, regex=True)\n",
    "ensembl_hgnc_merged_data['gene_type'].replace('pseudogene', 'pseudo', inplace=True, regex=True)\n",
    "ensembl_hgnc_merged_data['locus_group'].replace('protein-coding gene', 'protein-coding', inplace=True, regex=True)\n",
    "ensembl_hgnc_merged_data['locus_group'].replace('non-coding RNA', 'ncRNA', inplace=True, regex=True)\n",
    "ensembl_hgnc_merged_data['locus_group'].replace('protein-coding gene', 'protein-coding', inplace=True, regex=True)\n",
    "ensembl_hgnc_merged_data['locus_group'].replace('pseudogene', 'pseudo', inplace=True, regex=True)\n",
    "\n",
    "# make sure that merge columns are of same type\n",
    "explode_df_ncbi_gene['entrez_id'] = explode_df_ncbi_gene['entrez_id'].astype(str)\n",
    "\n",
    "# merge uniprot and ncbi data\n",
    "ensembl_hgnc_ncbi_merged_data = pandas.merge(ensembl_hgnc_merged_data,\n",
    "                                             explode_df_ncbi_gene,\n",
    "                                             left_on=['entrez_id', 'symbol', 'location', 'name'],\n",
    "                                             right_on=['entrez_id', 'symbol', 'location', 'name'],\n",
    "                                             how='outer')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "ensembl_hgnc_ncbi_merged_data.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "ensembl_hgnc_ncbi_merged_data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Clean Merged Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5337480/5337480 [17:28<00:00, 5088.43it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>protein_stable_id</th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>entrez_id</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>symbol</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>alias_symbol</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>Other_designations</th>\n",
       "      <th>dbXrefs</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>gene_type_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000450305</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1-201</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ensembl_gene_id transcript_stable_id protein_stable_id uniprot_ids  \\\n",
       "0  ENSG00000223972                 None              None        None   \n",
       "1  ENSG00000223972      ENST00000456328              None        None   \n",
       "5  ENSG00000223972      ENST00000450305              None        None   \n",
       "\n",
       "  entrez_id hgnc_id chromosome   symbol location  name alias_symbol Synonyms  \\\n",
       "0      None    None       None  DDX11L1     None  None         None     None   \n",
       "1      None    None       None  DDX11L1     None  None         None     None   \n",
       "5      None    None       None  DDX11L1     None  None         None     None   \n",
       "\n",
       "  Other_designations dbXrefs transcript_name  \\\n",
       "0               None    None            None   \n",
       "1               None    None     DDX11L1-202   \n",
       "5               None    None     DDX11L1-201   \n",
       "\n",
       "                      transcript_type                       gene_type  \\\n",
       "0                                None  transcribed_unprocessed_pseudo   \n",
       "1                processed_transcript  transcribed_unprocessed_pseudo   \n",
       "5  transcribed_unprocessed_pseudogene  transcribed_unprocessed_pseudo   \n",
       "\n",
       "                gene_type_cleaned  \n",
       "0  transcribed_unprocessed_pseudo  \n",
       "1  transcribed_unprocessed_pseudo  \n",
       "5  transcribed_unprocessed_pseudo  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up merged data by combining columns of same type and removing un-needed columns\n",
    "gene_type = []\n",
    "\n",
    "# loop over data and fill in missing values\n",
    "for idx, row in tqdm(ensembl_hgnc_ncbi_merged_data.iterrows(), total=ensembl_hgnc_ncbi_merged_data.shape[0]):\n",
    "    if row['locus_group'] != 'None' and row['type_of_gene'] != 'None' and row['gene_type'] != 'None':\n",
    "        if (row['locus_group'] == row['type_of_gene']):\n",
    "            gene_type.append(row['locus_group']) \n",
    "        else:\n",
    "            gene_type.append('{} (HGNC)|{} (Entrez Gene)|{} (Ensembl)'.format(row['locus_group'], row['type_of_gene'], row['gene_type']))\n",
    "    elif row['locus_group'] != 'None' and (row['entrez_id'] == 'None' and row['gene_type'] == 'None'):\n",
    "        gene_type.append(row['locus_group'])\n",
    "    elif row['type_of_gene'] != 'None' and (row['locus_group'] == 'None' and row['gene_type'] == 'None'):\n",
    "        gene_type.append(row['type_of_gene'])\n",
    "    elif row['gene_type'] != 'None' and (row['locus_group'] == 'None' and row['type_of_gene'] == 'None'):\n",
    "        gene_type.append(row['gene_type'])\n",
    "    else:\n",
    "        gene_type.append('None')\n",
    "            \n",
    "# reduce columns\n",
    "ensembl_hgnc_ncbi_merged_data_clean = ensembl_hgnc_ncbi_merged_data.copy()\n",
    "ensembl_hgnc_ncbi_merged_data_clean = ensembl_hgnc_ncbi_merged_data_clean[['ensembl_gene_id', 'transcript_stable_id', 'protein_stable_id',\n",
    "                                                                           'uniprot_ids', 'entrez_id', 'hgnc_id', 'chromosome', 'symbol',\n",
    "                                                                           'location', 'name', 'alias_symbol', 'Synonyms', 'Other_designations',\n",
    "                                                                           'dbXrefs', 'transcript_name', 'transcript_type', 'gene_type']]\n",
    "\n",
    "# add cleaned columns\n",
    "ensembl_hgnc_ncbi_merged_data_clean['gene_type_cleaned'] = gene_type\n",
    "\n",
    "# remove duplicates\n",
    "ensembl_hgnc_ncbi_merged_data_clean.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "    \n",
    "# preview data\n",
    "ensembl_hgnc_ncbi_merged_data_clean.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "**Merge Processed Data:** `ensembl_ncbi_merged_data_clean` + `promapping.txt`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>protein_stable_id</th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>entrez_id</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>symbol</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>alias_symbol</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>Other_designations</th>\n",
       "      <th>dbXrefs</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>gene_type_cleaned</th>\n",
       "      <th>pro_id</th>\n",
       "      <th>pro_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000450305</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1-201</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ensembl_gene_id transcript_stable_id protein_stable_id uniprot_ids  \\\n",
       "0  ENSG00000223972                 None              None        None   \n",
       "1  ENSG00000223972      ENST00000456328              None        None   \n",
       "2  ENSG00000223972      ENST00000450305              None        None   \n",
       "\n",
       "  entrez_id hgnc_id chromosome   symbol location  name alias_symbol Synonyms  \\\n",
       "0      None    None       None  DDX11L1     None  None         None     None   \n",
       "1      None    None       None  DDX11L1     None  None         None     None   \n",
       "2      None    None       None  DDX11L1     None  None         None     None   \n",
       "\n",
       "  Other_designations dbXrefs transcript_name  \\\n",
       "0               None    None            None   \n",
       "1               None    None     DDX11L1-202   \n",
       "2               None    None     DDX11L1-201   \n",
       "\n",
       "                      transcript_type                       gene_type  \\\n",
       "0                                None  transcribed_unprocessed_pseudo   \n",
       "1                processed_transcript  transcribed_unprocessed_pseudo   \n",
       "2  transcribed_unprocessed_pseudogene  transcribed_unprocessed_pseudo   \n",
       "\n",
       "                gene_type_cleaned pro_id pro_mapping  \n",
       "0  transcribed_unprocessed_pseudo   None        None  \n",
       "1  transcribed_unprocessed_pseudo   None        None  \n",
       "2  transcribed_unprocessed_pseudo   None        None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns before merging\n",
    "pro_mapping.rename(columns={'Entry': 'uniprot_ids'}, inplace=True)\n",
    "\n",
    "# merge uniprot and ncbi data\n",
    "merged_data = pandas.merge(ensembl_hgnc_ncbi_merged_data_clean,\n",
    "                           pro_mapping,\n",
    "                           left_on='uniprot_ids',\n",
    "                           right_on='uniprot_ids',\n",
    "                           how='outer')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "merged_data.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "merged_data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Full Merged Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 851764/851764 [00:00<00:00, 1667300.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>transcript_stable_id</th>\n",
       "      <th>protein_stable_id</th>\n",
       "      <th>uniprot_ids</th>\n",
       "      <th>entrez_id</th>\n",
       "      <th>hgnc_id</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>symbol</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>alias_symbol</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>Other_designations</th>\n",
       "      <th>dbXrefs</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_type</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>gene_type_cleaned</th>\n",
       "      <th>pro_id</th>\n",
       "      <th>pro_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000450305</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DDX11L1-201</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ensembl_gene_id transcript_stable_id protein_stable_id uniprot_ids  \\\n",
       "0  ENSG00000223972                 None              None        None   \n",
       "1  ENSG00000223972      ENST00000456328              None        None   \n",
       "2  ENSG00000223972      ENST00000450305              None        None   \n",
       "\n",
       "  entrez_id hgnc_id chromosome   symbol location  name alias_symbol Synonyms  \\\n",
       "0      None    None       None  DDX11L1     None  None         None     None   \n",
       "1      None    None       None  DDX11L1     None  None         None     None   \n",
       "2      None    None       None  DDX11L1     None  None         None     None   \n",
       "\n",
       "  Other_designations dbXrefs transcript_name  \\\n",
       "0               None    None            None   \n",
       "1               None    None     DDX11L1-202   \n",
       "2               None    None     DDX11L1-201   \n",
       "\n",
       "                      transcript_type                       gene_type  \\\n",
       "0                                None  transcribed_unprocessed_pseudo   \n",
       "1                processed_transcript  transcribed_unprocessed_pseudo   \n",
       "2  transcribed_unprocessed_pseudogene  transcribed_unprocessed_pseudo   \n",
       "\n",
       "                gene_type_cleaned pro_id pro_mapping  \n",
       "0  transcribed_unprocessed_pseudo   None        None  \n",
       "1  transcribed_unprocessed_pseudo   None        None  \n",
       "2  transcribed_unprocessed_pseudo   None        None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "merged_data_clean = merged_data.drop_duplicates(subset=None, keep='first')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "merged_data_clean.fillna('None', inplace=True)\n",
    "\n",
    "# clean up gene symbols that have been converted into dates\n",
    "clean_dates = []\n",
    "\n",
    "for x in tqdm(list(merged_data_clean['symbol'])):\n",
    "    if '-' in x and len(x.split('-')[0]) < 3 and len(x.split('-')[1]) == 3:\n",
    "        clean_dates.append(x.split('-')[1].upper() + x.split('-')[0])\n",
    "    else:\n",
    "        clean_dates.append(x)\n",
    "    \n",
    "merged_data_clean['symbol'] = clean_dates\n",
    "\n",
    "# write data\n",
    "merged_data_clean.to_csv(processed_data_location + 'Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt',\n",
    "                         header = True,\n",
    "                         sep = '\\t',\n",
    "                         index = False)\n",
    "    \n",
    "# preview data\n",
    "merged_data_clean.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembl Gene-Ensembl Transcript <a class=\"anchor\" id=\"ensemblgene-ensembltranscript\"></a>\n",
    "\n",
    "**Purpose:** To map Ensembl gene identifiers to Ensembl transcript identifiers when creating the following edges: \n",
    "- rna-cell   \n",
    "- rna-tissue types  \n",
    "\n",
    "**Output:** [`ENSEMBL_GENE_ENSEMBL_TRANSCRIPT_MAP.txt`](https://www.dropbox.com/s/8n1isqytlz2z1g6/ENSEMBL_GENE_ENSEMBL_TRANSCRIPT_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_ens = merged_data_clean.drop_duplicates(subset=['ensembl_gene_id', 'transcript_stable_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'ENSEMBL_GENE_ENSEMBL_TRANSCRIPT_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_ens.iterrows(), total=df_ens.shape[0]):\n",
    "        if row['ensembl_gene_id'] != 'None' and row['transcript_stable_id'] != 'None': \n",
    "            outfile.write(row['ensembl_gene_id'].strip() + '\\t' + row['transcript_stable_id'].strip() + '\\t' + row['gene_type_cleaned'] + '\\t' + row['transcript_type'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 243643 ensembl gene-ensembl transcript edges\n"
     ]
    }
   ],
   "source": [
    "eget_data = pandas.read_csv(processed_data_location + 'ENSEMBL_GENE_ENSEMBL_TRANSCRIPT_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['Ensembl_Gene_IDs', 'Ensembl_Transcript_IDs', 'Gene_Type', 'Transcript_Type'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} ensembl gene-ensembl transcript edges'.format(edge_count=len(eget_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensembl_Gene_IDs</th>\n",
       "      <th>Ensembl_Transcript_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "      <th>Transcript_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>processed_transcript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>ENST00000450305</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>ENST00000488147</td>\n",
       "      <td>unprocessed_pseudo</td>\n",
       "      <td>unprocessed_pseudogene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000278267</td>\n",
       "      <td>ENST00000619216</td>\n",
       "      <td>miRNA</td>\n",
       "      <td>miRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>ENST00000473358</td>\n",
       "      <td>lncRNA</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensembl_Gene_IDs Ensembl_Transcript_IDs                       Gene_Type  \\\n",
       "0  ENSG00000223972        ENST00000456328  transcribed_unprocessed_pseudo   \n",
       "1  ENSG00000223972        ENST00000450305  transcribed_unprocessed_pseudo   \n",
       "2  ENSG00000227232        ENST00000488147              unprocessed_pseudo   \n",
       "3  ENSG00000278267        ENST00000619216                           miRNA   \n",
       "4  ENSG00000243485        ENST00000473358                          lncRNA   \n",
       "\n",
       "                      Transcript_Type  \n",
       "0                processed_transcript  \n",
       "1  transcribed_unprocessed_pseudogene  \n",
       "2              unprocessed_pseudogene  \n",
       "3                               miRNA  \n",
       "4                              lncRNA  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eget_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembl Gene-Entrez Gene <a class=\"anchor\" id=\"ensemblgene-entrezgene\"></a>\n",
    "\n",
    "\n",
    "**Purpose:** To map Ensembl gene identifiers to Entrez gene identifiers when creating the following edges:   \n",
    "- gene-gene\n",
    "\n",
    "**Output:** [`ENSEMBL_GENE_ENTREZ_GENE_MAP.txt`](https://www.dropbox.com/s/crghjh2we5v7pws/ENSEMBL_GENE_ENTREZ_GENE_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_ens = merged_data_clean.drop_duplicates(subset=['ensembl_gene_id', 'entrez_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'ENSEMBL_GENE_ENTREZ_GENE_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_ens.iterrows(), total=df_ens.shape[0]):\n",
    "        if row['ensembl_gene_id'] != 'None' and row['entrez_id'] != 'None': \n",
    "            outfile.write(row['ensembl_gene_id'].strip() + '\\t' + row['entrez_id'].strip() + '\\t' + row['gene_type_cleaned'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42196 ensembl gene-entrez gene edges\n"
     ]
    }
   ],
   "source": [
    "egeg_data = pandas.read_csv(processed_data_location + 'ENSEMBL_GENE_ENTREZ_GENE_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['Ensembl_Gene_IDs', 'Entrez_Gene_IDs', 'Gene_Type'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} ensembl gene-entrez gene edges'.format(edge_count=len(egeg_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensembl_Gene_IDs</th>\n",
       "      <th>Entrez_Gene_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000187634</td>\n",
       "      <td>148398</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000188976</td>\n",
       "      <td>26155</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000187961</td>\n",
       "      <td>339451</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000187583</td>\n",
       "      <td>84069</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000187642</td>\n",
       "      <td>84808</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensembl_Gene_IDs Entrez_Gene_IDs       Gene_Type\n",
       "0  ENSG00000187634          148398  protein-coding\n",
       "1  ENSG00000188976           26155  protein-coding\n",
       "2  ENSG00000187961          339451  protein-coding\n",
       "3  ENSG00000187583           84069  protein-coding\n",
       "4  ENSG00000187642           84808  protein-coding"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egeg_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembl Transcript-Protein Ontology <a class=\"anchor\" id=\"ensembltranscript-proteinontology\"></a>\n",
    "\n",
    "**Purpose:** To map Ensembl transcript identifiers to Protein Ontology identifiers when creating the following edges: \n",
    "- rna-protein  \n",
    "\n",
    "**Output:** [`ENSEMBL_TRANSCRIPT_PROTEIN_ONTOLOGY_MAP.txt`](https://www.dropbox.com/s/ckrw11nfyu6a08c/ENSEMBL_TRANSCRIPT_PROTEIN_ONTOLOGY_MAP.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_po = merged_data_clean.drop_duplicates(subset=['transcript_stable_id', 'pro_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'ENSEMBL_TRANSCRIPT_PROTEIN_ONTOLOGY_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_po.iterrows(), total=df_po.shape[0]):\n",
    "        if row['transcript_stable_id'] != 'None' and row['pro_id'] != 'None': \n",
    "            outfile.write(row['transcript_stable_id'].strip() + '\\t' + row['pro_id'].replace('PR:', 'PR_').strip() + '\\t' + row['gene_type_cleaned'] + '\\t' + row['transcript_type'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 92270 ensembl transcript-protein ontology edges\n"
     ]
    }
   ],
   "source": [
    "etpr_data = pandas.read_csv(processed_data_location + 'ENSEMBL_TRANSCRIPT_PROTEIN_ONTOLOGY_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['Ensembl_Transcript_IDs', 'Protein_Ontology_IDs', 'Gene_Type', 'Transcript_Type'],\n",
    "                            delimiter = '\\t',\n",
    "                            low_memory=False)\n",
    "\n",
    "print('There are {edge_count} ensembl transcript-protein ontology edges'.format(edge_count=len(etpr_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensembl_Transcript_IDs</th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "      <th>Transcript_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000335137</td>\n",
       "      <td>PR_000011836</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>protein_coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000335137</td>\n",
       "      <td>PR_Q8NH21</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>protein_coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000426406</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>protein_coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000426406</td>\n",
       "      <td>PR_Q6IEY1</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>protein_coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000332831</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "      <td>protein_coding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ensembl_Transcript_IDs Protein_Ontology_IDs       Gene_Type Transcript_Type\n",
       "0        ENST00000335137         PR_000011836  protein-coding  protein_coding\n",
       "1        ENST00000335137            PR_Q8NH21  protein-coding  protein_coding\n",
       "2        ENST00000426406         PR_000011834  protein-coding  protein_coding\n",
       "3        ENST00000426406            PR_Q6IEY1  protein-coding  protein_coding\n",
       "4        ENST00000332831         PR_000011834  protein-coding  protein_coding"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etpr_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Symbol-Ensembl Transcript <a class=\"anchor\" id=\"genesymbol-ensembltranscript\"></a>\n",
    "\n",
    "**Purpose:** To map gene symbols to Ensembl transcript identifiers when creating the following edges: \n",
    "- gene-rna \n",
    "\n",
    "**Output:** [`GENE_SYMBOL_ENSEMBL_TRANSCRIPT_MAP.txt`](https://www.dropbox.com/s/5o8yt7eejbf819x/GENE_SYMBOL_ENSEMBL_TRANSCRIPT_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_ens = merged_data_clean.drop_duplicates(subset=['symbol', 'transcript_stable_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'GENE_SYMBOL_ENSEMBL_TRANSCRIPT_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_ens.iterrows(), total=df_ens.shape[0]):\n",
    "        if row['symbol'] != 'None' and row['transcript_stable_id'] != 'None': \n",
    "            outfile.write(row['symbol'].strip() + '\\t' + row['transcript_stable_id'].strip() + '\\t' + row['gene_type_cleaned'] + '\\t' + row['transcript_type'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 227818 gene symbol-ensembl transcript edges\n"
     ]
    }
   ],
   "source": [
    "set_data = pandas.read_csv(processed_data_location + 'GENE_SYMBOL_ENSEMBL_TRANSCRIPT_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['Gene_Symbols', 'Ensembl_Transcript_IDs', 'Gene_Type', 'Transcript_Type'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} gene symbol-ensembl transcript edges'.format(edge_count=len(set_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_Symbols</th>\n",
       "      <th>Ensembl_Transcript_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "      <th>Transcript_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>processed_transcript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>ENST00000450305</td>\n",
       "      <td>transcribed_unprocessed_pseudo</td>\n",
       "      <td>transcribed_unprocessed_pseudogene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WASH7P</td>\n",
       "      <td>ENST00000488147</td>\n",
       "      <td>unprocessed_pseudo</td>\n",
       "      <td>unprocessed_pseudogene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIR6859-1</td>\n",
       "      <td>ENST00000619216</td>\n",
       "      <td>miRNA</td>\n",
       "      <td>miRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MIR1302-2HG</td>\n",
       "      <td>ENST00000473358</td>\n",
       "      <td>lncRNA</td>\n",
       "      <td>lncRNA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene_Symbols Ensembl_Transcript_IDs                       Gene_Type  \\\n",
       "0      DDX11L1        ENST00000456328  transcribed_unprocessed_pseudo   \n",
       "1      DDX11L1        ENST00000450305  transcribed_unprocessed_pseudo   \n",
       "2       WASH7P        ENST00000488147              unprocessed_pseudo   \n",
       "3    MIR6859-1        ENST00000619216                           miRNA   \n",
       "4  MIR1302-2HG        ENST00000473358                          lncRNA   \n",
       "\n",
       "                      Transcript_Type  \n",
       "0                processed_transcript  \n",
       "1  transcribed_unprocessed_pseudogene  \n",
       "2              unprocessed_pseudogene  \n",
       "3                               miRNA  \n",
       "4                              lncRNA  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrez Gene-Protein Ontology <a class=\"anchor\" id=\"entrezgene-proteinontology\"></a>\n",
    "\n",
    "**Purpose:** To map Protein Ontology identifiers to Ensembl transcript identifiers when creating the following edges:   \n",
    "- chemical-protein  \n",
    "\n",
    "**Output:** [`ENTREZ_GENE_PRO_ONTOLOGY_MAP.txt`](https://www.dropbox.com/s/ufbp5o6zgagriw7/ENTREZ_GENE_PRO_ONTOLOGY_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_egpr = merged_data_clean.drop_duplicates(subset=['entrez_id', 'pro_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'ENTREZ_GENE_PRO_ONTOLOGY_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_egpr.iterrows(), total=df_egpr.shape[0]):\n",
    "        if row['entrez_id'] != 'None' and row['pro_id'] != 'None': \n",
    "            outfile.write(row['entrez_id'].strip() + '\\t' + row['pro_id'].replace(':', '_').strip() + '\\t' + row['gene_type_cleaned'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 38996 entrez gene-protein ontology edges\n"
     ]
    }
   ],
   "source": [
    "egpr_data = pandas.read_csv(processed_data_location + 'ENTREZ_GENE_PRO_ONTOLOGY_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['Gene_IDs', 'Protein_Ontology_IDs', 'Gene_Type'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} entrez gene-protein ontology edges'.format(edge_count=len(egpr_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_IDs</th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79501</td>\n",
       "      <td>PR_000011836</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79501</td>\n",
       "      <td>PR_Q8NH21</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>729759</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>729759</td>\n",
       "      <td>PR_Q6IEY1</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81399</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gene_IDs Protein_Ontology_IDs       Gene_Type\n",
       "0    79501         PR_000011836  protein-coding\n",
       "1    79501            PR_Q8NH21  protein-coding\n",
       "2   729759         PR_000011834  protein-coding\n",
       "3   729759            PR_Q6IEY1  protein-coding\n",
       "4    81399         PR_000011834  protein-coding"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egpr_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRING-Protein Ontology <a class=\"anchor\" id=\"string-proteinontology\"></a>\n",
    "\n",
    "**Purpose:** To map STRING identifiers to Protein Ontology identifiers when creating the following edges:   \n",
    "- protein-protein  \n",
    "\n",
    "**Output:** [`STRING_PRO_ONTOLOGY_MAP.txt`](https://www.dropbox.com/s/mekh5lr3bxp7gvu/STRING_PRO_ONTOLOGY_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_ens = merged_data_clean.drop_duplicates(subset=['protein_stable_id', 'pro_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'STRING_PRO_ONTOLOGY_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_ens.iterrows(), total=df_ens.shape[0]):\n",
    "        if row['protein_stable_id'] != 'None' and row['pro_id'] != 'None':\n",
    "            outfile.write('9606.' + row['protein_stable_id'].strip() + '\\t' + row['pro_id'].replace(':', '_').strip() + '\\t' + row['gene_type_cleaned'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 92270 string-protein ontology edges\n"
     ]
    }
   ],
   "source": [
    "stpr_data = pandas.read_csv(processed_data_location + 'STRING_PRO_ONTOLOGY_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['STRING_IDs', 'Protein_Ontology_IDs', 'Gene_Type'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} string-protein ontology edges'.format(edge_count=len(stpr_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STRING_IDs</th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9606.ENSP00000334393</td>\n",
       "      <td>PR_000011836</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9606.ENSP00000334393</td>\n",
       "      <td>PR_Q8NH21</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9606.ENSP00000409316</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9606.ENSP00000409316</td>\n",
       "      <td>PR_Q6IEY1</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9606.ENSP00000329982</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             STRING_IDs Protein_Ontology_IDs       Gene_Type\n",
       "0  9606.ENSP00000334393         PR_000011836  protein-coding\n",
       "1  9606.ENSP00000334393            PR_Q8NH21  protein-coding\n",
       "2  9606.ENSP00000409316         PR_000011834  protein-coding\n",
       "3  9606.ENSP00000409316            PR_Q6IEY1  protein-coding\n",
       "4  9606.ENSP00000329982         PR_000011834  protein-coding"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stpr_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniprot Accession-Protein Ontology <a class=\"anchor\" id=\"uniprotaccession-proteinontology\"></a>\n",
    "\n",
    "**Purpose:** To map Uniprot accession identifiers to Protein Ontology identifiers when creating the following edges:  \n",
    "- protein-gobp  \n",
    "- protein-gomf  \n",
    "- protein-gocc  \n",
    "- protein-complex  \n",
    "- protein-cofactor  \n",
    "- protein-catalyst \n",
    "- protein-reaction  \n",
    "- protein-pathway\n",
    "\n",
    "**Output:** [`UNIPROT_ACCESSION_PRO_ONTOLOGY_MAP.txt`](https://www.dropbox.com/s/txp8tqdipzwus9p/UNIPROT_ACCESSION_PRO_ONTOLOGY_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_ens = merged_data_clean.drop_duplicates(subset=['uniprot_ids', 'pro_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'UNIPROT_ACCESSION_PRO_ONTOLOGY_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_ens.iterrows(), total=df_ens.shape[0]):\n",
    "        if row['uniprot_ids'] != 'None' and row['pro_id'] != 'None': \n",
    "            outfile.write(row['uniprot_ids'].strip() + '\\t' + row['pro_id'].replace(':', '_').strip() + '\\t' + row['gene_type_cleaned'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 313776 uniprot accession-protein ontology edges\n"
     ]
    }
   ],
   "source": [
    "uapr_data = pandas.read_csv(processed_data_location + 'UNIPROT_ACCESSION_PRO_ONTOLOGY_MAP.txt',\n",
    "                            header = None,\n",
    "                            names=['Uniprot_Accession_IDs', 'Protein_Ontology_IDs', 'Gene_Types'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} uniprot accession-protein ontology edges'.format(edge_count=len(uapr_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_Accession_IDs</th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>Gene_Types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q8NH21</td>\n",
       "      <td>PR_000011836</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q8NH21</td>\n",
       "      <td>PR_Q8NH21</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q6IEY1</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q6IEY1</td>\n",
       "      <td>PR_Q6IEY1</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q96NU1</td>\n",
       "      <td>PR_000014441</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Uniprot_Accession_IDs Protein_Ontology_IDs      Gene_Types\n",
       "0                Q8NH21         PR_000011836  protein-coding\n",
       "1                Q8NH21            PR_Q8NH21  protein-coding\n",
       "2                Q6IEY1         PR_000011834  protein-coding\n",
       "3                Q6IEY1            PR_Q6IEY1  protein-coding\n",
       "4                Q96NU1         PR_000014441  protein-coding"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uapr_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### Other Identifier Mapping <a class=\"anchor\" id=\"other-identifier-mapping\"></a>\n",
    "***\n",
    "* [ChEBI Identifiers](#mesh-chebi)  \n",
    "* [Human Protein Atlas Tissue and Cell Types](#hpa-uberon) \n",
    "* [Human Disease and Phenotype Identifiers](#disease-identifiers) \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChEBI-MeSH Identifiers <a class=\"anchor\" id=\"mesh-chebi\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [mapping-mesh-to-chebi](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#mapping-mesh-identifiers-to-chebi-identifiers)  \n",
    "\n",
    "**Purpose:** Map MeSH identifiers to ChEBI identifiers when creating the following edges:  \n",
    "- chemical-gene  \n",
    "- chemical-disease\n",
    "\n",
    "**Dependencies:** This script assumes that the [`ncbo_rest_api.py`](https://github.com/callahantiff/PheKnowLator/blob/development/scripts/python/ncbo_rest_api.py) script was run and the data generated from this file was written to `./resources/processed_data/temp`. \n",
    "\n",
    "**Output:** [`MESH_CHEBI_MAP.txt`](https://www.dropbox.com/s/5nr87v5h6x8oc1b/MESH_CHEBI_MAP.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 44/44 [00:00<00:00, 670.44it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(processed_data_location + 'MESH_CHEBI_MAP.txt', 'w') as out:\n",
    "    for filename in tqdm(glob.glob(processed_data_location + 'temp/*.txt')):\n",
    "        for row in list(filter(None, open(filename, 'r').read().split('\\n'))):\n",
    "            mesh = '_'.join(row.split('\\t')[0].split('/')[-2:])\n",
    "            chebi = row.split('\\t')[1].split('/')[-1]\n",
    "            out.write(mesh + '\\t' + chebi + '\\n')\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11434 MeSH-ChEBI edges\n"
     ]
    }
   ],
   "source": [
    "mc_data = pandas.read_csv(processed_data_location + 'MESH_CHEBI_MAP.txt',\n",
    "                          delimiter = '\\t',\n",
    "                          header=None,\n",
    "                          names=['MeSH_IDs', 'ChEBI_IDs'])\n",
    "\n",
    "print('There are {edge_count} MeSH-ChEBI edges'.format(edge_count=len(mc_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MeSH_IDs</th>\n",
       "      <th>ChEBI_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH_C535085</td>\n",
       "      <td>CHEBI_133814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH_C008574</td>\n",
       "      <td>CHEBI_17221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MESH_C492482</td>\n",
       "      <td>CHEBI_34581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MESH_C007556</td>\n",
       "      <td>CHEBI_135978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MESH_C500395</td>\n",
       "      <td>CHEBI_29138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MeSH_IDs     ChEBI_IDs\n",
       "0  MESH_C535085  CHEBI_133814\n",
       "1  MESH_C008574   CHEBI_17221\n",
       "2  MESH_C492482   CHEBI_34581\n",
       "3  MESH_C007556  CHEBI_135978\n",
       "4  MESH_C500395   CHEBI_29138"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease and Phenotype Identifiers <a class=\"anchor\" id=\"disease-identifiers\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [disgenet](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#disgenet)  \n",
    "\n",
    "**Purpose:** This script downloads the [disease_mappings.tsv](https://www.disgenet.org/static/disgenet_ap1/files/downloads/disease_mappings.tsv.gz) to map UMLS identifiers to Human Disease and Human Phenotype identifiers when creating the following edges:  \n",
    "- chemical-disease  \n",
    "- disease-phenotype\n",
    "\n",
    "**Output:**   \n",
    "- Human Disease Ontology Mappings ➞ [`DISEASE_DOID_MAP.txt`](https://www.dropbox.com/s/q30ferujl7k574j/DISEASE_DOID_MAP.txt?dl=1)  \n",
    "- Human Phenotype Ontology Mappings ➞ [`PHENOTYPE_HPO_MAP.txt`](https://www.dropbox.com/s/5ayl0c5qm7r4tdm/PHENOTYPE_HPO_MAP.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.disgenet.org/static/disgenet_ap1/files/downloads/disease_mappings.tsv.gz'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diseaseId</th>\n",
       "      <th>name</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>code</th>\n",
       "      <th>vocabularyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0018923</td>\n",
       "      <td>Hemangiosarcoma</td>\n",
       "      <td>DO</td>\n",
       "      <td>0001816</td>\n",
       "      <td>angiosarcoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0854893</td>\n",
       "      <td>Angiosarcoma non-metastatic</td>\n",
       "      <td>DO</td>\n",
       "      <td>0001816</td>\n",
       "      <td>angiosarcoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0033999</td>\n",
       "      <td>Pterygium</td>\n",
       "      <td>DO</td>\n",
       "      <td>0002116</td>\n",
       "      <td>pterygium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diseaseId                         name vocabulary     code vocabularyName\n",
       "0  C0018923              Hemangiosarcoma         DO  0001816   angiosarcoma\n",
       "1  C0854893  Angiosarcoma non-metastatic         DO  0001816   angiosarcoma\n",
       "2  C0033999                    Pterygium         DO  0002116      pterygium"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_data = pandas.read_csv(unprocessed_data_location + 'disease_mappings.tsv',\n",
    "                               header = 0,\n",
    "                               delimiter = '|')\n",
    "\n",
    "disease_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dictionary\n",
    "disease_dict = {}\n",
    "\n",
    "for idx, row in tqdm(disease_data.iterrows(), total=disease_data.shape[0]):\n",
    "    if row['vocabulary'] == 'MSH':\n",
    "        mesh_finder(disease_data, row['code'], 'MESH:', disease_dict)\n",
    "    elif row['vocabulary'] == 'OMIM':\n",
    "        mesh_finder(disease_data, row['code'], 'OMIM:', disease_dict)\n",
    "    elif row['vocabulary'] == 'ORDO':\n",
    "        mesh_finder(disease_data, row['code'], 'ORPHA:', disease_dict)\n",
    "    elif row['diseaseId'] in disease_dict.keys():\n",
    "        if row['vocabulary'] == 'DO':\n",
    "            disease_dict[row['diseaseId']].append('DOID_' + row['code']) \n",
    "        if row['vocabulary'] == 'HPO':\n",
    "            disease_dict[row['diseaseId']].append(row['code'].replace('HP:', 'HP_'))\n",
    "    else:\n",
    "        if row['vocabulary'] == 'DO':\n",
    "            disease_dict[row['diseaseId']] = ['DOID_' + row['code']] \n",
    "        if row['vocabulary'] == 'HPO':\n",
    "            disease_dict[row['diseaseId']] = [row['code'].replace('HP:', 'HP_')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'DISEASE_DOID_MAP.txt', 'w') as outfile1,open(processed_data_location + 'PHENOTYPE_HPO_MAP.txt', 'w') as outfile2:\n",
    "    for key, value in tqdm(disease_dict.items()):\n",
    "        for i in value:\n",
    "            # get diseases\n",
    "            if i.startswith('DOID_'): \n",
    "                outfile1.write(key.split(':')[-1] + '\\t' + i + '\\n')\n",
    "\n",
    "            # get phenotypes\n",
    "            if i.startswith('HP_'): \n",
    "                outfile2.write(key.split(':')[-1] + '\\t' + i + '\\n')\n",
    "\n",
    "outfile1.close()\n",
    "outfile2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Preview Disease (DOID) Mappings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 46720 disease-DOID edges\n"
     ]
    }
   ],
   "source": [
    "dis_data = pandas.read_csv(processed_data_location + 'DISEASE_DOID_MAP.txt',\n",
    "                           header = None,\n",
    "                           names=['Disease_IDs', 'DOID_IDs'],\n",
    "                           delimiter = '\\t')\n",
    "\n",
    "print('There are {} disease-DOID edges'.format(len(dis_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease_IDs</th>\n",
       "      <th>DOID_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0018923</td>\n",
       "      <td>DOID_0001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0854893</td>\n",
       "      <td>DOID_0001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0033999</td>\n",
       "      <td>DOID_0002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4520843</td>\n",
       "      <td>DOID_0002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0024814</td>\n",
       "      <td>DOID_0014667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Disease_IDs      DOID_IDs\n",
       "0    C0018923  DOID_0001816\n",
       "1    C0854893  DOID_0001816\n",
       "2    C0033999  DOID_0002116\n",
       "3    C4520843  DOID_0002116\n",
       "4    C0024814  DOID_0014667"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Preview Phenotype (HP) Mappings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 21676 phenotype-HPO edges\n"
     ]
    }
   ],
   "source": [
    "hp_data = pandas.read_csv(processed_data_location + 'PHENOTYPE_HPO_MAP.txt',\n",
    "                          header = None,\n",
    "                          names=['Disease_IDs', 'HP_IDs'],\n",
    "                          delimiter = '\\t')\n",
    "\n",
    "print('There are {} phenotype-HPO edges'.format(len(hp_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease_IDs</th>\n",
       "      <th>HP_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0018923</td>\n",
       "      <td>HP_0200058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0033999</td>\n",
       "      <td>HP_0001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4520843</td>\n",
       "      <td>HP_0001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0037199</td>\n",
       "      <td>HP_0000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0008780</td>\n",
       "      <td>HP_0012265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Disease_IDs      HP_IDs\n",
       "0    C0018923  HP_0200058\n",
       "1    C0033999  HP_0001059\n",
       "2    C4520843  HP_0001059\n",
       "3    C0037199  HP_0000246\n",
       "4    C0008780  HP_0012265"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Protein Atlas/GTEx Tissue/Cells - UBERON + Cell Ontology + Cell Line Ontology <a class=\"anchor\" id=\"hpa-uberon\"></a>\n",
    "\n",
    "**Data Source Wiki Page:**  \n",
    "- [human-protein-atlas](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#human-protein-atlas) \n",
    "- [genotype-tissue-expression-project](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#the-genotype-tissue-expression-gtex-project)  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Purpose:** Downloads a query for cell, tissue, and blood types with overexpressed protein-coding genes in the human proteome ([`proteinatlas_search.tsv`](https://www.proteinatlas.org/api/search_download.php?search=&columns=g,eg,up,pe,rnatsm,rnaclsm,rnacasm,rnabrsm,rnabcsm,rnablsm,scl,t_RNA_adipose_tissue,t_RNA_adrenal_gland,t_RNA_amygdala,t_RNA_appendix,t_RNA_basal_ganglia,t_RNA_bone_marrow,t_RNA_breast,t_RNA_cerebellum,t_RNA_cerebral_cortex,t_RNA_cervix,_uterine,t_RNA_colon,t_RNA_corpus_callosum,t_RNA_ductus_deferens,t_RNA_duodenum,t_RNA_endometrium_1,t_RNA_epididymis,t_RNA_esophagus,t_RNA_fallopian_tube,t_RNA_gallbladder,t_RNA_heart_muscle,t_RNA_hippocampal_formation,t_RNA_hypothalamus,t_RNA_kidney,t_RNA_liver,t_RNA_lung,t_RNA_lymph_node,t_RNA_midbrain,t_RNA_olfactory_region,t_RNA_ovary,t_RNA_pancreas,t_RNA_parathyroid_gland,t_RNA_pituitary_gland,t_RNA_placenta,t_RNA_pons_and_medulla,t_RNA_prostate,t_RNA_rectum,t_RNA_retina,t_RNA_salivary_gland,t_RNA_seminal_vesicle,t_RNA_skeletal_muscle,t_RNA_skin_1,t_RNA_small_intestine,t_RNA_smooth_muscle,t_RNA_spinal_cord,t_RNA_spleen,t_RNA_stomach_1,t_RNA_testis,t_RNA_thalamus,t_RNA_thymus,t_RNA_thyroid_gland,t_RNA_tongue,t_RNA_tonsil,t_RNA_urinary_bladder,t_RNA_vagina,t_RNA_B-cells,t_RNA_dendritic_cells,t_RNA_granulocytes,t_RNA_monocytes,t_RNA_NK-cells,t_RNA_T-cells,t_RNA_total_PBMC,cell_RNA_A-431,cell_RNA_A549,cell_RNA_AF22,cell_RNA_AN3-CA,cell_RNA_ASC_diff,cell_RNA_ASC_TERT1,cell_RNA_BEWO,cell_RNA_BJ,cell_RNA_BJ_hTERT+,cell_RNA_BJ_hTERT+_SV40_Large_T+,cell_RNA_BJ_hTERT+_SV40_Large_T+_RasG12V,cell_RNA_CACO-2,cell_RNA_CAPAN-2,cell_RNA_Daudi,cell_RNA_EFO-21,cell_RNA_fHDF/TERT166,cell_RNA_HaCaT,cell_RNA_HAP1,cell_RNA_HBEC3-KT,cell_RNA_HBF_TERT88,cell_RNA_HDLM-2,cell_RNA_HEK_293,cell_RNA_HEL,cell_RNA_HeLa,cell_RNA_Hep_G2,cell_RNA_HHSteC,cell_RNA_HL-60,cell_RNA_HMC-1,cell_RNA_HSkMC,cell_RNA_hTCEpi,cell_RNA_hTEC/SVTERT24-B,cell_RNA_hTERT-HME1,cell_RNA_HUVEC_TERT2,cell_RNA_K-562,cell_RNA_Karpas-707,cell_RNA_LHCN-M2,cell_RNA_MCF7,cell_RNA_MOLT-4,cell_RNA_NB-4,cell_RNA_NTERA-2,cell_RNA_PC-3,cell_RNA_REH,cell_RNA_RH-30,cell_RNA_RPMI-8226,cell_RNA_RPTEC_TERT1,cell_RNA_RT4,cell_RNA_SCLC-21H,cell_RNA_SH-SY5Y,cell_RNA_SiHa,cell_RNA_SK-BR-3,cell_RNA_SK-MEL-30,cell_RNA_T-47d,cell_RNA_THP-1,cell_RNA_TIME,cell_RNA_U-138_MG,cell_RNA_U-2_OS,cell_RNA_U-2197,cell_RNA_U-251_MG,cell_RNA_U-266/70,cell_RNA_U-266/84,cell_RNA_U-698,cell_RNA_U-87_MG,cell_RNA_U-937,cell_RNA_WM-115,blood_RNA_basophil,blood_RNA_classical_monocyte,blood_RNA_eosinophil,blood_RNA_gdT-cell,blood_RNA_intermediate_monocyte,blood_RNA_MAIT_T-cell,blood_RNA_memory_B-cell,blood_RNA_memory_CD4_T-cell,blood_RNA_memory_CD8_T-cell,blood_RNA_myeloid_DC,blood_RNA_naive_B-cell,blood_RNA_naive_CD4_T-cell,blood_RNA_naive_CD8_T-cell,blood_RNA_neutrophil,blood_RNA_NK-cell,blood_RNA_non-classical_monocyte,blood_RNA_plasmacytoid_DC,blood_RNA_T-reg,blood_RNA_total_PBMC,brain_RNA_amygdala,brain_RNA_basal_ganglia,brain_RNA_cerebellum,brain_RNA_cerebral_cortex,brain_RNA_hippocampal_formation,brain_RNA_hypothalamus,brain_RNA_midbrain,brain_RNA_olfactory_region,brain_RNA_pons_and_medulla,brain_RNA_thalamus&format=tsv)) and median gene-level TPM by tissue for all genes that are not protein-coding ([`GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct`](https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz)) in order to create mappings between cell and tissue type strings to the Uber-Anatomy, Cell Ontology, and Cell Line Ontology concepts (see [human-protein-atlas](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#human-protein-atlas) for details on the mapping process). The [`Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt`](https://www.dropbox.com/s/fiek6h5rowi7dh0/Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt?dl=1) file was used to filter the GTEx data for genes that were not protein-coding. The mappings are then used to create the following edge types:  \n",
    "- rna-cell line  \n",
    "- rna-tissue type   \n",
    "- protein-cell line  \n",
    "- protein-tissue type  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Output:**  \n",
    "- All HPA tissue and cell type strings ➞ [`HPA_tissues.txt`](https://www.dropbox.com/s/m0spn8h1l8kxb61/HPA_tissues.txt?dl=1)  \n",
    "- Mapping HPA strings to ontology concepts (documentation) ➞ [`zooma_tissue_cell_mapping_04JAN2020.xlsx`](https://www.dropbox.com/s/lxp8vxj39eumvcn/zooma_tissue_cell_mapping_04JAN2020.xlsx?dl=1)  \n",
    "- Final HPA-ontology mappings ➞ [`HPA_GTEx_TISSUE_CELL_MAP.txt`](https://www.dropbox.com/s/snzdwv1cvs0v9pp/HPA_GTEx_TISSUE_CELL_MAP.txt?dl=1)\n",
    "- HPA Edges ➞ [`HPA_GTEX_RNA_GENE_PROTEIN_EDGES.txt`](https://www.dropbox.com/s/u7elnc056zxypc6/HPA_GTEX_RNA_GENE_PROTEIN_EDGES.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data used to identify genes that do not code for proteins from GTEx\n",
    "merged_data_clean = pandas.read_csv(processed_data_location + 'Merged_Human_Ensembl_Entrez_HGNC_Uniprot_Identifiers.txt',\n",
    "                                   header = 0,\n",
    "                                   low_memory=False,\n",
    "                                   delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Human Protein Atlas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.proteinatlas.org/api/search_download.php?search=&columns=g,eg,up,pe,rnatsm,rnaclsm,rnacasm,rnabrsm,rnabcsm,rnablsm,scl,t_RNA_adipose_tissue,t_RNA_adrenal_gland,t_RNA_amygdala,t_RNA_appendix,t_RNA_basal_ganglia,t_RNA_bone_marrow,t_RNA_breast,t_RNA_cerebellum,t_RNA_cerebral_cortex,t_RNA_cervix,_uterine,t_RNA_colon,t_RNA_corpus_callosum,t_RNA_ductus_deferens,t_RNA_duodenum,t_RNA_endometrium_1,t_RNA_epididymis,t_RNA_esophagus,t_RNA_fallopian_tube,t_RNA_gallbladder,t_RNA_heart_muscle,t_RNA_hippocampal_formation,t_RNA_hypothalamus,t_RNA_kidney,t_RNA_liver,t_RNA_lung,t_RNA_lymph_node,t_RNA_midbrain,t_RNA_olfactory_region,t_RNA_ovary,t_RNA_pancreas,t_RNA_parathyroid_gland,t_RNA_pituitary_gland,t_RNA_placenta,t_RNA_pons_and_medulla,t_RNA_prostate,t_RNA_rectum,t_RNA_retina,t_RNA_salivary_gland,t_RNA_seminal_vesicle,t_RNA_skeletal_muscle,t_RNA_skin_1,t_RNA_small_intestine,t_RNA_smooth_muscle,t_RNA_spinal_cord,t_RNA_spleen,t_RNA_stomach_1,t_RNA_testis,t_RNA_thalamus,t_RNA_thymus,t_RNA_thyroid_gland,t_RNA_tongue,t_RNA_tonsil,t_RNA_urinary_bladder,t_RNA_vagina,t_RNA_B-cells,t_RNA_dendritic_cells,t_RNA_granulocytes,t_RNA_monocytes,t_RNA_NK-cells,t_RNA_T-cells,t_RNA_total_PBMC,cell_RNA_A-431,cell_RNA_A549,cell_RNA_AF22,cell_RNA_AN3-CA,cell_RNA_ASC_diff,cell_RNA_ASC_TERT1,cell_RNA_BEWO,cell_RNA_BJ,cell_RNA_BJ_hTERT+,cell_RNA_BJ_hTERT+_SV40_Large_T+,cell_RNA_BJ_hTERT+_SV40_Large_T+_RasG12V,cell_RNA_CACO-2,cell_RNA_CAPAN-2,cell_RNA_Daudi,cell_RNA_EFO-21,cell_RNA_fHDF/TERT166,cell_RNA_HaCaT,cell_RNA_HAP1,cell_RNA_HBEC3-KT,cell_RNA_HBF_TERT88,cell_RNA_HDLM-2,cell_RNA_HEK_293,cell_RNA_HEL,cell_RNA_HeLa,cell_RNA_Hep_G2,cell_RNA_HHSteC,cell_RNA_HL-60,cell_RNA_HMC-1,cell_RNA_HSkMC,cell_RNA_hTCEpi,cell_RNA_hTEC/SVTERT24-B,cell_RNA_hTERT-HME1,cell_RNA_HUVEC_TERT2,cell_RNA_K-562,cell_RNA_Karpas-707,cell_RNA_LHCN-M2,cell_RNA_MCF7,cell_RNA_MOLT-4,cell_RNA_NB-4,cell_RNA_NTERA-2,cell_RNA_PC-3,cell_RNA_REH,cell_RNA_RH-30,cell_RNA_RPMI-8226,cell_RNA_RPTEC_TERT1,cell_RNA_RT4,cell_RNA_SCLC-21H,cell_RNA_SH-SY5Y,cell_RNA_SiHa,cell_RNA_SK-BR-3,cell_RNA_SK-MEL-30,cell_RNA_T-47d,cell_RNA_THP-1,cell_RNA_TIME,cell_RNA_U-138_MG,cell_RNA_U-2_OS,cell_RNA_U-2197,cell_RNA_U-251_MG,cell_RNA_U-266/70,cell_RNA_U-266/84,cell_RNA_U-698,cell_RNA_U-87_MG,cell_RNA_U-937,cell_RNA_WM-115,blood_RNA_basophil,blood_RNA_classical_monocyte,blood_RNA_eosinophil,blood_RNA_gdT-cell,blood_RNA_intermediate_monocyte,blood_RNA_MAIT_T-cell,blood_RNA_memory_B-cell,blood_RNA_memory_CD4_T-cell,blood_RNA_memory_CD8_T-cell,blood_RNA_myeloid_DC,blood_RNA_naive_B-cell,blood_RNA_naive_CD4_T-cell,blood_RNA_naive_CD8_T-cell,blood_RNA_neutrophil,blood_RNA_NK-cell,blood_RNA_non-classical_monocyte,blood_RNA_plasmacytoid_DC,blood_RNA_T-reg,blood_RNA_total_PBMC,brain_RNA_amygdala,brain_RNA_basal_ganglia,brain_RNA_cerebellum,brain_RNA_cerebral_cortex,brain_RNA_hippocampal_formation,brain_RNA_hypothalamus,brain_RNA_midbrain,brain_RNA_olfactory_region,brain_RNA_pons_and_medulla,brain_RNA_thalamus&format=tsv'\n",
    "data_downloader(url, unprocessed_data_location, 'proteinatlas_search.tsv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa = pandas.read_csv(unprocessed_data_location + 'proteinatlas_search.tsv',\n",
    "                      header = 0,\n",
    "                      delimiter = '\\t')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "hpa.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Identify HPA Terms Needing Mapping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:00<00:00, 52715.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# retrieve terms to map\n",
    "terms_to_map = list(hpa.columns)\n",
    "\n",
    "# write results\n",
    "with open(unprocessed_data_location + 'HPA_tissues.txt', 'w') as outfile:\n",
    "    for x in tqdm(terms_to_map):\n",
    "        if x.endswith('[NX]'):\n",
    "            term = x.split('RNA - ')[-1].split(' [NX]')[:-1][0]\n",
    "            outfile.write(term + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genotype-Tissue Expression Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gzipped data file\n"
     ]
    }
   ],
   "source": [
    "url='https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtex = pandas.read_csv(unprocessed_data_location + 'GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct',\n",
    "                      header = 0,\n",
    "                      skiprows=2,\n",
    "                      delimiter = '\\t')\n",
    "\n",
    "# replace NaN with 'None'\n",
    "gtex.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Mapping Data**  \n",
    "Here, we are reading back in the concepts that we externally mapped from HPA and GTEx tissue, cell, and cell lines to [UBERON](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#uber-anatomy-ontology), the [Cell Ontology](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#cell-ontology), and the [Cell Line Ontology](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#cell-line-ontology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGINAL TERM</th>\n",
       "      <th>UBERON ID</th>\n",
       "      <th>UBERON LABEL</th>\n",
       "      <th>CL ID</th>\n",
       "      <th>CL LABEL</th>\n",
       "      <th>CLO ID</th>\n",
       "      <th>CLO LABEL</th>\n",
       "      <th>UBERON MAPPING</th>\n",
       "      <th>CL MAPPING</th>\n",
       "      <th>CLO MAPPING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-431</td>\n",
       "      <td>UBERON_0000014</td>\n",
       "      <td>zone of skin</td>\n",
       "      <td>CL_0000066</td>\n",
       "      <td>epithelial cell</td>\n",
       "      <td>CLO_0001591</td>\n",
       "      <td>A431 cell</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A549</td>\n",
       "      <td>UBERON_0002048</td>\n",
       "      <td>lung</td>\n",
       "      <td>CL_0000141</td>\n",
       "      <td>epithelial cell of lung</td>\n",
       "      <td>CLO_0001601</td>\n",
       "      <td>A549 cell</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adipose - Subcutaneous</td>\n",
       "      <td>UBERON_0002190</td>\n",
       "      <td>subcutaneous adipose tissue</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>GTEX</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ORIGINAL TERM       UBERON ID                 UBERON LABEL  \\\n",
       "0                   A-431  UBERON_0000014                 zone of skin   \n",
       "1                    A549  UBERON_0002048                         lung   \n",
       "2  Adipose - Subcutaneous  UBERON_0002190  subcutaneous adipose tissue   \n",
       "\n",
       "        CL ID                 CL LABEL       CLO ID  CLO LABEL UBERON MAPPING  \\\n",
       "0  CL_0000066          epithelial cell  CLO_0001591  A431 cell         Manual   \n",
       "1  CL_0000141  epithelial cell of lung  CLO_0001601  A549 cell         Manual   \n",
       "2        None                     None         None       None           GTEX   \n",
       "\n",
       "  CL MAPPING CLO MAPPING  \n",
       "0     Manual      Manual  \n",
       "1     Manual      Manual  \n",
       "2       None        None  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back in mapped tissue/cell data\n",
    "mapping_data = pandas.read_excel(open(unprocessed_data_location + 'zooma_tissue_cell_mapping_04JAN2020.xlsx', 'rb'),\n",
    "                                 sheet_name='Concept_Mapping - 04JAN2020',\n",
    "                                 header=0)\n",
    "\n",
    "# convert NaN to None\n",
    "mapping_data.fillna('None', inplace=True)\n",
    "\n",
    "# preview data\n",
    "mapping_data.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:00<00:00, 2953.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'HPA_GTEx_TISSUE_CELL_MAP.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(mapping_data.iterrows(), total=mapping_data.shape[0]):\n",
    "        if row['UBERON ID'] != 'None':\n",
    "            outfile.write(str(row['ORIGINAL TERM']).strip() + '\\t' + str(row['UBERON ID']).strip() + '\\n')\n",
    "        if row['CL ID'] != 'None':\n",
    "            outfile.write(str(row['ORIGINAL TERM']).strip() + '\\t' + str(row['CL ID']).strip() + '\\n')\n",
    "        if row['CLO ID'] != 'None':\n",
    "            outfile.write(str(row['ORIGINAL TERM']).strip() + '\\t' + str(row['CLO ID']).strip() + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 337 edges\n"
     ]
    }
   ],
   "source": [
    "hpa_data = pandas.read_csv(processed_data_location + 'HPA_GTEx_TISSUE_CELL_MAP.txt',\n",
    "                           header = None,\n",
    "                           names=['TISSUE_CELL_TERM', 'ONTOLOGY_IDs'],\n",
    "                           delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} edges'.format(edge_count=len(hpa_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE_CELL_TERM</th>\n",
       "      <th>ONTOLOGY_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-431</td>\n",
       "      <td>UBERON_0000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-431</td>\n",
       "      <td>CL_0000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-431</td>\n",
       "      <td>CLO_0001591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TISSUE_CELL_TERM    ONTOLOGY_IDs\n",
       "0            A-431  UBERON_0000014\n",
       "1            A-431      CL_0000066\n",
       "2            A-431     CLO_0001591"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpa_data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Edge Data Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Genotype-Tissue Expression Project_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that contain protein coding genes\n",
    "gtex_genes = merged_data_clean.loc[merged_data_clean['gene_type_cleaned'].apply(lambda x: 'protein-coding' not in x.lower() and 'none' not in x.lower())]\n",
    "\n",
    "# merge gtex results with gene type data to allow filtering out of protein-coding genes\n",
    "merged_gtex = pandas.merge(gtex, gtex_genes, left_on='Description', right_on='symbol', how='left')\n",
    "\n",
    "# loop over data and re-organize - only keep results with tpm >= 1 and if gene symbol is not a protein-coding gene\n",
    "gtex_results = []\n",
    "\n",
    "for idx, row in tqdm(gtex.iterrows(), total=gtex.shape[0]):    \n",
    "    for col in list(gtex.columns)[2:]:\n",
    "        if row[col] >= 1.0:           \n",
    "            gtex_results += [[row['Name'], row['Description'], 'None', 'Evidence at transcript level', 'cell line' if 'Cells' in col else 'anatomy', col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Human Protein Atlas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpa_results = []\n",
    "\n",
    "for idx, row in tqdm(hpa.iterrows(), total=hpa.shape[0]):\n",
    "    if row['RNA tissue specific NX'] != 'None':\n",
    "        for x in row['RNA tissue specific NX'].split(';'):\n",
    "            hpa_results += [[row['Ensembl'], row['Gene'], row['Uniprot'], row['Evidence'], 'anatomy', x.split(':')[0]]]\n",
    "\n",
    "    if row['RNA cell line specific NX'] != 'None':\n",
    "        for x in row['RNA cell line specific NX'].split(';'):\n",
    "            hpa_results += [[row['Ensembl'], row['Gene'], row['Uniprot'], row['Evidence'], 'cell line', x.split(':')[0]]]\n",
    "\n",
    "    if row['RNA brain regional specific NX'] != 'None':\n",
    "        for x in row['RNA brain regional specific NX'].split(';'):\n",
    "            hpa_results += [[row['Ensembl'], row['Gene'], row['Uniprot'], row['Evidence'], 'anatomy', x.split(':')[0]]]\n",
    "\n",
    "    if row['RNA blood cell specific NX'] != 'None':\n",
    "        for x in row['RNA blood cell specific NX'].split(';'):\n",
    "            hpa_results += [[row['Ensembl'], row['Gene'], row['Uniprot'], row['Evidence'], 'anatomy', x.split(':')[0]]]\n",
    "\n",
    "    if row['RNA blood lineage specific NX'] != 'None':\n",
    "        for x in row['RNA blood lineage specific NX'].split(';'):\n",
    "            hpa_results += [[row['Ensembl'], row['Gene'], row['Uniprot'], row['Evidence'], 'anatomy', x.split(':')[0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write Results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'HPA_GTEX_RNA_GENE_PROTEIN_EDGES.txt', 'w') as outfile:\n",
    "    for res in tqdm(hpa_results + gtex_results):\n",
    "        outfile.write(res[0] + '\\t' + res[1] + '\\t' + res[2] + '\\t' + res[3] + '\\t' + res[4] + '\\t' + res[5] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 952962 edges\n"
     ]
    }
   ],
   "source": [
    "hpa_edges = pandas.read_csv(processed_data_location + 'HPA_GTEX_RNA_GENE_PROTEIN_EDGES.txt',\n",
    "                           header = None,\n",
    "                           names=['Ensembl_IDs', 'Gene_Symbols', 'Uniport_IDs', 'Evidence', 'Anatomy_Type', 'Anatomy'],\n",
    "                           low_memory=False,\n",
    "                           delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} edges'.format(edge_count=len(hpa_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ensembl_IDs</th>\n",
       "      <th>Gene_Symbols</th>\n",
       "      <th>Uniport_IDs</th>\n",
       "      <th>Evidence</th>\n",
       "      <th>Anatomy_Type</th>\n",
       "      <th>Anatomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>P04217</td>\n",
       "      <td>Evidence at protein level</td>\n",
       "      <td>anatomy</td>\n",
       "      <td>liver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>P04217</td>\n",
       "      <td>Evidence at protein level</td>\n",
       "      <td>cell line</td>\n",
       "      <td>HEK 293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>P04217</td>\n",
       "      <td>Evidence at protein level</td>\n",
       "      <td>cell line</td>\n",
       "      <td>Hep G2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>P04217</td>\n",
       "      <td>Evidence at protein level</td>\n",
       "      <td>cell line</td>\n",
       "      <td>REH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>P04217</td>\n",
       "      <td>Evidence at protein level</td>\n",
       "      <td>cell line</td>\n",
       "      <td>U-266/70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ensembl_IDs Gene_Symbols Uniport_IDs                   Evidence  \\\n",
       "0  ENSG00000121410         A1BG      P04217  Evidence at protein level   \n",
       "1  ENSG00000121410         A1BG      P04217  Evidence at protein level   \n",
       "2  ENSG00000121410         A1BG      P04217  Evidence at protein level   \n",
       "3  ENSG00000121410         A1BG      P04217  Evidence at protein level   \n",
       "4  ENSG00000121410         A1BG      P04217  Evidence at protein level   \n",
       "\n",
       "  Anatomy_Type   Anatomy  \n",
       "0      anatomy     liver  \n",
       "1    cell line   HEK 293  \n",
       "2    cell line    Hep G2  \n",
       "3    cell line       REH  \n",
       "4    cell line  U-266/70  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpa_edges.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### CREATE EDGE DATASETS  <a class=\"anchor\" id=\"create-edge-datasets\"></a>\n",
    "***\n",
    "***\n",
    "\n",
    "### Ontologies  <a class=\"anchor\" id=\"ontologies\"></a>\n",
    "***\n",
    "- [Protein Ontology](#protein-ontology)  \n",
    "- [Relations Ontology](#relations-ontology)  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Ontology <a class=\"anchor\" id=\"protein-ontology\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [protein-ontology](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#human-phenotype-ontology)  \n",
    "\n",
    "**Purpose:** This script downloads the [pr.owl](http://purl.obolibrary.org/obo/pr.owl) file from [ProConsortium.org](https://proconsortium.org/) in order to create a version of the ontology that contains only human proteins. This is achieved by performing forward and reverse breadth first search over all proteins which are `owl:subClassOf` [Homo sapiens protein](https://proconsortium.org/app/entry/PR%3A000029067/).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Output:**  \n",
    "- Human Protein Ontology ➞ [`human_pro.owl`](https://www.dropbox.com/s/jw8jksgnqbcz9sm/human_pro.owl?dl=1)\n",
    "- Classified Human Protein Ontology (Hermit) ➞ [`human_pro_closed.owl`](https://www.dropbox.com/s/6ux85agl95ja3wx/human_pro_closed.owl?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://purl.obolibrary.org/obo/pr.owl'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in ontology as graph (the ontology is large so this takes ~60 minutes) - 11,757,623 edges on 12/18/2019\n",
    "graph = Graph()\n",
    "graph.parse(unprocessed_data_location + 'pr.owl')\n",
    "\n",
    "print('There are {} edges in the ontology'.format(len(graph)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Ontology to Directed MulitGraph:**  \n",
    "In order to create a version of the ontology which includes all relevant human edges, we need to first convert the KG to a [directed multigraph](https://networkx.github.io/documentation/stable/reference/classes/multidigraph.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert RDF graph to multidigraph (the ontology is large so this takes ~45 minutes)\n",
    "networkx_mdg = rdflib_to_networkx_multidigraph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify Human Proteins:**   \n",
    "A list of human proteins is obtained by querying the ontology to return all ontology classes `only_in_taxon some Homo sapiens`. To expedite the query time, the following SPARQL query is run from the [ProConsortium](https://proconsortium.org/pro_sparql.shtml) SPARQL endpoint: \n",
    "\n",
    "```SPARQL\n",
    "PREFIX obo: <http://purl.obolibrary.org/obo/>\n",
    "\n",
    "SELECT ?PRO_term\n",
    "FROM <http://purl.obolibrary.org/obo/pr>\n",
    "WHERE {\n",
    "       ?PRO_term rdf:type owl:Class .\n",
    "       ?PRO_term rdfs:subClassOf ?restriction .\n",
    "       ?restriction owl:onProperty obo:RO_0002160 .\n",
    "       ?restriction owl:someValuesFrom obo:NCBITaxon_9606 .\n",
    "\n",
    "       # use this to filter-out things like hgnc ids\n",
    "       FILTER (regex(?PRO_term,\"http://purl.obolibrary.org/obo/*\")) .\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data - pro classes only_in_taxon some Homo sapiens (61,064 classes on 12/18/2019)\n",
    "url = 'http://sparql.proconsortium.org/virtuoso/sparql?query=PREFIX+obo%3A+%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2F%3E%0D%0ASELECT+%3FPRO_term%0D%0AFROM+%3Chttp%3A%2F%2Fpurl.obolibrary.org%2Fobo%2Fpr%3E%0D%0AWHERE%0D%0A%7B%0D%0A+++%3FPRO_term+rdf%3Atype+owl%3AClass+.%0D%0A+++%3FPRO_term+rdfs%3AsubClassOf+%3Frestriction+.%0D%0A+++%3Frestriction+owl%3AonProperty+obo%3ARO_0002160+.%0D%0A+++%3Frestriction+owl%3AsomeValuesFrom+obo%3ANCBITaxon_9606+.%0D%0A%0D%0A+++FILTER+%28regex%28%3FPRO_term%2C%22http%3A%2F%2Fpurl.obolibrary.org%2Fobo%2F*%22%29%29+.%0D%0A%0D%0A%7D%0D%0A&format=text%2Fhtml&debug='\n",
    "html = requests.get(url, allow_redirects=True).content\n",
    "\n",
    "# extract data from html table\n",
    "df_list = pandas.read_html(html)\n",
    "human_pro_classes = list(df_list[-1]['PRO_term'])\n",
    "\n",
    "print('There are {protein_count} human classes in the PRO ontology'.format(protein_count=len(human_pro_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct Human PRO:**   \n",
    "Now that we have all of the paths from the original graph that are relevant to humans, we can construct a human-only version of the PRotein ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new graph using bfs paths\n",
    "human_pro_graph = Graph()\n",
    "human_networkx_mdg = networkx.MultiDiGraph()\n",
    "\n",
    "for node in tqdm(human_pro_classes):\n",
    "    forward = list(networkx.edge_bfs(networkx_mdg, URIRef(node), orientation='original'))\n",
    "    reverse = list(networkx.edge_bfs(networkx_mdg, URIRef(node), orientation='reverse'))\n",
    "    \n",
    "    # add edges from forward and reverse bfs paths\n",
    "    for path in forward + reverse:\n",
    "        human_pro_graph.add((path[0], path[2], path[1]))\n",
    "        human_networkx_mdg.add_edge(path[0], path[1], path[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that the constructed ontology only has 1 component\n",
    "networkx.number_connected_components(human_networkx_mdg.to_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filtered ontology\n",
    "human_pro_graph.serialize(destination=unprocessed_data_location + 'human_pro.owl', format='xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify Ontology:**  \n",
    "To ensure that we have correclty built the new ontology, we run the hermit reasoner over it to ensure that there are no incomplete triples or inconsistent classes. In order to do this, we will call the reasoner using [OWLTools](https://github.com/owlcollab/owltools), which this script assumes has already been downloaded to the `../resources/lib` directory. The following arguments are then called to run the reasoner (from the command line):  \n",
    "\n",
    "```bash\n",
    "./resources/lib/owltools ./resources/unprocessed_data/human_pro_filtered.owl --reasoner hermit --run-reasoner --assert-implied -o ./resources/processed_data/human_pro_closed.owl\n",
    "```\n",
    "\n",
    "_**Note.** This step takes around 30-45 minutes to run. When run from the command line the reasoner determined that the ontology was consistent and 174 new axioms were inferrred (12/18/2019)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run reasoner -- RUN FROM COMMAND LINE NOT HERE\n",
    "# subprocess.run(['../../resources/lib/owltools',\n",
    "#                 '../../resources/unprocessed_data/human_pro_filtered.owl',\n",
    "#                 '--reasoner hermit',\n",
    "#                 '--run-reasoner',\n",
    "#                 '--assert-implied',\n",
    "#                 '--list-unsatisfiable',\n",
    "#                 '-o ./resources/processed_data/human_pro_closed.owl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine Cleaned Human PRO:**  \n",
    "Once we have cleaned the ontology we can get counts of components, nodes, edges, and then write the cleaned graph to the `../../resources/processed_data` repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of connected components\n",
    "pro_human_graph = Graph()\n",
    "pro_human_graph.parse(processed_data_location + 'human_pro_closed.owl')\n",
    "\n",
    "# get node and edge count\n",
    "edge_count = len(human_pro_graph)\n",
    "node_count = len(set([str(node) for edge in list(human_pro_graph) for node in edge[0::2]]))\n",
    "\n",
    "print('\\n The classified, filtered Human version of PRO contains {node} nodes and {edge} edges\\n'.format(node=node_count, edge=edge_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relations Ontology <a class=\"anchor\" id=\"relations-ontology\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [RO](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#relation-ontology)  \n",
    "\n",
    "**Purpose:** This script downloads the [ro.owl](http://purl.obolibrary.org/obo/ro.owl) file from [obofoundry.org](http://www.obofoundry.org/) in order to obtain all `ObjectProperties` and their inverse relations.  \n",
    "\n",
    "**Output:** \n",
    "- Relations and Inverse Relations ➞ [`INVERSE_RELATIONS.txt`](https://www.dropbox.com/s/sd8qlib8f6gqyz4/INVERSE_RELATIONS.txt?dl=1)\n",
    "- Relations and Labels ➞ [`RELATIONS_LABELS.txt`](https://www.dropbox.com/s/k2hm9p0r8l9ecj3/RELATIONS_LABELS.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://purl.obolibrary.org/obo/ro.owl'\n",
    "data_downloader(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_graph = Graph()\n",
    "ro_graph.parse(unprocessed_data_location + 'ro.owl')\n",
    "\n",
    "print('There are {} edges in the ontology'.format(len(ro_graph))) #5,669 edges on 12/15/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "**Identify Relations and Inverse Relations:**  \n",
    "Identify all relations and their inverse relations using the `owl:inverseOf` property. To make it easier to look up the inverse relations, each pair is listed twice, for example:  \n",
    "- [location of](http://www.ontobee.org/ontology/RO?iri=http://purl.obolibrary.org/obo/RO_0001015) `owl:inverseOf` [located in](http://www.ontobee.org/ontology/RO?iri=http://purl.obolibrary.org/obo/RO_0001025)  \n",
    "- [located in](http://www.ontobee.org/ontology/RO?iri=http://purl.obolibrary.org/obo/RO_0001025) `owl:inverseOf` [location of](http://www.ontobee.org/ontology/RO?iri=http://purl.obolibrary.org/obo/RO_0001015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./resources/relations_data/INVERSE_RELATIONS.txt', 'w') as outfile:\n",
    "    \n",
    "    # write column names\n",
    "    outfile.write('Relation' + '\\t' + 'Inverse_Relation' + '\\n')\n",
    "    \n",
    "    # manually add missing relations\n",
    "    outfile.write('RO_0000056' + '\\t' + 'RO_0000057' + '\\n') #participates_in/has_participant\n",
    "    outfile.write('RO_0000057' + '\\t' + 'RO_0000056' + '\\n') #participates_in/has_participant\n",
    "    outfile.write('RO_0000085' + '\\t' + 'RO_0000079' + '\\n') #has_function/function_of\n",
    "    outfile.write('RO_0000079' + '\\t' + 'RO_0000085' + '\\n') #has_function/function_of\n",
    "    outfile.write('RO_0001025' + '\\t' + 'RO_0001015' + '\\n') #located_in/has_location\n",
    "    outfile.write('RO_0001015' + '\\t' + 'RO_0001025' + '\\n') #located_in/has_location\n",
    "\n",
    "    # find inverse relations\n",
    "    for s, p, o in tqdm(ro_graph):\n",
    "        if 'owl#inverseOf' in str(p):\n",
    "            if 'RO' in str(s) and 'RO' in str(o):\n",
    "                outfile.write(str(s.split('/')[-1]) + '\\t' + str(o.split('/')[-1]) + '\\n')\n",
    "                outfile.write(str(o.split('/')[-1]) + '\\t' + str(s.split('/')[-1]) + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_data = pandas.read_csv('./resources/relations_data/INVERSE_RELATIONS.txt',\n",
    "                          header = 0,\n",
    "                          delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} RO Relations and Inverse Relations'.format(edge_count=len(ro_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Get Relations Labels:**  \n",
    "Identify all relations and their labels for use when building the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ro_graph.query(\n",
    "    \"\"\"SELECT DISTINCT ?p ?p_label\n",
    "           WHERE {\n",
    "              ?p rdf:type owl:ObjectProperty .\n",
    "              ?p rdfs:label ?p_label . }\n",
    "           \"\"\", initNs={\"rdf\": 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "                        \"rdfs\": 'http://www.w3.org/2000/01/rdf-schema#',\n",
    "                        \"owl\": 'http://www.w3.org/2002/07/owl#'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to file\n",
    "with open('./resources/relations_data/RELATIONS_LABELS.txt', 'w') as outfile:\n",
    "    \n",
    "    # write column names\n",
    "    outfile.write('Relation' + '\\t' + 'Label' + '\\n')\n",
    "\n",
    "    for p, p_label in list(results):\n",
    "        outfile.write(str(p).split('/')[-1] + '\\t' + str(p_label) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_data_label = pandas.read_csv('./resources/relations_data/RELATIONS_LABELS.txt',\n",
    "                                header = 0,\n",
    "                                delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} RO Relations and Labels'.format(edge_count=len(ro_data_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_data_label.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### Linked Data <a class=\"anchor\" id=\"linked-data\"></a>\n",
    "***\n",
    "* [Clinvar Variant-Diseases and Phenotypes](#clinvar-variant)\n",
    "* [NCBI Gene Protein-Coding Genes and Proteins](#ncbi-protein-coding-genes)  \n",
    "* [Reactome Chemical-Complex Data](#reactome-chemical-complex)  \n",
    "* [Reactome Complex-Complex Data](#reactome-complex-complex)  \n",
    "* [Reactome Protein-Complex Data](#reactome-protein-complex)  \n",
    "* [Uniprot Protein-Cofactor and Protein-Catalyst](#uniprot-protein-cofactorcatalyst)  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinvar Variant-Diseases and Phenotypes <a class=\"anchor\" id=\"clinvar-variant\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Clinvar](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#clinvar)  \n",
    "\n",
    "**Purpose:** This script downloads the [variant_summary.txt](ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz) file from [CLinVar](https://www.ncbi.nlm.nih.gov/clinvar/) in order to create the following edges:  \n",
    "- gene-variant  \n",
    "- variant-disease  \n",
    "- variant-phenotype  \n",
    "\n",
    "**Output:** [`CLINVAR_VARIANT_GENE_DISEASE_PHENOTYPE_EDGES.txt`](https://www.dropbox.com/s/1doj3lj46ufgdpd/CLINVAR_VARIANT_GENE_DISEASE_PHENOTYPE_EDGES.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and provided labels (needed to unnest data)\n",
    "clinvar_data = pandas.read_csv(unprocessed_data_location + 'variant_summary.txt',\n",
    "                               header = 0,\n",
    "                               delimiter = '\\t',\n",
    "                               low_memory=False)\n",
    "\n",
    "# replace NaN with 'None'\n",
    "clinvar_data.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode nested data\n",
    "explode_df_clinvar = explode(clinvar_data.copy(), ['PhenotypeIDS'], ';')\n",
    "explode_df_clinvar = explode(explode_df_clinvar.copy(), ['PhenotypeIDS'], ',')\n",
    "\n",
    "# edit column formatting\n",
    "explode_df_clinvar['PhenotypeIDS'].replace('Orphanet:ORPHA','ORPHA:', inplace=True, regex=True)\n",
    "explode_df_clinvar['PhenotypeIDS'].replace('Human Phenotype Ontology:HP:','HP_', inplace=True, regex=True)\n",
    "\n",
    "# write data\n",
    "explode_df_clinvar.to_csv(processed_data_location + 'CLINVAR_VARIANT_GENE_DISEASE_PHENOTYPE_EDGES.txt', header = True, sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3587975 variant edges\n"
     ]
    }
   ],
   "source": [
    "print('There are {edge_count} variant edges'.format(edge_count=len(explode_df_clinvar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AlleleID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>GeneSymbol</th>\n",
       "      <th>HGNC_ID</th>\n",
       "      <th>ClinicalSignificance</th>\n",
       "      <th>ClinSigSimple</th>\n",
       "      <th>LastEvaluated</th>\n",
       "      <th>RS# (dbSNP)</th>\n",
       "      <th>...</th>\n",
       "      <th>ReferenceAllele</th>\n",
       "      <th>AlternateAllele</th>\n",
       "      <th>Cytogenetic</th>\n",
       "      <th>ReviewStatus</th>\n",
       "      <th>NumberSubmitters</th>\n",
       "      <th>Guidelines</th>\n",
       "      <th>TestedInGTR</th>\n",
       "      <th>OtherIDs</th>\n",
       "      <th>SubmitterCategories</th>\n",
       "      <th>VariationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15228</td>\n",
       "      <td>deletion</td>\n",
       "      <td>NM_001017995.3(SH3PXD2B):c.969del (p.Arg324fs)</td>\n",
       "      <td>285590</td>\n",
       "      <td>SH3PXD2B</td>\n",
       "      <td>HGNC:29242</td>\n",
       "      <td>Pathogenic/Likely pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 01, 2017</td>\n",
       "      <td>794728006</td>\n",
       "      <td>...</td>\n",
       "      <td>GC</td>\n",
       "      <td>G</td>\n",
       "      <td>5q35.1</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>OMIM Allelic Variant:613293.0002</td>\n",
       "      <td>3</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15228</td>\n",
       "      <td>deletion</td>\n",
       "      <td>NM_001017995.3(SH3PXD2B):c.969del (p.Arg324fs)</td>\n",
       "      <td>285590</td>\n",
       "      <td>SH3PXD2B</td>\n",
       "      <td>HGNC:29242</td>\n",
       "      <td>Pathogenic/Likely pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 01, 2017</td>\n",
       "      <td>794728006</td>\n",
       "      <td>...</td>\n",
       "      <td>GC</td>\n",
       "      <td>G</td>\n",
       "      <td>5q35.1</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>OMIM Allelic Variant:613293.0002</td>\n",
       "      <td>3</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15228</td>\n",
       "      <td>deletion</td>\n",
       "      <td>NM_001017995.3(SH3PXD2B):c.969del (p.Arg324fs)</td>\n",
       "      <td>285590</td>\n",
       "      <td>SH3PXD2B</td>\n",
       "      <td>HGNC:29242</td>\n",
       "      <td>Pathogenic/Likely pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jun 01, 2017</td>\n",
       "      <td>794728006</td>\n",
       "      <td>...</td>\n",
       "      <td>GC</td>\n",
       "      <td>G</td>\n",
       "      <td>5q35.1</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>OMIM Allelic Variant:613293.0002</td>\n",
       "      <td>3</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15229</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_001017995.3(SH3PXD2B):c.127C&gt;T (p.Arg43Trp)</td>\n",
       "      <td>285590</td>\n",
       "      <td>SH3PXD2B</td>\n",
       "      <td>HGNC:29242</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Feb 12, 2010</td>\n",
       "      <td>267607046</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>5q35.1</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>OMIM Allelic Variant:613293.0003,UniProtKB (pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15229</td>\n",
       "      <td>single nucleotide variant</td>\n",
       "      <td>NM_001017995.3(SH3PXD2B):c.127C&gt;T (p.Arg43Trp)</td>\n",
       "      <td>285590</td>\n",
       "      <td>SH3PXD2B</td>\n",
       "      <td>HGNC:29242</td>\n",
       "      <td>Pathogenic</td>\n",
       "      <td>1</td>\n",
       "      <td>Feb 12, 2010</td>\n",
       "      <td>267607046</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>5q35.1</td>\n",
       "      <td>no assertion criteria provided</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>OMIM Allelic Variant:613293.0003,UniProtKB (pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   #AlleleID                       Type  \\\n",
       "0      15228                   deletion   \n",
       "1      15228                   deletion   \n",
       "2      15228                   deletion   \n",
       "3      15229  single nucleotide variant   \n",
       "4      15229  single nucleotide variant   \n",
       "\n",
       "                                             Name  GeneID GeneSymbol  \\\n",
       "0  NM_001017995.3(SH3PXD2B):c.969del (p.Arg324fs)  285590   SH3PXD2B   \n",
       "1  NM_001017995.3(SH3PXD2B):c.969del (p.Arg324fs)  285590   SH3PXD2B   \n",
       "2  NM_001017995.3(SH3PXD2B):c.969del (p.Arg324fs)  285590   SH3PXD2B   \n",
       "3  NM_001017995.3(SH3PXD2B):c.127C>T (p.Arg43Trp)  285590   SH3PXD2B   \n",
       "4  NM_001017995.3(SH3PXD2B):c.127C>T (p.Arg43Trp)  285590   SH3PXD2B   \n",
       "\n",
       "      HGNC_ID          ClinicalSignificance  ClinSigSimple LastEvaluated  \\\n",
       "0  HGNC:29242  Pathogenic/Likely pathogenic              1  Jun 01, 2017   \n",
       "1  HGNC:29242  Pathogenic/Likely pathogenic              1  Jun 01, 2017   \n",
       "2  HGNC:29242  Pathogenic/Likely pathogenic              1  Jun 01, 2017   \n",
       "3  HGNC:29242                    Pathogenic              1  Feb 12, 2010   \n",
       "4  HGNC:29242                    Pathogenic              1  Feb 12, 2010   \n",
       "\n",
       "   RS# (dbSNP)  ... ReferenceAllele AlternateAllele Cytogenetic  \\\n",
       "0    794728006  ...              GC               G      5q35.1   \n",
       "1    794728006  ...              GC               G      5q35.1   \n",
       "2    794728006  ...              GC               G      5q35.1   \n",
       "3    267607046  ...               G               A      5q35.1   \n",
       "4    267607046  ...               G               A      5q35.1   \n",
       "\n",
       "                     ReviewStatus NumberSubmitters Guidelines TestedInGTR  \\\n",
       "0  no assertion criteria provided                3       None           N   \n",
       "1  no assertion criteria provided                3       None           N   \n",
       "2  no assertion criteria provided                3       None           N   \n",
       "3  no assertion criteria provided                1       None           N   \n",
       "4  no assertion criteria provided                1       None           N   \n",
       "\n",
       "                                            OtherIDs SubmitterCategories  \\\n",
       "0                   OMIM Allelic Variant:613293.0002                   3   \n",
       "1                   OMIM Allelic Variant:613293.0002                   3   \n",
       "2                   OMIM Allelic Variant:613293.0002                   3   \n",
       "3  OMIM Allelic Variant:613293.0003,UniProtKB (pr...                   1   \n",
       "4  OMIM Allelic Variant:613293.0003,UniProtKB (pr...                   1   \n",
       "\n",
       "   VariationID  \n",
       "0          189  \n",
       "1          189  \n",
       "2          189  \n",
       "3          190  \n",
       "4          190  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "explode_df_clinvar.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCBI Gene Protein-Coding Gene-Protein <a class=\"anchor\" id=\"ncbi-protein-coding-genes\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Uniprot](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#uniprot-knowledgebase) \n",
    "\n",
    "**Purpose:** This script utilizes the merged data created in the [Human-Transcript, Gene, and Protein Identifier Mapping](#Human-Transcript,-Gene,-and-Protein-Identifier-Mapping) subsection in order to create the following edges:  \n",
    "- gene-protein\n",
    "\n",
    "**Output:** [`PROTEIN_CODING_GENES_PROTEINS.txt`](https://www.dropbox.com/s/79ce6oe68jt72ph/PROTEIN_CODING_GENES_PROTEINS.txt?dl=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-dup data\n",
    "df_ens = merged_data_clean.drop_duplicates(subset=['entrez_id', 'pro_id'], keep='first', inplace=False) \n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'PROTEIN_CODING_GENES_PROTEINS.txt', 'w') as outfile:\n",
    "    for idx, row in tqdm(df_ens.iterrows(), total=df_ens.shape[0]):\n",
    "        if (row['entrez_id'] != 'None' and row['pro_id'] != 'None') and row['gene_type'] == 'protein-coding': \n",
    "            outfile.write(row['entrez_id'].strip() + '\\t' + row['pro_id'].replace('PR:', 'PR_').strip() + '\\t' + row['gene_type_cleaned'] + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37569 protein-coding gene edges\n"
     ]
    }
   ],
   "source": [
    "hpe_data = pandas.read_csv(processed_data_location + 'PROTEIN_CODING_GENES_PROTEINS.txt',\n",
    "                           header = None,\n",
    "                           names=['Entrez_Gene_IDs', 'Protein_Ontology_IDs', \"Gene_Type\"],\n",
    "                           delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} protein-coding gene edges'.format(edge_count=len(hpe_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entrez_Gene_IDs</th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>Gene_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79501</td>\n",
       "      <td>PR_000011836</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79501</td>\n",
       "      <td>PR_Q8NH21</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>729759</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>729759</td>\n",
       "      <td>PR_Q6IEY1</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81399</td>\n",
       "      <td>PR_000011834</td>\n",
       "      <td>protein-coding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Entrez_Gene_IDs Protein_Ontology_IDs       Gene_Type\n",
       "0           79501         PR_000011836  protein-coding\n",
       "1           79501            PR_Q8NH21  protein-coding\n",
       "2          729759         PR_000011834  protein-coding\n",
       "3          729759            PR_Q6IEY1  protein-coding\n",
       "4           81399         PR_000011834  protein-coding"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpe_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactome Chemical-Complex Data <a class=\"anchor\" id=\"reactome-chemical-complex\"></a>\n",
    "\n",
    "**Data Souurce Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#reactome-pathway-database)  \n",
    "\n",
    "**Purpose:** This script downloads the [ComplexParticipantsPubMedIdentifiers_human.txt](https://reactome.org/download/current/ComplexParticipantsPubMedIdentifiers_human.txt) file from [Reactome](https://reactome.orgt) in order to create the following edges:  \n",
    "- chemical-complex  \n",
    "\n",
    "**Output:** [`REACTOME_CHEMICAL_COMPLEX.txt`](https://www.dropbox.com/s/qoetjt0vfy6qb3y/REACTOME_CHEMICAL_COMPLEX.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "data = open(unprocessed_data_location + 'ComplexParticipantsPubMedIdentifiers_human.txt').readlines()\n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'REACTOME_CHEMICAL_COMPLEX.txt', 'w') as outfile:\n",
    "    for line in tqdm(data[1:]):\n",
    "        row = line.split('\\t')\n",
    "        \n",
    "        if (row[0].strip().startswith('R-HSA') or row[0].strip().startswith('R-ALL')):\n",
    "            # find all proteins in a complex\n",
    "            for x in row[2].split('|'):\n",
    "                if x.startswith('chebi:'):            \n",
    "                    outfile.write(x.replace('chebi:', 'CHEBI_') + '\\t' + row[0].strip() + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5589 chemical-complex edges\n"
     ]
    }
   ],
   "source": [
    "cc1_data = pandas.read_csv(processed_data_location + 'REACTOME_CHEMICAL_COMPLEX.txt',\n",
    "                           header = None,\n",
    "                           names=['CHEBI_IDs', 'Reactome_IDs'],\n",
    "                           delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} chemical-complex edges'.format(edge_count=len(cc1_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHEBI_IDs</th>\n",
       "      <th>Reactome_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEBI_24505</td>\n",
       "      <td>R-HSA-1006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEBI_28879</td>\n",
       "      <td>R-HSA-1006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEBI_59888</td>\n",
       "      <td>R-HSA-1013011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEBI_59888</td>\n",
       "      <td>R-HSA-1013017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEBI_29105</td>\n",
       "      <td>R-HSA-109266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHEBI_IDs   Reactome_IDs\n",
       "0  CHEBI_24505  R-HSA-1006173\n",
       "1  CHEBI_28879  R-HSA-1006173\n",
       "2  CHEBI_59888  R-HSA-1013011\n",
       "3  CHEBI_59888  R-HSA-1013017\n",
       "4  CHEBI_29105   R-HSA-109266"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc1_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactome Complex-Complex Data <a class=\"anchor\" id=\"reactome-complex-complex\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#reactome-pathway-database)  \n",
    "\n",
    "**Purpose:** This script downloads the [ComplexParticipantsPubMedIdentifiers_human.txt](https://reactome.org/download/current/ComplexParticipantsPubMedIdentifiers_human.txt) file from [Reactome](https://reactome.orgt) in order to create the following edges:  \n",
    "- complex-complex  \n",
    "\n",
    "**Output:** [`REACTOME_COMPLEX_COMPLEX.txt`](https://www.dropbox.com/s/sojaq8u3hwfw4jz/REACTOME_COMPLEX_COMPLEX.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label dictionary\n",
    "labels = pandas.read_csv(unprocessed_data_location + 'ComplexParticipantsPubMedIdentifiers_human.txt',\n",
    "                         header = 0,\n",
    "                         delimiter = '\\t')\n",
    "\n",
    "# convert to dictionary\n",
    "label_dict = {row[0]:row[1] for idx, row in labels.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "data = open(unprocessed_data_location + 'ComplexParticipantsPubMedIdentifiers_human.txt').readlines()\n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'REACTOME_COMPLEX_COMPLEX.txt', 'w') as outfile:\n",
    "    for line in tqdm(data[1:]):\n",
    "        row = line.split('\\t')\n",
    "        \n",
    "        if row[0].strip().startswith('R-HSA'):\n",
    "            # find all complexes\n",
    "            for x in row[3].split('|'):\n",
    "                if (x.startswith('R-HSA-') or x.startswith('R-ALL-')) and x.strip() in label_dict.keys():            \n",
    "                    outfile.write(row[0].strip() + '\\t' + x.strip() + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13606 complex-complex edges\n"
     ]
    }
   ],
   "source": [
    "cc_data = pandas.read_csv(processed_data_location + 'REACTOME_COMPLEX_COMPLEX.txt',\n",
    "                          header = None,\n",
    "                          names=['Reactome_Complex_u', 'Reactome_Complex_v'],\n",
    "                          delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} complex-complex edges'.format(edge_count=len(cc_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reactome_Complex_u</th>\n",
       "      <th>Reactome_Complex_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-HSA-1008206</td>\n",
       "      <td>R-HSA-1008229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R-HSA-1013011</td>\n",
       "      <td>R-HSA-1013017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R-HSA-1013011</td>\n",
       "      <td>R-HSA-1013019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R-HSA-1013011</td>\n",
       "      <td>R-HSA-420698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R-HSA-1013011</td>\n",
       "      <td>R-HSA-420748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reactome_Complex_u Reactome_Complex_v\n",
       "0      R-HSA-1008206      R-HSA-1008229\n",
       "1      R-HSA-1013011      R-HSA-1013017\n",
       "2      R-HSA-1013011      R-HSA-1013019\n",
       "3      R-HSA-1013011       R-HSA-420698\n",
       "4      R-HSA-1013011       R-HSA-420748"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactome Complex-Pathway Data <a class=\"anchor\" id=\"reactome-complex-pathway\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#reactome-pathway-database)  \n",
    "\n",
    "**Purpose:** This script downloads the [Complex_2_Pathway_human.txt](https://reactome.org/download/current/Complex_2_Pathway_human.txt) file from [Reactome](https://reactome.orgt) in order to create the following edges:  \n",
    "- complex-pathway  \n",
    "\n",
    "**Output:** [`REACTOME_COMPLEX_PATHWAY.txt`](https://www.dropbox.com/s/my03w16fjw7bt20/REACTOME_COMPLEX_PATHWAY.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://reactome.org/download/current/Complex_2_Pathway_human.txt'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "data = open(unprocessed_data_location + 'Complex_2_Pathway_human.txt').readlines()\n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'REACTOME_COMPLEX_PATHWAY.txt', 'w') as outfile:\n",
    "    for line in tqdm(data[1:]):\n",
    "        row = line.split('\\t')\n",
    "        if row[0].startswith('R-HSA-'):            \n",
    "            outfile.write(row[0].strip() + '\\t' + row[1].strip() + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previewed Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20480 complex-pathway edges\n"
     ]
    }
   ],
   "source": [
    "cp_data = pandas.read_csv(processed_data_location + 'REACTOME_COMPLEX_PATHWAY.txt',\n",
    "                          header = None,\n",
    "                          names=['Reactome_Complex', 'Reactome_Pathway'],\n",
    "                          delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} complex-pathway edges'.format(edge_count=len(cp_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reactome_Complex</th>\n",
       "      <th>Reactome_Pathway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-HSA-1006173</td>\n",
       "      <td>R-HSA-977606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R-HSA-1008206</td>\n",
       "      <td>R-HSA-983231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R-HSA-1008229</td>\n",
       "      <td>R-HSA-983231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R-HSA-1008252</td>\n",
       "      <td>R-HSA-983231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R-HSA-1011577</td>\n",
       "      <td>R-HSA-983231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reactome_Complex Reactome_Pathway\n",
       "0    R-HSA-1006173     R-HSA-977606\n",
       "1    R-HSA-1008206     R-HSA-983231\n",
       "2    R-HSA-1008229     R-HSA-983231\n",
       "3    R-HSA-1008252     R-HSA-983231\n",
       "4    R-HSA-1011577     R-HSA-983231"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactome Protein-Complex Data <a class=\"anchor\" id=\"reactome-protein-complex\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#reactome-pathway-database)  \n",
    "\n",
    "**Purpose:** This script downloads the [ComplexParticipantsPubMedIdentifiers_human.txt](https://reactome.org/download/current/ComplexParticipantsPubMedIdentifiers_human.txt) file from [Reactome](https://reactome.org) in order to create the following edges:  \n",
    "- protein-complex\n",
    "\n",
    "**Output:** [`REACTOME_PROTEIN_COMPLEX.txt`](https://www.dropbox.com/s/7meu0cdz1mrnsz7/REACTOME_PROTEIN_COMPLEX.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://reactome.org/download/current/ComplexParticipantsPubMedIdentifiers_human.txt'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "data = open(unprocessed_data_location + 'ComplexParticipantsPubMedIdentifiers_human.txt').readlines()\n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'REACTOME_PROTEIN_COMPLEX.txt', 'w') as outfile:\n",
    "    for line in tqdm(data):\n",
    "        row = line.split('\\t')\n",
    "        \n",
    "        if row[0].strip().startswith('R-HSA'):\n",
    "            # find all proteins in a complex\n",
    "            for x in row[2].split('|'):\n",
    "                if x.startswith('uniprot:'):            \n",
    "                    outfile.write(x.split(':')[-1].strip() + '\\t' + row[0].strip() + '\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91201 protein-complex edges\n"
     ]
    }
   ],
   "source": [
    "pc_data = pandas.read_csv(processed_data_location + 'REACTOME_PROTEIN_COMPLEX.txt',\n",
    "                       header = None,\n",
    "                       names=['Uniprot_Protein', 'Reactome_Complex'],\n",
    "                       delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} protein-complex edges'.format(edge_count=len(pc_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_Protein</th>\n",
       "      <th>Reactome_Complex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P08603</td>\n",
       "      <td>R-HSA-1006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q16621</td>\n",
       "      <td>R-HSA-1008206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9ULX9</td>\n",
       "      <td>R-HSA-1008206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O15525</td>\n",
       "      <td>R-HSA-1008206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O60675</td>\n",
       "      <td>R-HSA-1008206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Uniprot_Protein Reactome_Complex\n",
       "0          P08603    R-HSA-1006173\n",
       "1          Q16621    R-HSA-1008206\n",
       "2          Q9ULX9    R-HSA-1008206\n",
       "3          O15525    R-HSA-1008206\n",
       "4          O60675    R-HSA-1008206"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniprot  Protein-Cofactor and Protein-Catalyst <a class=\"anchor\" id=\"uniprot-protein-cofactorcatalyst\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Uniprot](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#uniprot-knowledgebase)  \n",
    "\n",
    "**Purpose:** This script downloads the [uniprot-cofactor-catalyst.tab](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#uniprot-knowledgebase) file from the [Uniprot Knowledge Base](https://www.uniprot.org) in order to create the following edges:  \n",
    "- protein-cofactor  \n",
    "- protein-catalyst  \n",
    "\n",
    "**Output:**  \n",
    "- protein-cofactor ➞ [`UNIPROT_PROTEIN_COFACTOR.txt`](https://www.dropbox.com/s/ij9t89botd8nmmj/UNIPROT_PROTEIN_COFACTOR.txt?dl=1)\n",
    "- protein-catalyst ➞ [`UNIPROT_PROTEIN_CATALYST.txt`](https://www.dropbox.com/s/pvopvs0iq8x3oq2/UNIPROT_PROTEIN_CATALYST.txt?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.uniprot.org/uniprot/?query=&fil=organism%3A%22Homo%20sapiens%20(Human)%20%5B9606%5D%22&columns=id%2Centry%20name%2Creviewed%2Cdatabase(PRO)%2Cchebi(Cofactor)%2Cchebi(Catalytic%20activity)&format=tab'\n",
    "data_downloader(url, unprocessed_data_location, 'uniprot-cofactor-catalyst.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(unprocessed_data_location + 'uniprot-cofactor-catalyst.tab').readlines()\n",
    "\n",
    "# reformat data and write it out\n",
    "with open(processed_data_location + 'UNIPROT_PROTEIN_COFACTOR.txt', 'w') as outfile1, open(processed_data_location + 'UNIPROT_PROTEIN_CATALYST.txt', 'w') as outfile2:\n",
    "    for line in tqdm(data):\n",
    "\n",
    "        # get cofactors\n",
    "        if 'CHEBI' in line.split('\\t')[4]: \n",
    "            for i in line.split('\\t')[4].split(';'):\n",
    "                chebi = i.split('[')[-1].replace(']', '').replace(':', '_')\n",
    "                outfile1.write('PR_' + line.split('\\t')[3].strip(';') + '\\t' + chebi + '\\n')\n",
    "        \n",
    "        # get catalysts\n",
    "        if 'CHEBI' in line.split('\\t')[5]:       \n",
    "            for i in line.split('\\t')[5].split(';'):\n",
    "                chebi = i.split('[')[-1].replace(']', '').replace(':', '_')\n",
    "                outfile2.write('PR_' + line.split('\\t')[3].strip(';') + '\\t' + chebi + '\\n')\n",
    "\n",
    "outfile1.close()\n",
    "outfile2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview Processed Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Preview Cofactor Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5577 protein-cofactor edges\n"
     ]
    }
   ],
   "source": [
    "pcp1_data = pandas.read_csv(processed_data_location + 'UNIPROT_PROTEIN_COFACTOR.txt',\n",
    "                            header = None,\n",
    "                            names=['Protein_Ontology_IDs', 'CHEBI_IDs'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} protein-cofactor edges'.format(edge_count=len(pcp1_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>CHEBI_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR_Q9BRS2</td>\n",
       "      <td>CHEBI_18420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR_Q05823</td>\n",
       "      <td>CHEBI_18420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR_Q05823</td>\n",
       "      <td>CHEBI_29035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR_Q13472</td>\n",
       "      <td>CHEBI_18420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR_Q9BXA7</td>\n",
       "      <td>CHEBI_18420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_Ontology_IDs    CHEBI_IDs\n",
       "0            PR_Q9BRS2  CHEBI_18420\n",
       "1            PR_Q05823  CHEBI_18420\n",
       "2            PR_Q05823  CHEBI_29035\n",
       "3            PR_Q13472  CHEBI_18420\n",
       "4            PR_Q9BXA7  CHEBI_18420"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp1_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Preview Catalyst Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59863 protein-catalyst edges\n"
     ]
    }
   ],
   "source": [
    "pcp2_data = pandas.read_csv(processed_data_location + 'UNIPROT_PROTEIN_CATALYST.txt',\n",
    "                            header = None,\n",
    "                            names=['Protein_Ontology_IDs', 'CHEBI_IDs'],\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "print('There are {edge_count} protein-catalyst edges'.format(edge_count=len(pcp2_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_Ontology_IDs</th>\n",
       "      <th>CHEBI_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR_Q9NP80</td>\n",
       "      <td>CHEBI_15377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR_Q9NP80</td>\n",
       "      <td>CHEBI_15378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR_Q9NP80</td>\n",
       "      <td>CHEBI_28868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR_Q9NP80</td>\n",
       "      <td>CHEBI_16870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR_Q9NP80</td>\n",
       "      <td>CHEBI_58168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_Ontology_IDs    CHEBI_IDs\n",
       "0            PR_Q9NP80  CHEBI_15377\n",
       "1            PR_Q9NP80  CHEBI_15378\n",
       "2            PR_Q9NP80  CHEBI_28868\n",
       "3            PR_Q9NP80  CHEBI_16870\n",
       "4            PR_Q9NP80  CHEBI_58168"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcp2_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "### INSTANCE METADATA <a class=\"anchor\" id=\"create-instance-metadata\"></a>\n",
    "***\n",
    "\n",
    "**Data Source Wiki Page:** [Dependencies](https://github.com/callahantiff/PheKnowLator/wiki/Dependencies/#node-metadata) \n",
    "\n",
    "**Purpose:** The goal of this section is to obtain metadata for each instance data source used in the knowledge graph. To determine which of the edges contains instance data, the [`Master_Edge_List_Dict.json`](https://www.dropbox.com/s/4j0vrwx26dh8hd1/Master_Edge_List_Dict.json?dl=1) file is parsed and saved to a nested dictionary (see example below). \n",
    "\n",
    "```python\n",
    "{\n",
    "  'complex': {\n",
    "              'chemical-complex': [[node_1, node_2]...[node_n, node_m]],\n",
    "              'complex-complex':  [[node_1, node_2]...[node_n, node_m]],\n",
    "              'complex-pathway':  [[node_1, node_2]...[node_n, node_m]],\n",
    "              },\n",
    "     'gene': {\n",
    "                'chemical-gene':  [[node_1, node_2]...[node_n, node_m]],\n",
    "                 'gene-disease':  [[node_1, node_2]...[node_n, node_m]],\n",
    "              }\n",
    "}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Once this dictionary is created, each major data type (examples shown in the list below) will be processed. For **[`Release V2.0.0`](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)**, the following are instance data and require the compiling of metadata:\n",
    "- [Genes](#gene-metadata)\n",
    "- [RNA](#rna-metadata)\n",
    "- [Pathways](#pathway-metadata)\n",
    "- [Complexes](#complex-metadata)\n",
    "- [Reactions](#reaction-metadata)\n",
    "- [Variants](#variant-metadata)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "____\n",
    "\n",
    "**Metadata:** The <u>metadata</u> we will gather includes:  \n",
    "\n",
    "| **Metadata Type** | **Definition** | **Example Node**  | **Example Node Metadata** | \n",
    "| :---: | :---: | :---: | :---: | \n",
    "| Label | The primary label or name for the node | `R-HSA-1006173` | \"CFH:Host cell surface\" |       \n",
    "| Description | A definition or other useful details about the node | `rs794727058` | This `germline` `single nucleotide variant (allele alteration: C➞T)` located on chromosome `5 (GRCh38: NC_000005.10, start/stop positions (126555930/126555930))` with `pathogenic` clinical significance and a last review date of `2/23/2015` (review status: `criteria provided, single submitter`). |        \n",
    "| Synonym | Alternative terms used for a node | `81399` | \"OR1-1, OR7-21\" |           \n",
    "\n",
    "<br>\n",
    "\n",
    "The metadata information will be used to create the following edges in the knowledge graph:  \n",
    "- **Label** ➞ node `rdfs:label`  \n",
    "- **Description** ➞ node `obo:IAO_0000115` description \n",
    "- **Synonyms** ➞ node `oboInOwl:hasExactSynonym` synonym \n",
    "\n",
    "<br>\n",
    "\n",
    "*<b>NOTE.</b> All node metadata datasets are written to the `node_data` directory. The algorithm will look for data in this directory and if it is not there, then no node metadata will be created.*\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Metadata Dictionaries\n",
    "***\n",
    "\n",
    "**Purpose:** To create the resources needed in order to create metadata dictionaries, which are in turn used to obtain metadata for instance data nodes. This process has the following steps:\n",
    "\n",
    "**1. [Identify Instance Data Nodes](#identify-instance-data-nodes):** In order to automatically obtain the list of edges that include an instance data source and their corresponding edge lists, the `Master_Edge_List_Dict.json` is read in and processed.  \n",
    "  - <u>Input Data</u>: [`Master_Edge_List_Dict.json`](./resources/Master_Edge_List_Dict.json)  \n",
    "\n",
    "<br>\n",
    "\n",
    "**2. [Generate Metadata Dictionaries](#generate-metadata-dictionaries):** In order to efficiently obtain metadata for the instance data nodes identified in _Step 1_, we first read in the data for each node type (i.e. genes, rna, complexes, pathways, reactions, and variants) and convert it into a dictionary. Then, each metadata dictionary is saved to a `master_metadata_dictioanry`, keyed by node type.\n",
    "  - <u>Input Datasets</u>:  \n",
    "    - Genes ➞ [`Homo_sapiens.gene_info`](https://www.dropbox.com/s/vazlmzxydgv6xzz/Homo_sapiens.gene_info?dl=1)    \n",
    "    - RNA ➞ [`Merged_Human_Ensembl_Entrez_Uniprot_Identifiers.txt`](https://www.dropbox.com/s/l79166x1fx6vc4l/Merged_Human_Ensembl_Entrez_Uniprot_Identifiers.txt?dl=1) \n",
    "    - Complexes ➞ [`reactome2py API`](https://github.com/reactome/reactome2py)  \n",
    "    - Pathways ➞ [`reactome2py API`](https://github.com/reactome/reactome2py)  \n",
    "    - Reactions ➞ [`reactome2py API`](https://github.com/reactome/reactome2py)  \n",
    "    - Variants ➞ [`variant_summary.txt.gz`](ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz)  \n",
    "\n",
    "<br>\n",
    "\n",
    "**3. [Write Metadata Files](#write-metadata-files):** The Instance data node dictionary from _Step 1_ and metadata dictionaries from _Step 2_ are used to write `.txt` files for all `edge-type` data included in the instance node dictionary.\n",
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Instance Data Nodes  <a class=\"anchor\" id=\"identify-instance-data-nodes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data files for each edge type\n",
    "edge_data = json.load(open('./resources/Master_Edge_List_Dict.json', 'r'))\n",
    "edge_dict = {key:[edge_data[key]['data_type'], edge_data[key]['edge_list']] for key in edge_data.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort Data:** For all edges in the `edge_dict()` that include instance data, we create a new dictionary where each edge type is further organized by node from the edge type that references the instance data (e.g. from the `chemical-gene` edge type, the `gene` node references instance data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 51797.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# sort data files\n",
    "metadata_file_info = {}\n",
    "\n",
    "for edge in tqdm(edge_dict.keys()): \n",
    "    if 'instance' in edge_dict[edge][0]:\n",
    "        \n",
    "        # get instance type\n",
    "        inst_type = edge.split('-')[edge_dict[edge][0].split('-').index('instance')]\n",
    "        \n",
    "        # read in data\n",
    "        if inst_type in metadata_file_info.keys(): \n",
    "            metadata_file_info[inst_type][edge] = {}\n",
    "            metadata_file_info[inst_type][edge]['data'] = edge_dict[edge][1]\n",
    "            metadata_file_info[inst_type][edge]['instance_idx'] = edge_dict[edge][0]\n",
    "            \n",
    "        else:\n",
    "            metadata_file_info[inst_type] = {}\n",
    "            metadata_file_info[inst_type][edge] =  {}\n",
    "            metadata_file_info[inst_type][edge]['data'] =  edge_dict[edge][1]\n",
    "            metadata_file_info[inst_type][edge]['instance_idx'] = edge_dict[edge][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory to write node data to\n",
    "node_directory = './resources/node_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Metadata Dictionaries  <a class=\"anchor\" id=\"generate-metadata-dictionaries\"></a>\n",
    "In this step, the goal is to create a metadata dictionary for each node type that does not rely on API data. In this case, only the **Gene**, **RNA**, and **Variant** nodes require data that is not from an API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genes Metadata Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in ncbi gene data\n",
    "ncbi_gene = pandas.read_csv(unprocessed_data_location + 'Homo_sapiens.gene_info',\n",
    "                            header = 0,\n",
    "                            delimiter = '\\t')\n",
    "\n",
    "\n",
    "# replace \"-\" with \"None\"\n",
    "ncbi_gene.replace('-','None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61645/61645 [00:15<00:00, 3943.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# create metadata\n",
    "genes, label, description, synonym = [], [], [], []\n",
    "\n",
    "for idx, row in tqdm(ncbi_gene.iterrows(), total=ncbi_gene.shape[0]):\n",
    "    \n",
    "    # node \n",
    "    if row['GeneID'] != 'None':\n",
    "        genes.append(row['GeneID'])\n",
    "    \n",
    "    # label -- only want metadata if there is a label\n",
    "    if row['Symbol'] != 'None':\n",
    "        label.append(row['Symbol'])\n",
    "    \n",
    "        # description\n",
    "        description.append('{desc} is a {gene} gene that is located on chromosome {chrom} (map_location: {map_loc}).'.format(desc=row['description'].title(),\n",
    "                                                                                                                            gene=row['type_of_gene'],\n",
    "                                                                                                                            chrom=row['chromosome'],\n",
    "                                                                                                                            map_loc=row['map_location']))\n",
    "        # synonym\n",
    "        if row['Synonyms'] != 'None' and row['Other_designations'] != 'None':\n",
    "            synonym.append(row['Synonyms'] + '|' + row['Other_designations'])\n",
    "\n",
    "        elif row['Synonyms'] != 'None' and row['Other_designations'] == 'None':\n",
    "            synonym.append(row['Synonyms'])\n",
    "\n",
    "        elif row['Synonyms'] == 'None' and row['Other_designations'] != 'None':\n",
    "            synonym.append(row['Other_designations'])\n",
    "\n",
    "        else:\n",
    "            synonym.append('None')\n",
    "            \n",
    "    \n",
    "# combine into new data frame        \n",
    "gene_metadata_final = pandas.DataFrame(list(zip(genes, label, description, synonym)), columns =['ID', 'Label', 'Description', 'Synonym'])\n",
    "\n",
    "# make all variables string\n",
    "gene_metadata_final = gene_metadata_final.astype(str)\n",
    "\n",
    "# convert df to dictionary\n",
    "gene_metadata_final.set_index('ID', inplace=True)\n",
    "gene_metadata_dict = gene_metadata_final.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNA Metadata Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "rna_gene_data = pandas.read_csv(processed_data_location + 'Merged_Human_Ensembl_Entrez_Uniprot_Identifiers.txt',\n",
    "                                header = 0,\n",
    "                                delimiter = '\\t',\n",
    "                                low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows without identifiers\n",
    "rna_data = rna_gene_data.loc[rna_gene_data['transcript_stable_id'].apply(lambda x: x != 'None')]\n",
    "rna_data_labels = rna_gene_data.loc[rna_gene_data['GeneID_Cleaned'].apply(lambda x: x != 'None')]\n",
    "\n",
    "# de-dup data\n",
    "rna_metadata = rna_data[['transcript_stable_id', 'type_of_gene', 'Symbol', 'Synonyms', 'description', 'chromosome', 'map_location', 'Other_designations']].drop_duplicates(subset=['transcript_stable_id', 'type_of_gene', 'Symbol', 'Synonyms', 'description', 'chromosome', 'map_location', 'Other_designations'], keep='first', inplace=False) \n",
    "\n",
    "\n",
    "# aggregate mapping identifiers\n",
    "agg_cols = []\n",
    "\n",
    "for x in [ x for x in list(rna_data_labels) if x != 'transcript_stable_id']:\n",
    "    if x == 'GeneID_Cleaned':\n",
    "        agg_cols.append(rna_data_labels[['transcript_stable_id', x]].groupby('transcript_stable_id', as_index=False).agg(lambda x: '|'.join([x for x in list(set(x)) if x != 'None'])))\n",
    "    \n",
    "    else:\n",
    "        agg_cols.append(rna_data_labels[['transcript_stable_id', x]].groupby('transcript_stable_id', as_index=False).agg(lambda x: ', '.join([x for x in list(set(x)) if x != 'None'])))\n",
    "\n",
    "# merged aggreagted columns back together\n",
    "rna_merged = reduce(lambda  left, right: pandas.merge(left, right, on=['transcript_stable_id'], how='outer'), agg_cols)\n",
    "\n",
    "# replace NaN with 'None'\n",
    "rna_merged.replace('','None', inplace=True)\n",
    "\n",
    "# replace NaN with 'None'\n",
    "rna_merged.fillna('None', inplace=True)\n",
    "\n",
    "# remove rows without symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171919/171919 [00:48<00:00, 3535.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# create metadata\n",
    "rna, label, description, synonym = [], [], [], []\n",
    "\n",
    "for idx, row in tqdm(rna_merged.iterrows(), total=rna_merged.shape[0]):\n",
    "    \n",
    "    # node\n",
    "    if row['transcript_stable_id'] != 'None':\n",
    "        rna.append(row['transcript_stable_id'])\n",
    "    \n",
    "    # label -- only want metadata if there is a label\n",
    "    if row['Symbol'] != 'None':\n",
    "        label.append(row['Symbol'])\n",
    "    \n",
    "        # description\n",
    "        description.append('This transcript was transcribed from {desc}, a {gene} gene that is located on chromosome {chrom} (map_location: {map_loc}).'.format(desc=row['description'].title(),\n",
    "                                                                                                                                                                 gene=row['type_of_gene'],\n",
    "                                                                                                                                                                 chrom=row['chromosome'],\n",
    "                                                                                                                                                                 map_loc=row['map_location']))\n",
    "\n",
    "        # synonym\n",
    "        if row['Synonyms'] != 'None' and row['Other_designations'] != 'None':\n",
    "            synonym.append(row['Synonyms'] + '|' + row['Other_designations'])\n",
    "\n",
    "        elif row['Synonyms'] != 'None' and row['Other_designations'] == 'None':\n",
    "            synonym.append(row['Synonyms'])\n",
    "\n",
    "        elif row['Synonyms'] == 'None' and row['Other_designations'] != 'None':\n",
    "            synonym.append(row['Other_designations'])\n",
    "\n",
    "        else:\n",
    "            synonym.append('None')\n",
    "    \n",
    "# combine into new data frame\n",
    "rna_metadata_final = pandas.DataFrame(list(zip(rna, label, description, synonym)), columns =['ID', 'Label', 'Description', 'Synonym'])\n",
    "\n",
    "# make all variables string\n",
    "rna_metadata_final = rna_metadata_final.astype(str)\n",
    "\n",
    "# convert df to dictionary\n",
    "rna_metadata_final.set_index('ID', inplace=True)\n",
    "rna_metadata_dict = rna_metadata_final.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variant Metadata Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar/tab_delimited/variant_summary.txt.gz'\n",
    "data_downloader(url, unprocessed_data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data = pandas.read_csv(unprocessed_data_location + 'variant_summary.txt',\n",
    "                           header = 0,\n",
    "                           delimiter = '\\t',\n",
    "                           low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows without identifiers\n",
    "var_data = var_data.loc[var_data['Assembly'].apply(lambda x: x == 'GRCh38')]\n",
    "var_data = var_data.loc[var_data['RS# (dbSNP)'].apply(lambda x: x != -1)]\n",
    "\n",
    "# de-dup data\n",
    "var_metadata = var_data[['#AlleleID', 'Type', 'Name', 'ClinicalSignificance', 'RS# (dbSNP)', 'Origin',\n",
    "                         'ChromosomeAccession', 'Chromosome', 'Start', 'Stop', 'ReferenceAllele',\n",
    "                         'Assembly', 'AlternateAllele','Cytogenetic', 'ReviewStatus', 'LastEvaluated']] \n",
    "\n",
    "# replace NaN with 'None'\n",
    "var_metadata.fillna('None', inplace=True)\n",
    "\n",
    "# remove duplicate dbSNP ids by choosing the most recent reviewed variant\n",
    "var_metadata.sort_values('LastEvaluated', ascending=False, inplace=True)\n",
    "var_metadata.drop_duplicates(subset='RS# (dbSNP)', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429639/429639 [02:15<00:00, 3180.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# create metadata\n",
    "variant, label, description = [], [], []\n",
    "\n",
    "for idx, row in tqdm(var_metadata.iterrows(), total=var_metadata.shape[0]):\n",
    "    \n",
    "    # node\n",
    "    if row['RS# (dbSNP)'] != 'None':\n",
    "        variant.append('rs' + str(row['RS# (dbSNP)']))\n",
    "    \n",
    "    # label -- only want metadata if there is a label\n",
    "    if row['Name'] != 'None':\n",
    "        label.append(row['Name'])\n",
    "    \n",
    "        # description\n",
    "        sent = 'This variant is a {Origin} {Type} that results when a {ReferenceAllele} allele is changed to {AlternateAllele} on chromosome {Chromosome} ({ChromosomeAccession}, start:{Start}/stop:{Stop} positions, cytogenetic location:{Cytogenetic}) and has clinical significance {ClinicalSignificance}. This entry is for the {Assembly} and was last reviewed on {LastEvaluated} with review status \"{ReviewStatus}\".'\n",
    "        description.append(sent.format(Origin=row['Origin'], Type=row['Type'], ReferenceAllele=row['ReferenceAllele'],\n",
    "                                       AlternateAllele=row['AlternateAllele'], Chromosome=row['Chromosome'],\n",
    "                                       ChromosomeAccession=row['ChromosomeAccession'], Start=row['Start'],\n",
    "                                       Stop=row['Stop'], Cytogenetic=row['Cytogenetic'], ClinicalSignificance=row['ClinicalSignificance'],\n",
    "                                       Assembly=row['Assembly'], LastEvaluated=row['LastEvaluated'], ReviewStatus=row['ReviewStatus']))\n",
    "\n",
    "# combine into new data frame\n",
    "var_metadata_final = pandas.DataFrame(list(zip(variant, label, description)), columns =['ID', 'Label', 'Description'])\n",
    "\n",
    "# drop duplicates\n",
    "var_metadata_final.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "\n",
    "# make all variables string\n",
    "var_metadata_final = var_metadata_final.astype(str)\n",
    "\n",
    "# convert df to dictionary\n",
    "var_metadata_final.set_index('ID', inplace=True)\n",
    "var_metadata_dict = var_metadata_final.to_dict('index')                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Master Metadata Dictionary**  \n",
    "To make it easier to navigate the mapping of each instance node in an edge, a master dictionary is created and keyed by node type. This is most useful when both nodes in an edge are instances, but of different data types (e.g. `gene-rna`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_metadata_dictionary = {'gene': gene_metadata_dict, 'rna': rna_metadata_dict, 'variant': var_metadata_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Metadata Files  <a class=\"anchor\" id=\"write-metadata-files\"></a>   \n",
    "using the `Master Metadata Dictionary` created in the prior step, all of the `edge-type` data is processed and the resulting data written out `.txt` file to the `./resource/node_data` repository.\n",
    "\n",
    "- [Genes](#gene-metadata)\n",
    "- [RNA](#rna-metadata)\n",
    "- [Pathways](#pathway-metadata)\n",
    "- [Complexes](#complex-metadata)\n",
    "- [Reactions](#reaction-metadata)\n",
    "- [Variants](#variant-metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genes <a class=\"anchor\" id=\"gene-metadata\"></a>\n",
    "\n",
    "**Data Source Wiki Pages:** [NCBI Gene](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#ncbi-gene) \n",
    "\n",
    "**Output:**  \n",
    "- chemical-gene ➞ [`chemical-gene_GENE_METADATA.txt`](https://www.dropbox.com/s/fvkqnuk5xhs0huh/chemical-gene_GENE_METADATA.txt?dl=1) \n",
    "- gene-disease ➞ [`gene-disease_GENE_METADATA.txt`](https://www.dropbox.com/s/o0y21rx3b829q6d/gene-disease_GENE_METADATA.txt?dl=1) \n",
    "- gene-gene ➞ [`gene-gene_GENE_METADATA.txt`](https://www.dropbox.com/s/i4gznnct7rzh7pn/gene-gene_GENE_METADATA.txt?dl=1) \n",
    "- gene-pathway ➞ [`gene-pathway_GENE_METADATA.txt`](https://www.dropbox.com/s/yncd95vanhkp0ey/gene-pathway_GENE_METADATA.txt?dl=1) \n",
    "- gene-phenotype ➞ [`gene-phenotype_GENE_METADATA.txt`](https://www.dropbox.com/s/jghcoc5xzada011/gene-phenotype_GENE_METADATA.txt?dl=1) \n",
    "- gene-protein ➞ [`gene-protein_GENE_METADATA.txt`](https://www.dropbox.com/s/6vu961lna08qn08/gene-protein_GENE_METADATA.txt?dl=1) \n",
    "- gene-rna ➞ [`gene-rna_GENE_METADATA.txt`](https://www.dropbox.com/s/vs0kirmugdo9zkd/gene-rna_GENE_METADATA.txt?dl=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = 'gene'\n",
    "\n",
    "for edge_type in tqdm(metadata_file_info[node_type]):\n",
    "    print('\\nPROCESSING EDGE TYPE: {}'.format(edge_type))\n",
    "\n",
    "    # gather vars for processing data\n",
    "    data = metadata_file_info[node_type][edge_type]['data']\n",
    "    edge_data_type = metadata_file_info[node_type][edge_type]['instance_idx']\n",
    "    inst_idx = edge_data_type.split('-').index('instance')\n",
    "\n",
    "    # get list of nodes to map and the dictionary to use\n",
    "    # when nodes are of the same type (i.e. gene-gene)\n",
    "    if (edge_type.split('-')[0] == edge_type.split('-')[1]):\n",
    "        nodes = set([x for y in data for x in y])\n",
    "        \n",
    "        if edge_type.split('-')[0] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[0]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "            \n",
    "    # when nodes are both instances, but different types (i.e. gene-rna)\n",
    "    elif edge_data_type.split('-')[0] == edge_data_type.split('-')[1]:\n",
    "        data_res = []\n",
    "\n",
    "        for node in edge_type.split('-'):\n",
    "            nodes = set([x[int(edge_type.split('-').index(node))] for x in data])\n",
    "            \n",
    "            if node in master_metadata_dictionary:\n",
    "                metadata_dictionaries = master_metadata_dictionary[node]\n",
    "                data_res.append(metadata_dictionary_mapper(nodes, metadata_dictionaries))\n",
    "            else:\n",
    "                data_res.append(metadata_api_mapper(list(nodes)))\n",
    "    \n",
    "        # combine data into single df\n",
    "        results = pandas.concat(data_res, ignore_index=True)\n",
    "                \n",
    "    # when only one node is an instance\n",
    "    else:\n",
    "        nodes = set([x[int(inst_idx)] for x in data])\n",
    "        \n",
    "        if edge_type.split('-')[int(inst_idx)] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[int(inst_idx)]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "\n",
    "    # write data\n",
    "    results.to_csv(node_directory + edge_type + '_' + node_type.upper() + '_METADATA.txt', header = True, sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA<a class=\"anchor\" id=\"rna-metadata\"></a>\n",
    "\n",
    "**Data Source Wiki Pages:**  \n",
    "- [Ensembl](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#clinvar)  \n",
    "- [NCBI Gene](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources/#ncbi-gene) \n",
    "\n",
    "**Output:**  \n",
    "- chemical-rna ➞ [`chemical-rna_RNA_METADATA.txt`](https://www.dropbox.com/s/sm0orl0waq5iqhd/chemical-rna_RNA_METADATA.txt?dl=1) \n",
    "- rna-anatomy ➞ [`rna-anatomy_RNA_METADATA.txt`](https://www.dropbox.com/s/plkrunhhusx6mez/rna-anatomy_RNA_METADATA.txt?dl=1) \n",
    "- rna-cell ➞ [`rna-cell_RNA_METADATA.txt`](https://www.dropbox.com/s/dld0eadxyyzr44y/rna-cell_RNA_METADATA.txt?dl=1) \n",
    "- rna-protein ➞ [`rna-protein_RNA_METADATA.txt`](https://www.dropbox.com/s/3g72sb2e685rptn/rna-protein_RNA_METADATA.txt?dl=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = 'rna'\n",
    "\n",
    "for edge_type in tqdm(metadata_file_info[node_type]):\n",
    "    print('\\nPROCESSING EDGE TYPE: {}'.format(edge_type))\n",
    "\n",
    "    # gather vars for processing data\n",
    "    data = metadata_file_info[node_type][edge_type]['data']\n",
    "    edge_data_type = metadata_file_info[node_type][edge_type]['instance_idx']\n",
    "    inst_idx = edge_data_type.split('-').index('instance')\n",
    "\n",
    "    # get list of nodes to map and the dictionary to use\n",
    "    # when nodes are of the same type (i.e. gene-gene)\n",
    "    if (edge_type.split('-')[0] == edge_type.split('-')[1]):\n",
    "        nodes = set([x for y in data for x in y])\n",
    "        \n",
    "        if edge_type.split('-')[0] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[0]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "            \n",
    "    # when nodes are both instances, but different types (i.e. gene-rna)\n",
    "    elif edge_data_type.split('-')[0] == edge_data_type.split('-')[1]:\n",
    "        data_res = []\n",
    "\n",
    "        for node in edge_type.split('-'):\n",
    "            nodes = set([x[int(edge_type.split('-').index(node))] for x in data])\n",
    "            \n",
    "            if node in master_metadata_dictionary:\n",
    "                metadata_dictionaries = master_metadata_dictionary[node]\n",
    "                data_res.append(metadata_dictionary_mapper(nodes, metadata_dictionaries))\n",
    "            else:\n",
    "                data_res.append(metadata_api_mapper(list(nodes)))\n",
    "    \n",
    "        # combine data into single df\n",
    "        results = pandas.concat(data_res, ignore_index=True)\n",
    "                \n",
    "    # when only one node is an instance\n",
    "    else:\n",
    "        nodes = set([x[int(inst_idx)] for x in data])\n",
    "        \n",
    "        if edge_type.split('-')[int(inst_idx)] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[int(inst_idx)]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "\n",
    "    # write data\n",
    "    results.to_csv(node_directory + edge_type + '_' + node_type.upper() + '_METADATA.txt', header = True, sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathways<a class=\"anchor\" id=\"pathway-metadata\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#reactome-pathway-database)  \n",
    "\n",
    "**Output:**    \n",
    "- chemical-pathway ➞ [`chemical-pathway_PATHWAY_METADATA.txt`](https://www.dropbox.com/s/2txg2ui4e6y7rnm/chemical-pathway_PATHWAY_METADATA.txt?dl=1)\n",
    "- gobp-pathway ➞ [`gobp-pathway_PATHWAY_METADATA.txt`](https://www.dropbox.com/s/bq0g1g4ef40vwxj/gobp-pathway_PATHWAY_METADATA.txt?dl=1)\n",
    "- pathway-gocc ➞ [`pathway-gocc_PATHWAY_METADATA.txt`](https://www.dropbox.com/s/6fzkzjxj08u6jfi/pathway-gocc_PATHWAY_METADATA.txt?dl=1)\n",
    "- pathway-gomf ➞ [`pathway-gomf_PATHWAY_METADATA.txt`](https://www.dropbox.com/s/gfqt86vujnoo7j5/pathway-gomf_PATHWAY_METADATA.txt?dl=1)\n",
    "- protein-pathway ➞ [`protein-pathway_PATHWAY_METADATA.txt`](https://www.dropbox.com/s/xadtz4c0ab4a7p9/protein-pathway_PATHWAY_METADATA.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = 'pathway'\n",
    "\n",
    "for edge_type in tqdm(metadata_file_info[node_type]):\n",
    "    print('\\nPROCESSING EDGE TYPE: {}'.format(edge_type))\n",
    "\n",
    "    # gather vars for processing data\n",
    "    data = metadata_file_info[node_type][edge_type]['data']\n",
    "    edge_data_type = metadata_file_info[node_type][edge_type]['instance_idx']\n",
    "    inst_idx = edge_data_type.split('-').index('instance')\n",
    "\n",
    "    # get list of nodes to map and the dictionary to use\n",
    "    # when nodes are of the same type (i.e. gene-gene)\n",
    "    if (edge_type.split('-')[0] == edge_type.split('-')[1]):\n",
    "        nodes = set([x for y in data for x in y])\n",
    "        \n",
    "        if edge_type.split('-')[0] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[0]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "            \n",
    "    # when nodes are both instances, but different types (i.e. gene-rna)\n",
    "    elif edge_data_type.split('-')[0] == edge_data_type.split('-')[1]:\n",
    "        data_res = []\n",
    "\n",
    "        for node in edge_type.split('-'):\n",
    "            nodes = set([x[int(edge_type.split('-').index(node))] for x in data])\n",
    "            \n",
    "            if node in master_metadata_dictionary:\n",
    "                metadata_dictionaries = master_metadata_dictionary[node]\n",
    "                data_res.append(metadata_dictionary_mapper(nodes, metadata_dictionaries))\n",
    "            else:\n",
    "                data_res.append(metadata_api_mapper(list(nodes)))\n",
    "    \n",
    "        # combine data into single df\n",
    "        results = pandas.concat(data_res, ignore_index=True)\n",
    "                \n",
    "    # when only one node is an instance\n",
    "    else:\n",
    "        nodes = set([x[int(inst_idx)] for x in data])\n",
    "        \n",
    "        if edge_type.split('-')[int(inst_idx)] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[int(inst_idx)]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "\n",
    "    # write data\n",
    "    results.to_csv(node_directory + edge_type + '_' + node_type.upper() + '_METADATA.txt', header = True, sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexes<a class=\"anchor\" id=\"complex-metadata\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#reactome-pathway-database)    \n",
    "\n",
    "**Output:**    \n",
    "- chemical-complex ➞ [`chemical-complex_COMPLEX_METADATA.txt`](https://www.dropbox.com/s/mu53u8fv5v0epvf/chemical-complex_COMPLEX_METADATA.txt?dl=1) \n",
    "- complex-complex ➞ [`complex-complex_COMPLEX_METADATA.txt`](https://www.dropbox.com/s/y4qt0ne47ix1tqb/complex-complex_COMPLEX_METADATA.txt?dl=1) \n",
    "- complex-pathway ➞ [`complex-pathway_COMPLEX_METADATA.txt`](https://www.dropbox.com/s/6n9w0vvxabi7efl/complex-pathway_COMPLEX_METADATA.txt?dl=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = 'complex'\n",
    "\n",
    "for edge_type in tqdm(metadata_file_info[node_type]):\n",
    "    print('\\nPROCESSING EDGE TYPE: {}'.format(edge_type))\n",
    "\n",
    "    # gather vars for processing data\n",
    "    data = metadata_file_info[node_type][edge_type]['data']\n",
    "    edge_data_type = metadata_file_info[node_type][edge_type]['instance_idx']\n",
    "    inst_idx = edge_data_type.split('-').index('instance')\n",
    "\n",
    "    # get list of nodes to map and the dictionary to use\n",
    "    # when nodes are of the same type (i.e. gene-gene)\n",
    "    if (edge_type.split('-')[0] == edge_type.split('-')[1]):\n",
    "        nodes = set([x for y in data for x in y])\n",
    "        \n",
    "        if edge_type.split('-')[0] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[0]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "            \n",
    "    # when nodes are both instances, but different types (i.e. gene-rna)\n",
    "    elif edge_data_type.split('-')[0] == edge_data_type.split('-')[1]:\n",
    "        data_res = []\n",
    "\n",
    "        for node in edge_type.split('-'):\n",
    "            nodes = set([x[int(edge_type.split('-').index(node))] for x in data])\n",
    "            \n",
    "            if node in master_metadata_dictionary:\n",
    "                metadata_dictionaries = master_metadata_dictionary[node]\n",
    "                data_res.append(metadata_dictionary_mapper(nodes, metadata_dictionaries))\n",
    "            else:\n",
    "                data_res.append(metadata_api_mapper(list(nodes)))\n",
    "    \n",
    "        # combine data into single df\n",
    "        results = pandas.concat(data_res, ignore_index=True)\n",
    "                \n",
    "    # when only one node is an instance\n",
    "    else:\n",
    "        nodes = set([x[int(inst_idx)] for x in data])\n",
    "        \n",
    "        if edge_type.split('-')[int(inst_idx)] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[int(inst_idx)]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "\n",
    "    # write data\n",
    "    results.to_csv(node_directory + edge_type + '_' + node_type.upper() + '_METADATA.txt', header = True, sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactions<a class=\"anchor\" id=\"reaction-metadata\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [Reactome](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#reactome-pathway-database)   \n",
    "\n",
    "**Output:**    \n",
    "- chemical-reaction ➞ [`chemical-reaction_REACTION_METADATA.txt`](https://www.dropbox.com/s/6iztwaxrhrp1f7h/chemical-reaction_REACTION_METADATA.txt?dl=1)\n",
    "- protein-reaction ➞ [`protein-reaction_REACTION_METADATA.txt`](https://www.dropbox.com/s/92vsuon54w4uq4j/protein-reaction_REACTION_METADATA.txt?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = 'reaction'\n",
    "\n",
    "for edge_type in tqdm(metadata_file_info[node_type]):\n",
    "    print('\\nPROCESSING EDGE TYPE: {}'.format(edge_type))\n",
    "\n",
    "    # gather vars for processing data\n",
    "    data = metadata_file_info[node_type][edge_type]['data']\n",
    "    edge_data_type = metadata_file_info[node_type][edge_type]['instance_idx']\n",
    "    inst_idx = edge_data_type.split('-').index('instance')\n",
    "\n",
    "    # get list of nodes to map and the dictionary to use\n",
    "    # when nodes are of the same type (i.e. gene-gene)\n",
    "    if (edge_type.split('-')[0] == edge_type.split('-')[1]):\n",
    "        nodes = set([x for y in data for x in y])\n",
    "        \n",
    "        if edge_type.split('-')[0] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[0]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "            \n",
    "    # when nodes are both instances, but different types (i.e. gene-rna)\n",
    "    elif edge_data_type.split('-')[0] == edge_data_type.split('-')[1]:\n",
    "        data_res = []\n",
    "\n",
    "        for node in edge_type.split('-'):\n",
    "            nodes = set([x[int(edge_type.split('-').index(node))] for x in data])\n",
    "            \n",
    "            if node in master_metadata_dictionary:\n",
    "                metadata_dictionaries = master_metadata_dictionary[node]\n",
    "                data_res.append(metadata_dictionary_mapper(nodes, metadata_dictionaries))\n",
    "            else:\n",
    "                data_res.append(metadata_api_mapper(list(nodes)))\n",
    "    \n",
    "        # combine data into single df\n",
    "        results = pandas.concat(data_res, ignore_index=True)\n",
    "                \n",
    "    # when only one node is an instance\n",
    "    else:\n",
    "        nodes = set([x[int(inst_idx)] for x in data])\n",
    "        \n",
    "        if edge_type.split('-')[int(inst_idx)] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[int(inst_idx)]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "\n",
    "    # write data\n",
    "    results.to_csv(node_directory + edge_type + '_' + node_type.upper() + '_METADATA.txt', header = True, sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants<a class=\"anchor\" id=\"variant-metadata\"></a>\n",
    "\n",
    "**Data Source Wiki Page:** [ClinVar](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources#clinvar)  \n",
    "\n",
    "**Output:**  \n",
    "- variant-disease ➞ [`variant-disease_VARIANT_METADATA.txt`](https://www.dropbox.com/s/vj440u5efwdwibl/variant-disease_VARIANT_METADATA.txt?dl=1)  \n",
    "- variant-gene ➞ [`variant-gene_VARIANT_METADATA.txt`](https://www.dropbox.com/s/geui7nby9h055bc/variant-gene_VARIANT_METADATA.txt?dl=1)  \n",
    "- variant-phenotype ➞ [`variant-phenotype_VARIANT_METADATA.txt`](https://www.dropbox.com/s/hnocd802detivdd/variant-phenotype_VARIANT_METADATA.txt?dl=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = 'variant'\n",
    "\n",
    "for edge_type in tqdm(metadata_file_info[node_type]):\n",
    "    print('\\nPROCESSING EDGE TYPE: {}'.format(edge_type))\n",
    "\n",
    "    # gather vars for processing data\n",
    "    data = metadata_file_info[node_type][edge_type]['data']\n",
    "    edge_data_type = metadata_file_info[node_type][edge_type]['instance_idx']\n",
    "    inst_idx = edge_data_type.split('-').index('instance')\n",
    "\n",
    "    # get list of nodes to map and the dictionary to use\n",
    "    # when nodes are of the same type (i.e. gene-gene)\n",
    "    if (edge_type.split('-')[0] == edge_type.split('-')[1]):\n",
    "        nodes = set([x for y in data for x in y])\n",
    "        \n",
    "        if edge_type.split('-')[0] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[0]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "            \n",
    "    # when nodes are both instances, but different types (i.e. gene-rna)\n",
    "    elif edge_data_type.split('-')[0] == edge_data_type.split('-')[1]:\n",
    "        data_res = []\n",
    "\n",
    "        for node in edge_type.split('-'):\n",
    "            nodes = set([x[int(edge_type.split('-').index(node))] for x in data])\n",
    "            \n",
    "            if node in master_metadata_dictionary:\n",
    "                metadata_dictionaries = master_metadata_dictionary[node]\n",
    "                data_res.append(metadata_dictionary_mapper(nodes, metadata_dictionaries))\n",
    "            else:\n",
    "                data_res.append(metadata_api_mapper(list(nodes)))\n",
    "    \n",
    "        # combine data into single df\n",
    "        results = pandas.concat(data_res, ignore_index=True)\n",
    "                \n",
    "    # when only one node is an instance\n",
    "    else:\n",
    "        nodes = set([x[int(inst_idx)] for x in data])\n",
    "        \n",
    "        if edge_type.split('-')[int(inst_idx)] in master_metadata_dictionary.keys():\n",
    "            metadata_dictionaries = master_metadata_dictionary[edge_type.split('-')[int(inst_idx)]]\n",
    "            results = metadata_dictionary_mapper(nodes, metadata_dictionaries)\n",
    "        else:\n",
    "            results = metadata_api_mapper(list(nodes))\n",
    "\n",
    "    # write data\n",
    "    results.to_csv(node_directory + edge_type + '_' + node_type.upper() + '_METADATA.txt', header = True, sep = '\\t', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "```\n",
    "@misc{callahan_tj_2019_3401437,\n",
    "  author       = {Callahan, TJ},\n",
    "  title        = {PheKnowLator},\n",
    "  month        = mar,\n",
    "  year         = 2019,\n",
    "  doi          = {10.5281/zenodo.3401437},\n",
    "  url          = {https://doi.org/10.5281/zenodo.3401437}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
