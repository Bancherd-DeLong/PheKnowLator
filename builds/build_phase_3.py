#!/usr/bin/env python
# -*- coding: utf-8 -*-

# import needed libraries
import click
import fnmatch
import glob
import logging.config
import os
import re
import subprocess
import traceback

from datetime import datetime
from google.cloud import storage  # type: ignore

from pkt_kg.__version__ import __version__
from pkt_kg.utils import *

# set environment variables
# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'resources/project_keys/pheknowlator-6cc612b4cbee.json'
# logging
log_dir, log, log_config = 'logs', 'pkt_builder_phase3_log.log', glob.glob('**/logging.ini', recursive=True)
if not os.path.exists(log_dir): os.mkdir(log_dir)
logger = logging.getLogger(__name__)
logging.config.fileConfig(log_config[0], disable_existing_loggers=False, defaults={'log_file': log_dir + '/' + log})


def uploads_data_to_gcs_bucket(bucket, bucket_location, directory, file_loc):
    """Takes a file name and pushes the corresponding data referenced by the filename object from a local
    temporary directory to a Google Cloud Storage bucket.

    Args:
        bucket: A storage bucket object specifying a Google Cloud Storage bucket.
        bucket_location: A string containing a file path to a directory within a Google Cloud Storage Bucket.
        directory: A string containing a local directory.
        file_loc: A string containing the name of file to write to a Google Cloud Storage bucket.

    Returns:
        None.
    """

    blob = bucket.blob(bucket_location + file_loc)
    blob.upload_from_filename(directory + '/' + file_loc)

    return None


def uploads_build_data(bucket, gcs_location):
    """Methods moves data generated by the knowledge graph construction process from the docker container to the
    dedicated Google Cloud Storage Bucket for the current build.

    Args:
        bucket: A storage bucket object specifying a Google Cloud Storage bucket.
        gcs_location: A string containing the location for the archive build in the current release directory
            within the dedicated project Google Cloud Storage Bucket.

    Returns:
        None.
    """

    # create variables to store source directory locations
    resources_loc = 'resources'
    kg_loc = resources_loc + '/knowledge_graphs/'
    metadata_loc = resources_loc + '/node_data/'
    construct_app = resources_loc + '/construction_/'

    # move knowledge graph data
    for kg_file in [x for x in glob.glob(kg_loc + '*') if 'README.md' not in x]:
        uploads_data_to_gcs_bucket(bucket, gcs_location, kg_loc, kg_file)
    # move master edge list
    uploads_data_to_gcs_bucket(bucket, gcs_location, resources_location, 'Master_Edge_List_Dict.json')
    # node metadata dict
    uploads_data_to_gcs_bucket(bucket, gcs_location, metadata_loc, 'node_metadata_dict.pkl')
    # construction approach logs
    uploads_data_to_gcs_bucket(bucket, gcs_location, construct_app, 'subclass_map_missing_node_log.json')

    return None


@click.command()
@click.option('--app', prompt='construction approach to use (i.e. instance or subclass)')
@click.option('--rel', prompt='yes/no - adding inverse relations to knowledge graph')
@click.option('--owl', prompt='yes/no - removing OWL Semantics from knowledge graph')
def main(app, rel, owl):

    start_time = datetime.now()
    print('#' * 35 + '\nBUILD PHASE 3: DATA PRE-PROCESSING\n' + '#' * 35)
    logger.info('#' * 5 + 'BUILD PHASE 3: DATA PRE-PROCESSING' + '#' * 5)

    #####################################################
    # STEP 1 - INITIALIZE GOOGLE STORAGE BUCKET OBJECTS
    print('\nSTEP 1: INITIALIZE GOOGLE STORAGE BUCKET AND REFORMAT INPUT ARGUMENTS')
    logger.info('STEP 1: INITIALIZE GOOGLE STORAGE BUCKET AND REFORMAT INPUT ARGUMENTS')

    # set bucket information and find current archived build directory
    storage_client = storage.Client()
    bucket = storage_client.get_bucket('pheknowlator')
    release = 'release_v' + __version__
    bucket_files = [file.name.split('/')[2] for file in bucket.list_blobs(prefix=release + '/archived_builds/')]
    builds = [x[0] for x in [re.findall(r'(?<=_)\d.*', x) for x in bucket_files] if len(x) > 0]
    sorted_dates = sorted([datetime.strftime(datetime.strptime(str(x), '%d%b%Y'), '%Y-%m-%d').upper() for x in builds])
    build = 'build_' + datetime.strftime(datetime.strptime(sorted_dates[-1], '%Y-%m-%d'), '%d%b%Y').upper()

    # reformat input arguments and create gcs directory variables
    build_app = 'instance_builds' if app == 'instance' else 'subclass_builds'
    rel_type = 'relations_only' if rel == 'no' else 'inverse_relations'
    owl_decoding = 'owl' if owl == 'no' else 'owlnets'
    arch_string = 'archived_builds/{}/{}/knowledge_graphs/{}/{}/{}/'
    gcs_archive_loc = arch_string.format(release, build, build_app, rel_type, owl_decoding)
    gcs_current_loc = 'current_build/knowledge_graphs/{}/{}/{}/'.format(build_app, rel_type, owl_decoding)

    uploads_data_to_gcs_bucket(bucket, gcs_current_loc, log_dir, log)  # uploads log to gcs bucket

    #####################################################
    # STEP 2 - CONSTRUCT KNOWLEDGE GRAPH
    print('\nSTEP 2: CONSTRUCT KNOWLEDGE GRAPH')
    print('Knowledge Graph Build: {} + {} + {}.txt'.format(app, rel_type.lower(), owl_decoding.lower()))
    logger.info('STEP 2: CONSTRUCT KNOWLEDGE GRAPH')
    logger.info('Knowledge Graph Build: {} + {} + {}.txt'.format(app, rel_type.lower(), owl_decoding.lower()))
    # command = 'python Main.py --onts resources/ontology_source_list.txt --edg resources/edge_source_list.txt ' \
    #           '--res resources/resource_info.txt --out ./resources/knowledge_graphs --nde yes --kg full' \
    #           '--app {} --rel {} --owl {}'
    # try:
    #     return_code = os.system(command.format(app, rel, owl))
    #     if return_code != 0:
    #         logger.error('ERROR: Program Finished with Errors: {}'.format(return_code))
    #         raise Exception('ERROR: Program Finished with Errors: {}'.format(return_code))
    # except: logger.error('ERROR: Uncaught Exception: {}'.format(traceback.format_exc()))

    uploads_data_to_gcs_bucket(bucket, gcs_current_loc, log_dir, log)  # uploads log to gcs bucket

    #####################################################
    # STEP 3 - UPLOAD BUILD DATA TO GOOGLE CLOUD STORAGE
    print('\nSTEP 3: UPLOAD KNOWLEDGE GRAPH DATA TO GOOGLE CLOUD STORAGE')
    logger.info('STEP 3: UPLOAD KNOWLEDGE GRAPH DATA TO GOOGLE CLOUD STORAGE')

    # upload data from Docker to archived_builds Google Cloud Storage Bucket
    # uploads_build_data(bucket, gcs_archive_loc)
    # uploads_data_to_gcs_bucket(bucket, gcs_current_loc, log_dir, log)  # uploads log to gcs bucket
    #
    # # upload data from Docker to current_build Google Cloud Storage Bucket
    # uploads_build_data(bucket, gcs_current_loc)
    # uploads_data_to_gcs_bucket(bucket, gcs_current_loc, log_dir, log)  # uploads log to gcs bucket

    #######################################################
    # STEP 4 - LOG EXIT STATUS TO FINISH RUN
    print('\nSTEP 4: BUILD CLEAN-UP')
    logger.info('STEP 4: BUILD CLEAN-UP')
    runtime = round((datetime.now() - start_time).total_seconds() / 60, 3)
    print('\n\n' + '*' * 5 + ' COMPLETED BUILD PHASE 3: {} MINUTES '.format(runtime) + '*' * 5)
    logger.info('COMPLETED BUILD PHASE 3: {} MINUTES'.format(runtime))  # don't delete needed for build monitoring

    # copy build logs
    print('Upload Logs for Build Phases 1-3')
    logger.info('Upload Logs for Build Phases 1-3')
    base_url = 'https://storage.googleapis.com/pheknowlator/{}'
    # copy phases 1-2 log from current to archive build directory
    log_file = fnmatch.filter([_.name for _ in bucket.list_blobs(prefix='current_build/')], '*/*_log.log')[0]
    data_downloader(base_url.format(log_file), log_dir, log_file.split('/')[-1])
    uploads_data_to_gcs_bucket(bucket, gcs_archive_loc, log_dir, log_file.split('/')[-1])
    # copy phase 3 log from current to archive build directory
    uploads_data_to_gcs_bucket(bucket, gcs_archive_loc, log_dir, log)

    # exit build
    uploads_data_to_gcs_bucket(bucket, gcs_current_loc, log_dir, log)  # uploads log to gcs bucket

    return None


if __name__ == '__main__':
    main()
