#!/usr/bin/env python
# -*- coding: utf-8 -*-

# import needed libraries
import click
import fnmatch
import glob
import logging.config
import pickle
import os
import re
import subprocess
import traceback

from datetime import datetime
from google.cloud import storage  # type: ignore

from pkt_kg.__version__ import __version__

# set environment variables
# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'resources/project_keys/pheknowlator-6cc612b4cbee.json'
# logging
log_dir, log, log_config = 'logs', 'pkt_builder_phase3_log.log', glob.glob('**/logging.ini', recursive=True)
if not os.path.exists(log_dir): os.mkdir(log_dir)
logger = logging.getLogger(__name__)
logging.config.fileConfig(log_config[0], disable_existing_loggers=False, defaults={'log_file': log_dir + '/' + log})


def uploads_data_to_gcs_bucket(bucket, bucket_location, directory, file_loc):
    """Takes a file name and pushes the corresponding data referenced by the filename object from a local
    temporary directory to a Google Cloud Storage bucket.

    Args:
        bucket: A storage bucket object specifying a Google Cloud Storage bucket.
        bucket_location: A string containing a file path to a directory within a Google Cloud Storage Bucket.
        directory: A string containing a local directory.
        file_loc: A string containing the name of file to write to a Google Cloud Storage bucket.

    Returns:
        None.
    """

    blob = bucket.blob(bucket_location + file_loc)
    blob.upload_from_filename(directory + '/' + file_loc)

    return None


def uploads_build_data(bucket, gcs_location):
    """Methods moves data generated by the knowledge graph construction process from the docker container to the
    dedicated Google Cloud Storage Bucket for the current build.

    Args:
        bucket: A storage bucket object specifying a Google Cloud Storage bucket.
        gcs_location: A string containing the location for the archive build in the current release directory
            within the dedicated project Google Cloud Storage Bucket.

    Returns:
        None.
    """

    # create variables to store source directory locations
    resources_loc = 'resources'
    kg_loc = resources_loc + '/knowledge_graphs/'
    metadata_loc = resources_loc + '/node_data/'
    construct_app = resources_loc + '/construction_/'

    # move knowledge graph data
    for kg_file in [x for x in glob.glob(kg_loc + '*') if 'README.md' not in x]:
        uploads_data_to_gcs_bucket(bucket, gcs_location, kg_loc, kg_file)
    # move master edge list
    uploads_data_to_gcs_bucket(bucket, gcs_location, resources_location, 'Master_Edge_List_Dict.json')
    # node metadata dict
    uploads_data_to_gcs_bucket(bucket, gcs_location, metadata_loc, 'node_metadata_dict.pkl')
    # construction approach logs
    uploads_data_to_gcs_bucket(bucket, gcs_location, construct_app, 'subclass_map_missing_node_log.json')

    return None


@click.command()
@click.option('--app', prompt='construction approach to use (i.e. instance or subclass)')
@click.option('--rel', prompt='yes/no - adding inverse relations to knowledge graph')
@click.option('--owl', prompt='yes/no - removing OWL Semantics from knowledge graph')
def main(app, rel, owl):

    start_time = datetime.now()

    #####################################################
    # STEP 1 - INITIALIZE GOOGLE STORAGE BUCKET OBJECTS

    storage_client = storage.Client()
    bucket = storage_client.get_bucket('pheknowlator')
    # define write path to Google Cloud Storage bucket
    release = 'release_v' + __version__
    bucket_files = [file.name.split('/')[2] for file in bucket.list_blobs(prefix=release + '/archived_builds/')]
    # find current archived build directory
    builds = [x[0] for x in [re.findall(r'(?<=_)\d.*', x) for x in bucket_files] if len(x) > 0]
    sorted_dates = sorted([datetime.strftime(datetime.strptime(str(x), '%d%b%Y'), '%Y-%m-%d').upper() for x in builds])
    build = 'build_' + datetime.strftime(datetime.strptime(sorted_dates[-1], '%Y-%m-%d'), '%d%b%Y').upper()
    # set gcs bucket variables
    gcs_archived_build = '{}/archived_builds/{}/'.format(release, build)
    gcs_current_build = '{}/current_build/'.format(release)

    # try:
    #     y[0]
    # except IndexError as e:
    #     logger.error(e, exc_info=True)

    # upload logging to GCS bucket
    uploads_data_to_gcs_bucket(bucket, gcs_current_build, log_dir, log)

    #####################################################
    # STEP 2 - CONSTRUCT KNOWLEDGE GRAPH

    print('Knowledge Graph Build: {} + {} + {}.txt'.format(app, rel_type.lower(), owl_decoding.lower()))
    logger.info('Knowledge Graph Build: {} + {} + {}.txt'.format(app, rel_type.lower(), owl_decoding.lower()))
    command = 'python Main.py --onts resources/ontology_source_list.txt --edg resources/edge_source_list.txt ' \
              '--res resources/resource_info.txt --out ./resources/knowledge_graphs --nde yes --kg full' \
              '--app {} --rel {} --owl {}'
    try: os.system(command.format(app, rel, owl))
    except: logger.error('Uncaught Exception: {}'.format(traceback.format_exc()))
    uploads_data_to_gcs_bucket(bucket, gcs_current_build, log_dir, log)

    #####################################################
    # STEP 3 - UPLOAD BUILD DATA TO GOOGLE CLOUD STORAGE
    # set variable to store file destination information
    build_app = 'instance_builds' if app == 'instance' else 'subclass_builds'
    rel_type = 'relations_only' if rel == 'no' else 'inverse_relations'
    owl_decoding = 'owl' if owl == 'no' else 'owlnets'
    source_location = gcs_archived_build + '{}/{}/{}'.format(build_app, rel_type, owl_decoding)

    # upload data to Archive Google Cloud Storage Buckets
    uploads_build_data(bucket, source_location)
    uploads_data_to_gcs_bucket(bucket, gcs_current_build, log_dir, log)

    # copy build logs for run to archive bucket

    #######################################################
    # STEP 4 - LOG EXIT STATUS TO FINISH RUN
    runtime = round((datetime.now() - start_time).total_seconds() / 60, 3)
    print('\n\n' + '*' * 5 + ' COMPLETED BUILD PHASE 3: {} MINUTES '.format(runtime) + '*' * 5)
    logger.info('COMPLETED BUILD PHASE 3: {} MINUTES'.format(runtime))  # don't delete needed for build monitoring

    return None


if __name__ == '__main__':
    main()
