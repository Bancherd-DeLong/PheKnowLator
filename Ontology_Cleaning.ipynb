{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# PheKnowLator - Ontology Cleaning\n",
    "***\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=callahantiff@gmail.com)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Release:** **[v2.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)**\n",
    "  \n",
    "<br>  \n",
    "  \n",
    "**Purpose:** This notebook serves as a script to help prepare ontologies prior to be ingested into the knowledge graph build algorithm. This script focuses on preparing ontologies for digestion by performing the following steps:  \n",
    "1. [Clean Ontologies](#clean-ontologies)  \n",
    "2. [Merge Ontologies](#merge-ontologies)  \n",
    "3. [Normalize Classes](#normalize-classes)  \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumptions:**   \n",
    "- Steps 1-2 (i.e. data downloading and master edge list creation) have already been performed  \n",
    "- Directory of Imported Ontologies ➞ `./resources/ontologies`    \n",
    "- Processed data write location ➞ `./resources/ontologies`  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Dependencies:**   \n",
    "- This notebook utilizes several helper functions, which are stored in the [`kg_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/kg_utils.py) script. Hyperlinks to all downloaded and generated data sources are provided on the [Data Sources](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources) Wiki page as well as within each source subsection of this notebook. All generated data is freely available for download from DropBox. \n",
    "- [`OWLTools`](https://github.com/owlcollab/owltools)\n",
    "\n",
    "_____\n",
    "***\n",
    "\n",
    "### PheKnowLator Build V2.0.0 Ontology Cleaning Summary  \n",
    "**Date:** `06/09/2020`  \n",
    "\n",
    "The table below is meant to provide a high-level overview of the modifications that were applied to each individual ontology as well as to the merged ontology file. The specific details and code for performing each of the tasks in the table are described throughout the rest of this document.  \n",
    "\n",
    "**Error Types:**   \n",
    "1. Value Errors  \n",
    "2. Punning Errors  \n",
    "3. Obsolete Entities/Unused Entities    \n",
    "4. Erroneously Defined Entities  \n",
    "5. Concept Connectivity  \n",
    "6. Identifier Resolution and Alignment\n",
    "\n",
    "\n",
    "Ontology | 1 | 2 | 3 | 4 | 5 | 6\n",
    ":---:              | :---: | :---: | :---: | :---: | :---:  | :---:  \n",
    "Cell Line Ontology | 1     | 8     | 7 | X | X     | X      | X \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-Up Environment\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from owlready2 import *\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import script containing helper functions\n",
    "from pkt_kg.utils import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment variables\n",
    "write_location = './resources/knowledge_graphs'\n",
    "merged_ontology_file = '/PheKnowLator_MergedOntologies.owl'\n",
    "ontology_repository = glob.glob('*/ontologies/*_with_imports.owl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Clean Ontologies <a class=\"anchor\" id=\"clean-ontologies\"></a>\n",
    "\n",
    "**Purpose:** In this step, we read in the ontologies using the [`owlready2`](https://pypi.org/project/Owlready2/) library and use it to indicate the presence of errors in the ontology files. We use this tool because it has strict filters.\n",
    "\n",
    "Errors were found in the following ontologies:  \n",
    "\n",
    "[`Vaccine Ontology`](http://www.violinet.org/vaccineontology/) - GitHub [issue #4](https://github.com/vaccineontology/VO/issues/4)\n",
    "\n",
    "[`PRotein Ontology`](https://proconsortium.org/pro.shtml) - GitHub [issue #176](https://github.com/PROconsortium/PRoteinOntology/issues/176)\n",
    "\n",
    "[`Cell Line Ontology`](http://www.clo-ontology.org/) - GitHub [issue #42](https://github.com/CLO-ontology/CLO/issues/42), [issue #52](https://github.com/CLO-ontology/CLO/issues/52)  \n",
    "- `8` anatomical entities entered as individuals and classes (i.e. digestive tract, lymph node, mesoderm, circulatory system, central nervous system, organ, respiratory system, and musculature of body) were repaired. The problem was resolved by removing the individuals and keeping the classes     \n",
    "- `7` NCBITaxon identifiers listed as individuals, but never used in the ontology (i.e. `NCBITaxon_110815`, `NCBITaxon_147099`, `NCBITaxon_41324`, `NCBITaxon_6040`, `NCBITaxon_6073`, `NCBITaxon_6157`, and `NCBITaxon_8570`)   were removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Ontology Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ont in tqdm(ontology_repository):\n",
    "    load_onto = get_ontology(ont).load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Cell Line Ontology](http://www.clo-ontology.org/) yield the following error message:\n",
    "\n",
    "```python\n",
    "\n",
    "ValueError: invalid literal for int() with base 10: '永生的乳腺衍生细胞系细胞'\n",
    "\n",
    "...\n",
    "\n",
    "OwlReadyOntologyParsingError: RDF/XML parsing error in file ./resources/knowledge_graphs/PheKnowLator_MergedOntologies.owl, line 2363344, column 99.\n",
    "```\n",
    "\n",
    "This tells us that we need to repair the triple containing the Literal '永生的乳腺衍生细胞系细胞' by removing it and redefining it as a `string`, rather than an `int` as it is currently defined as. \n",
    "\n",
    "<br>\n",
    "\n",
    "This is currently noted as an issue in the [Cell Line Ontology's](http://www.clo-ontology.org/) GitHub repo ([issue #45](https://github.com/CLO-ontology/CLO/issues/48)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in tqdm(graph):\n",
    "    if '永生的乳腺衍生细胞系细胞' in str(edge[0]) or '永生的乳腺衍生细胞系细胞' in str(edge[2]):\n",
    "        \n",
    "        # repair broken triple\n",
    "        graph.add((edge[0], edge[1], Literal(str(edge[2]), datatype=URIRef('http://www.w3.org/2001/XMLSchema#string'))))\n",
    "        graph.remove(edge)\n",
    "        break\n",
    "\n",
    "# save cleaned up ontology\n",
    "graph.serialize(destination='./resources/ontologies/clo_with_imports', format='xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try reading in the cleaned ontology again\n",
    "merged_onto = get_ontology('./resources/ontologies/clo_with_imports').load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next errors that are generated are related to punning, specifically that the following OWL object properties had been incorrectly redeclared as OWL annotation properties:\n",
    "\n",
    "```bash\n",
    "2020-03-24 16:48:25,458 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0002091 in punning not allowed [Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0002091>)), Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0002091>))]\n",
    "2020-03-24 16:48:25,460 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/BFO_0000062 in punning not allowed [Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/BFO_0000062>)), Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/BFO_0000062>))]\n",
    "2020-03-24 16:48:25,460 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/BFO_0000063 in punning not allowed [Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/BFO_0000063>)), Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/BFO_0000063>))]\n",
    "2020-03-24 16:48:25,460 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0002222 in punning not allowed [Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0002222>)), Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0002222>))]\n",
    "2020-03-24 16:48:25,460 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0000087 in punning not allowed [Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0000087>)), Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0000087>))]\n",
    "2020-03-24 16:48:25,460 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0002161 in punning not allowed [Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0002161>)), Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0002161>))]\n",
    "```\n",
    "\n",
    "From this message, we can see that we need to remove the following redeclaration to Annotation Properties for the following object properties:  \n",
    "- RO_0002091  \n",
    "- BFO_0000062  \n",
    "- BFO_0000063  \n",
    "- RO_0002222  \n",
    "- RO_0000087  \n",
    "- RO_0002161  \n",
    "\n",
    "<br>\n",
    "\n",
    "- This is another error caused by the [Cell Line Ontology](http://www.clo-ontology.org/) and has been posted to GitHub ([issue #43](https://github.com/CLO-ontology/CLO/issues/43))  \n",
    "- We also removed RO_0002161 (the Annotation Property) from GO, UBERON, and HPO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Identifier Check**  \n",
    "Check class identifiers to ensure consistency in identifier prefixes. Running this check revealed mislabeling of two [pROtein Ontology](https://proconsortium.org/) identifiers in the [Vaccine Ontology](http://www.violinet.org/vaccineontology/) (see [this](https://github.com/vaccineontology/VO/issues) GitHub issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all classes in graph\n",
    "kg_classes = graph.query(\n",
    "    \"\"\"SELECT DISTINCT ?c\n",
    "           WHERE {?c rdf:type owl:Class . }\n",
    "           \"\"\", initNs={'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "                        'owl': 'http://www.w3.org/2002/07/owl#'}\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to list of classes and only keep hgnc identifiers\n",
    "class_list = [res[0] for res in tqdm(kg_classes) if isinstance(res[0], URIRef) and 'obo' in str(res[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_types = []\n",
    "\n",
    "for cls in class_list2:\n",
    "    class_types.append(cls.split('/')[-1].split('_')[0])\n",
    "    \n",
    "set(class_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Obsolete Ontology Classes**  \n",
    "To make sure that the ontology only contains current information, all obsolete classes and any triples that they participate in are removed from the ontologies.\n",
    "\n",
    "For the current build, we removed the following number of entites related to or containing a deprecated ontology class:    \n",
    "\n",
    "Ontology | Classes | Axioms\n",
    ":--: | :--: | :--:\n",
    "CheBI Lite | 18,443 | 73,831  \n",
    "CLO | 16 | 153  \n",
    "DOID | 2,431 | 17,760  \n",
    "GO | 5,610 | 42,840  \n",
    "HPO | 293 | 1,636 \n",
    "PW | 42 | 728  \n",
    "PRO - Human | 8 | 75\n",
    "SO | 336 | 2,091  \n",
    "UBERON | 1,558 | 11,072  \n",
    "VO | 10 | 87  \n",
    "RO | 2 | 48\n",
    "\n",
    "\n",
    "\n",
    "_NOTE._ In addition to running the code below, it may also be necessary to check for classes that are a sub-class of `oboInOwl:ObsoleteClass`, as well as any obsolete or deprecated annotations, individuals, or `owl:ObjectProperty`. Please note that `8` genes (i.e. [`HGNC:26619`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/26619), [`HGNC:13392`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/13392), [`HGNC:31424`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/31424), [`HGNC:8103`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/8103), \n",
    "[`HGNC:25943`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/25943), [`HGNC:16957`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/16957), [`HGNC:23418`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/23418), [`HGNC:32021`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/32021)), which are currently obsolete, were removed from the PRO (more details below, but the numbers reflect those changes). Finally, we recommend verifying each ontology using an ontology debugger (i.e. by running a reasoner) to ensure that your changes and edits have not introduced unexpected errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare query\n",
    "deprecated_class_query = prepareQuery(\n",
    "    \"\"\"SELECT DISTINCT ?c\n",
    "       WHERE {?c owl:deprecated true . }\n",
    "    \"\"\", initNs={'owl': OWL})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove triples containing deprecated classes\n",
    "for ont in tqdm(ontology_repository):\n",
    "    dep_class_counter = 0\n",
    "    \n",
    "    print('\\nLoading: {}'.format(ont))\n",
    "    graph = Graph()\n",
    "    graph.parse(ont)\n",
    "    \n",
    "    print('Obtaining a list of deprecated classes')\n",
    "    results = graph.query(deprecated_class_query)\n",
    "   \n",
    "    dep_cls = [res[0] for res in tqdm(results) if isinstance(res[0], URIRef)]   # convert to node list\n",
    "    \n",
    "    print('Removing triples containing deprecated classes')\n",
    "    for node in tqdm(dep_cls):        \n",
    "        graph.remove((node, None, None))  # remove all triples about node\n",
    "        graph.remove((None, None, node))  # remove all triples pointing to node\n",
    "        dep_class_counter += 1\n",
    "\n",
    "    print('Serializing cleaned ontology to: {}'.format(ont[:-4] + '_clean_test.owl'))\n",
    "    graph.serialize(destination=ont[:-4] + '_clean_test.owl', format='xml')\n",
    "    \n",
    "    print('Removed {} triples containing a deprecated ontology class.'.format(dep_class_counter))\n",
    "    del graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### MERGE ONTOLOGIES <a class=\"anchor\" id=\"merge-ontologies\"></a>\n",
    "\n",
    "**Purpose:** In this step, the `OWL Tools` library is designed to merge a directory of ontology files into a single ontology file. This merged ontology file is required as input to the knowledge graph build algorithm.  \n",
    "\n",
    "**Inputs:** A directory of ontology files (`.owl`)  \n",
    "**Outputs:** [`PheKnowLator_MergedOntologies.owl`](https://www.dropbox.com/s/1lhh4hdwbjzds74/PheKnowLator_MergedOntologiesGeneID_Normalized_Cleaned.owl?dl=1)\n",
    "\n",
    "<br>\n",
    "\n",
    "*Merged Ontology File Punning Update:* Consistent with the solution described [here](https://github.com/oborel/obo-relations/issues/130), we removed all `AnnotationProperty` declarations from the merged ontology file. The Annotation Properties for each of the Object Properties listed above were removed using Protége."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify there are ontology files in ontology repo\n",
    "for ont in ontology_repository:\n",
    "    print(ont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ontologies\n",
    "if write_location + merged_ontology_file in glob.glob(write_location + '/*.owl'):\n",
    "    graph = Graph()\n",
    "    graph.parse(write_location + merged_ontology_file)\n",
    "    gets_ontology_statistics(write_location + merged_ontology_file)\n",
    "else:\n",
    "    merges_ontologies(ontology_repository, write_location, merged_ontology_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Normalize Classes <a class=\"anchor\" id=\"normalize-classes\"></a>\n",
    "\n",
    "**Purpose:** The goal of this section is to checked the cleaned merged ontology file to ensure that there is consistency between the existing classes. To do this, we check the following two things:  \n",
    "- <u>Aligning Existing Ontology Classes</u>: For this check, we want to make sure that all classes that represent the same entity are connected to each other. For example, consider the following:  \n",
    "    - Ontologies: [Sequence Ontology](http://www.sequenceontology.org/), [ChEBI](https://www.ebi.ac.uk/chebi), and [PRotein Ontology](https://proconsortium.org/) all include terms for protein, but none of these classes are connected to each other. \n",
    "    \n",
    "    \n",
    "- <u>Aligning Ontology Classes and New Edge Data</u>: For this check, we want to make sure that any of the existing ontology classes can be aligned with any of the new data entities that we want to add to the knowledge graph. For example:  \n",
    "  - Gene Classes: there are several gene classes that use [HGNC](https://www.genenames.org/) identifiers. We also want to add genes, but prefer to use [Entrez gene](https://www.ncbi.nlm.nih.gov/gene) identifiers. In order to be used with our data, we must first normalize all of the HPO gene classes to Entrez gene identifiers.\n",
    "  \n",
    "<br>\n",
    "\n",
    "**Dependencies:** The Merged Gene, RNA, Protein Map ([`Merged_gene_rna_protein_identifiers.pkl`](https://www.dropbox.com/s/6idnt7b3i322hlh/Merged_gene_rna_protein_identifiers.pkl?dl=1)) we generated in order to map genomic identifier data sources.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aligning Existing Ontology Classes**\n",
    "\n",
    "The follow classes occur in all of the ontologies used in the current build and have to be resolved:  \n",
    "\n",
    "- Gene: [VO](http://purl.obolibrary.org/obo/OGG_0000000002)  \n",
    "  - <u>Solution</u>: Make the VO imported OGG class a subclass of the SO gene term  \n",
    "\n",
    "- Protein: [SO](http://purl.obolibrary.org/obo/SO_0000104), [PRO](http://purl.obolibrary.org/obo/PR_000000001), [ChEBI](http://purl.obolibrary.org/obo/CHEBI_36080) \n",
    "  - <u>Solution</u>: Make the ChEBI and PRO classes a subclass of the SO protein term  \n",
    "  \n",
    "- Disorder: [VO](http://purl.obolibrary.org/obo/OGMS_0000045)  \n",
    "  - <u>Solution</u>: Make the VO imported OGMS class a subclass of the DOID disease term  \n",
    "\n",
    "- Antigen: [VO](http://purl.obolibrary.org/obo/OBI_1110034)  \n",
    "  - <u>Solution</u>: Make the VO imported OBI class a subclass of the CHEBI antigen term  \n",
    "\n",
    "- Gelatin: [VO]('http://purl.obolibrary.org/obo/VO_0003030') \n",
    "  - <u>Solution</u>: Make the VO class a subclass of the CHEBI gelatin term \n",
    "\n",
    "- Hormone: [VO](http://purl.obolibrary.org/obo/FMA_12278) \n",
    "  - <u>Solution</u>: Make the VO imported FMA class a subclass of the CHEBI hormone term\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix gene class inconsistencies\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/OGG_0000000002'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/SO_0000704')))\n",
    "\n",
    "# fix protein class inconsistencies\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/PR_000000001'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/SO_0000104')))\n",
    "\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/CHEBI_36080'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/SO_0000104')))\n",
    "\n",
    "# fix disorder class inconsistencies\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/OGMS_0000045'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/DOID_4')))\n",
    "\n",
    "# fix antigen class inconsistencies\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/OBI_1110034'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/CHEBI_59132')))\n",
    "\n",
    "# fix gelatin class inconsistencies\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/VO_0003030'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/CHEBI_5291')))\n",
    "\n",
    "# fix hormone class inconsistencies\n",
    "graph.add((URIRef('http://purl.obolibrary.org/obo/FMA_12278'),\n",
    "           URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
    "           URIRef('http://purl.obolibrary.org/obo/CHEBI_24621')))\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aligning Ontology Classes and New Edge Data**  \n",
    "The first step to normalizing ontology classes with multiple identifiers is to query the ontology and obtain all classes that are not part of the [Open Biomedical Ontology](http://www.obofoundry.org/) namespace.\n",
    "\n",
    "For the current build, the primary focus of this task is to convert all classes that reference an HGNC gene (`n=19,820`) to an Entrez identifier. To do this, we will utilize the genomic identifier mapping information ([`Merged_gene_rna_protein_identifiers.pkl`](https://www.dropbox.com/s/6idnt7b3i322hlh/Merged_gene_rna_protein_identifiers.pkl?dl=1)) we constructed in the [`Data_Preparation.ipynb`](https://github.com/callahantiff/PheKnowLator/blob/master/Data_Preparation.ipynb) Jupyter notebook. Note that we aree only updating identifiers and not verifying labels or other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all classes in graph\n",
    "kg_classes = graph.query(\n",
    "    \"\"\"SELECT DISTINCT ?c\n",
    "           WHERE {?c rdf:type owl:Class . }\n",
    "           \"\"\", initNs={'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "                        'owl': 'http://www.w3.org/2002/07/owl#'}\n",
    ")\n",
    "\n",
    "# convert results to list of classes and only keep hgnc identifiers\n",
    "class_list_gene = [res[0] for res in tqdm(kg_classes) if isinstance(res[0], URIRef) and 'hgnc' in str(res[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load genomic identifier mapping dictionary\n",
    "genomic_id_map = pickle.load(open('resources/processed_data/Merged_gene_rna_protein_identifiers.pkl', 'rb'), encoding='bytes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each gene class and get entrez gene id equivalent\n",
    "matches, not_matched = {}, []\n",
    "gene_url = 'https://www.ncbi.nlm.nih.gov/gene/'\n",
    "\n",
    "for gene_class in tqdm(class_list_gene):\n",
    "    key = 'hgnc_id_' + str(gene_class).split('=')[-1]\n",
    "    \n",
    "    if key in genomic_id_map.keys() and any(x for x in genomic_id_map[key] if x.startswith('entrez_id')):        \n",
    "        matches[str(gene_class)] = [gene_url + x.split('_')[-1] for x in genomic_id_map[key] if 'entrez_id' in x]\n",
    "    else:\n",
    "        not_matched.append(gene_class)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print non-matching gene uris\n",
    "not_matched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Investigate UnMatched Genes_  \n",
    "Only 3 of the HGNC genes were not found in our dictionary ([`HGNC:24033`](http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=24033), [`HGNC:31447`](http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=31447), [`HGNC:33870`](http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=33870)). Investigating these revealed that HGNC made these identifiers obsolete and replaced them with new identifiers. Until this term is updated in the PRO ontology, we have to manually fix it. \n",
    "\n",
    "Additionally, there were 8 HGNC ids that have all been withdrawn (i.e. [`HGNC:26619`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/26619), [`HGNC:13392`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/13392), [`HGNC:31424`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/31424), [`HGNC:8103`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/8103), \n",
    "[`HGNC:25943`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/25943), [`HGNC:16957`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/16957), [`HGNC:23418`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/23418), [`HGNC:32021`](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/32021)) and for our purposes, will be removed. _Note_. Please verify the output file to ensure that no errors were added when removing these genes (as mentioned in a prior cell, these `8` genes were each deleted from the PRO ontology prior to merging).\n",
    "\n",
    "This issue has been reported to [PRotein Ontology](https://proconsortium.org/pro.shtml) (see [this](https://github.com/PROconsortium/PRoteinOntology/issues/176) GitHub issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate HGNC genes with no mappings to Entrez\n",
    "not_matched\n",
    "\n",
    "# update mapping dictionary\n",
    "gene_url = 'https://www.ncbi.nlm.nih.gov/gene/'\n",
    "matches['http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=24033'] =  [gene_url + x.split('_')[-1] for x in genomic_id_map['hgnc_id_26545'] if 'entrez_id' in x]\n",
    "matches['http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=31447'] =  [gene_url + x.split('_')[-1] for x in genomic_id_map['hgnc_id_16932'] if 'entrez_id' in x]\n",
    "matches['http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=33870'] =  [gene_url + x.split('_')[-1] for x in genomic_id_map['hgnc_id_20667'] if 'entrez_id' in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated gene identifiers in graph\n",
    "for edge in tqdm(graph):\n",
    "    if str(edge[0]) in matches.keys():\n",
    "        for mapped_id in matches[str(edge[0])]:\n",
    "            graph.add((URIRef(mapped_id), edge[1], edge[2]))\n",
    "            graph.remove(edge)\n",
    "    elif str(edge[2]) in matches.keys():\n",
    "        for mapped_id in matches[str(edge[2])]:\n",
    "            graph.add((edge[0], edge[1], URIRef(mapped_id)))\n",
    "            graph.remove(edge)\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check URIs for Overlapping Ontology and Non-Ontology Class Entities**  \n",
    "To make sure that any new edges that we add don't inadvertently result in duplicate nodes, we need to verify the URIs used in the merged ontologies with the URIs we plan to use when constructing a PheKnowLator knowledge graph.\n",
    "\n",
    "From looking into the knowledge graph we identified `20` classes that existed in the new edge list and in the merged ontologies, but that had differing URIs (`http://www.ncbi.nlm.nih.gov/` vs. `https://www.ncbi.nlm.nih.gov/`). Those classes were:  \n",
    "- `http://www.ncbi.nlm.nih.gov/gene/100129307`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/100131107`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/101927789`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/102723383`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/105373297`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/107987235`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/140606`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/157285`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/163404`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/390928`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/392490`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/50810`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/51714`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/54886`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/58515`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/64748`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/79948`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/83642`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/84717`\n",
    "- `http://www.ncbi.nlm.nih.gov/gene/9890`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read in Master Edge List**  \n",
    "The [`master edge list`](https://www.dropbox.com/s/t8sgzd847t1rof4/Master_Edge_List_Dict.json?dl=1) that is created in Step 2 of the `pkt_kg` algorithm is read in and processed into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in master edge list\n",
    "edge_data = json.load(open('./resources/Master_Edge_List_Dict.json', 'r'))\n",
    "\n",
    "# convert to dictionary\n",
    "edge_dict = dict()\n",
    "\n",
    "# iterate over master edges to \n",
    "for k in tqdm(edge_data):\n",
    "    rel = edge_data[k]['uri']\n",
    "    for edge in edge_data[k]['edge_list']:\n",
    "        for x in edge:\n",
    "            if x in edge_dict.keys():\n",
    "                edge_dict[x] |= {rel[edge.index(x)]}\n",
    "            else:\n",
    "                edge_dict[x] = {rel[edge.index(x)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Process merged Ontologies and Verify New Edge Relations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in tqdm(graph):\n",
    "    if str(edge[0]).startswith('http://www.ncbi.nlm.nih.gov/gene/'):\n",
    "        updated_subj = str(edge[0]).replace('http://www.ncbi.nlm.nih.gov/gene/', 'https://www.ncbi.nlm.nih.gov/gene/')\n",
    "        graph.add((URIRef(updated_subj), edge[1], edge[2]))\n",
    "        graph.remove(edge)\n",
    "        \n",
    "    if str(edge[2]).startswith('http://www.ncbi.nlm.nih.gov/gene/'):\n",
    "        updated_obj = str(edge[2]).replace('http://www.ncbi.nlm.nih.gov/gene/', 'https://www.ncbi.nlm.nih.gov/gene/')\n",
    "        graph.add((edge[0], edge[1], URIRef(updated_obj)))\n",
    "        graph.remove(edge)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save normalized ontology\n",
    "graph.serialize(destination=write_location + merged_ontology_file[:-4] + 'GeneID_Normalized_Cleaned.owl', format='xml')\n",
    "\n",
    "# apply OWL API formatting to file\n",
    "ontology_file_formatter(write_location, merged_ontology_file[:-4] + 'GeneID_Normalized_Cleaned.owl')\n",
    "\n",
    "# get ontology stats\n",
    "gets_ontology_statistics(write_location + merged_ontology_file[:-4] + 'GeneID_Normalized_Cleaned.owl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
