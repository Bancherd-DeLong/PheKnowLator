{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# PheKnowLator - Ontology Cleaning\n",
    "***\n",
    "***\n",
    "\n",
    "**Author:** [TJCallahan](https://mail.google.com/mail/u/0/?view=cm&fs=1&tf=1&to=callahantiff@gmail.com)  \n",
    "**GitHub Repository:** [PheKnowLator](https://github.com/callahantiff/PheKnowLator/wiki)  \n",
    "**Release:** **[v2.0.0](https://github.com/callahantiff/PheKnowLator/wiki/v2.0.0)**\n",
    "  \n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook serves as a script to help prepare ontologies prior to be ingested into the knowledge graph build algorithm. This script performs the following steps:  \n",
    "1. [Clean Ontologies](#clean-ontologies)  \n",
    "2. [Merge Ontologies](#merge-ontologies)  \n",
    "3. [Normalize Classes](#normalize-classes)\n",
    "\n",
    "## Assumptions and Dependencies  \n",
    "  \n",
    "**Assumptions:**   \n",
    "- Knowledge Graph Build Steps 1-2 (i.e. data downloading and master edge list creation) have already been performed  \n",
    "- Directory of Imported Ontologies ➞ `./resources/ontologies`    \n",
    "- Processed data write location ➞ `./resources/ontologies`  \n",
    "\n",
    "**Dependencies:**   \n",
    "- <u>Scripts</u>: This notebook utilizes several helper functions, which are stored in the [`kg_utils.py`](https://github.com/callahantiff/PheKnowLator/blob/master/pkt_kg/utils/kg_utils.py) script.\n",
    "- <u>Software</u>:[`OWLTools`](https://github.com/owlcollab/owltools)  \n",
    "- <u>Data</u>: Details on the data utilized in this script can be found on the [Data Sources](https://github.com/callahantiff/PheKnowLator/wiki/v2-Data-Sources) Wiki. Data can be downloaded from [this](https://console.cloud.google.com/storage/browser/pheknowlator/release_v2.0.0?project=pheknowlator) dedicated Google Cloud Storage Bucket. Please note that all build data are freely available and organized by release and build date. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***  \n",
    "## Set-Up Environment\n",
    "***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from owlready2 import *\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal\n",
    "from rdflib.namespace import OWL, RDF, RDFS \n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import script containing helper functions\n",
    "from pkt_kg.utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment variables\n",
    "write_location = 'resources/ontologies'\n",
    "merged_ontology_file = '/PheKnowLator_MergedOntologies.owl'\n",
    "ontology_repository = glob.glob('*/ontologies/*.owl')\n",
    "processed_data_location = 'resources/processed_data/'\n",
    "\n",
    "# set global namespaces\n",
    "schema = Namespace('http://www.w3.org/2001/XMLSchema#')\n",
    "obo = Namespace('http://purl.obolibrary.org/obo/')\n",
    "oboinowl = Namespace('http://www.geneontology.org/formats/oboInOwl#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Clean Ontologies <a class=\"anchor\" id=\"clean-ontologies\"></a>\n",
    "***\n",
    "\n",
    "**Purpose:** In this step, we read in the ontologies using the [`owlready2`](https://pypi.org/project/Owlready2/) library and use it to indicate the presence of errors in the ontology files. We use this tool because it has strict filters. Using this tool we performed the following checks to clean the ontologies:\n",
    "\n",
    "* [Value Errors](#value-error)  \n",
    "* [Punning Errors](#punning-error)  \n",
    "* [Double-Typed Classes](#double-typed)  \n",
    "* [Class Identifier Check](#identifier-check)  \n",
    "* [Obsolete/Deprecated Classes](#obsolete-classes)  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Value Errors <a class=\"anchor\" id=\"value-error\"></a>\n",
    "***\n",
    "\n",
    "This check utilizes the [`owlready2`](https://pypi.org/project/Owlready2/) library to read in each of the ontologies. This library is strict and will catch a wide variety of value errors. Should any of these errors arise, we retype the edge correctly. \n",
    "\n",
    "#### Example Findings  \n",
    "The [Cell Line Ontology](http://www.clo-ontology.org/) yield the following error message:\n",
    "\n",
    "```python\n",
    "ValueError: invalid literal for int() with base 10: '永生的乳腺衍生细胞系细胞'\n",
    "...\n",
    "OwlReadyOntologyParsingError: RDF/XML parsing error in file clo_with_imports.owl, line 10970, column 99.\n",
    "```\n",
    "\n",
    "This tells us that we need to repair the triple containing the Literal '永生的乳腺衍生细胞系细胞' by removing it and redefining it as a `string`, rather than an `int` as it is currently defined as. This is currently noted as an issue in the [Cell Line Ontology's](http://www.clo-ontology.org/) GitHub repo ([issue #48](https://github.com/CLO-ontology/CLO/issues/48)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {x: {} for x in ontology_repository}\n",
    "for ont in ontology_repository:\n",
    "    print('Loading: {}'.format(ont))\n",
    "    try: load_onto = get_ontology(ont).load()\n",
    "    except OwlReadyOntologyParsingError as e: errors[ont]['OwlReadyOntologyParsingError'] = str(e)\n",
    "    except KeyError as e: errors[ont]['KeyError'] = str(e)\n",
    "    except TypeError as e: errors[ont]['PunningError'] = str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value Error Repairs**  \n",
    "Code to fix the Cell Ontology *Value Error* is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in errors.keys():\n",
    "    if 'OwlReadyOntologyParsingError' in errors[key].keys():\n",
    "        error_key = 'OwlReadyOntologyParsingError'\n",
    "        line_num = int(re.findall(r'(?<=line\\s).*(?=,)', str(errors[key][error_key]))[0]) - 1\n",
    "        raw_data, graph = open(key).readlines(), Graph().parse(key)\n",
    "       \n",
    "        # obtain bad string and triple -- assuming for now the errors are miss-typed string errors\n",
    "        bad_content = re.findall(r'(?<=\\>).*(?=\\<)', raw_data[line_num])[0]      \n",
    "        bad_triple = [x for x in graph if bad_content in str(x[0]) or bad_content in str(x[2])]\n",
    "        for e in bad_triple:\n",
    "            graph.add((e[0], e[1], Literal(str(e[2]), datatype=schema.string)))\n",
    "            graph.remove(e)\n",
    "        \n",
    "        # save cleaned up ontology\n",
    "        filename = '/' + key.split('/')[-1]\n",
    "        graph.serialize(destination=key, format='xml')\n",
    "        ontology_file_formatter(write_location, filename, './pkt_kg/libs/owltools')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "## MERGE ONTOLOGIES <a class=\"anchor\" id=\"merge-ontologies\"></a>\n",
    "***\n",
    "\n",
    "**Purpose:** In this step, the [`OWLTools`](https://github.com/owlcollab/owltools) library is designed to merge a directory of ontology files into a single ontology file. This merged ontology file is required as input to the knowledge graph build algorithm.  \n",
    "\n",
    "**Inputs:** A directory of ontology files (`.owl`)\n",
    "\n",
    "**Outputs:** [`PheKnowLator_MergedOntologies.owl`](https://www.dropbox.com/s/1lhh4hdwbjzds74/PheKnowLator_MergedOntologiesGeneID_Normalized_Cleaned.owl?dl=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge ontologies\n",
    "if write_location + merged_ontology_file in glob.glob(write_location + '/*.owl'):\n",
    "    graph = Graph().parse(write_location + merged_ontology_file)\n",
    "    gets_ontology_statistics(write_location + merged_ontology_file)\n",
    "else:\n",
    "    merges_ontologies(ontology_repository, write_location, merged_ontology_file)\n",
    "    gets_ontology_statistics(write_location + merged_ontology_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Merged Ontology Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in merged data\n",
    "merged_onts = Graph().parse(write_location + merged_ontology_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Punning Errors <a class=\"anchor\" id=\"punning-error\"></a>\n",
    "***\n",
    "\n",
    "[Punning](https://www.w3.org/2007/OWL/wiki/Punning) or redeclaration errors occur for a few different reasons, but the primary or most prevalent cause observed in the ontologies used in `PheKnowLator` is due to an `owl:ObjectProperty` being incorrectly redeclared as an `owl:AnnotationProperty` or an `owl:Class` also being defined as an `OWL:ObjectProperty`. Consistent with the solution described [here](https://github.com/oborel/obo-relations/issues/130), for `owl:ObjectProperty` redeclarations we remove all `owl:AnnotationProperty` declarations. For all `owl:Class` redeclarations, we remove all `owl:ObjectProperty` redeclarations.\n",
    "\n",
    "#### Example Findings  \n",
    "The [Cell Line Ontology](http://www.clo-ontology.org/) had 7 object properties that were illegally redeclared and triggered punning errors. More details regarding these errors are shown below. \n",
    "\n",
    "```bash\n",
    "2020-12-03 20:57:15,616 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0002091 in punning not allowed [Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0002091>)), Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0002091>))]\n",
    "2020-12-03 20:57:15,619 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/BFO_0000062 in punning not allowed [Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/BFO_0000062>)), Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/BFO_0000062>))]\n",
    "2020-12-03 20:57:15,620 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/BFO_0000063 in punning not allowed [Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/BFO_0000063>)), Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/BFO_0000063>))]\n",
    "2020-12-03 20:57:15,620 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0002222 in punning not allowed [Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0002222>)), Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0002222>))]\n",
    "2020-12-03 20:57:15,620 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0000087 in punning not allowed [Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0000087>)), Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0000087>))]\n",
    "2020-12-03 20:57:15,620 ERROR (OWLOntologyManagerImpl:1138) Illegal redeclarations of entities: reuse of entity http://purl.obolibrary.org/obo/RO_0002161 in punning not allowed [Declaration(ObjectProperty(<http://purl.obolibrary.org/obo/RO_0002161>)), Declaration(AnnotationProperty(<http://purl.obolibrary.org/obo/RO_0002161>))]\n",
    "```\n",
    "\n",
    "From this message, we can see that we need to remove the following `owl:ObjectProperty` redeclared to `owl:AnnotationProperty`: `RO_0002091`, `BFO_0000062`, `BFO_0000063`, `RO_0002222`, `RO_0000087`, `RO_0002161`. There were also 2 classes (i.e. `CLO_0054407` and `CLO_0054409`) defined as being a `owl:Class` and an `owl:ObjectProperty`. This is currently noted as an issue in the Cell Line Ontology's GitHub repo [issue #43](https://github.com/CLO-ontology/CLO/issues/43))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_classes = set()\n",
    "# identifiy and remove punning errors\n",
    "for s, p, o in tqdm(merged_onts):\n",
    "    triples = list(merged_onts.triples((s, None, None)))\n",
    "    # check for objects defined as classes and object properties\n",
    "    class_prop, obj_prop = (s, RDF.type, OWL.Class), (s, RDF.type, OWL.ObjectProperty)\n",
    "    if (class_prop in triples and obj_prop in triples) and str(s) not in bad_classes:\n",
    "        bad_classes.add(str(s))\n",
    "        print('Punning Error: {} defined as an owl:Class and owl:ObjectProperty'.format(str(s)))\n",
    "        merged_onts.remove(class_prop)\n",
    "    # check for objects defined as object properties and annotation properties\n",
    "    if o == OWL.ObjectProperty:\n",
    "        obj_prop, annot_prop = (s, RDF.type, OWL.ObjectProperty), (s, RDF.type, OWL.AnnotationProperty)\n",
    "        if obj_prop in triples and annot_prop in triples:\n",
    "            print('Punning Error: {} defined as an owl:ObjectProperty and owl:AnnotationProperty'.format(str(s)))\n",
    "            merged_onts.remove(annot_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Double-Typed Classes <a class=\"anchor\" id=\"double-typed\"></a>\n",
    "***\n",
    "\n",
    "\n",
    "Similar to resolving punning errors, we also need to identify classes that have been typed as `owl:Class` and `owl:NamedIndividuals` and remove the `owl:NamedIndividual` axiom.\n",
    "\n",
    "#### Example Findings  \n",
    "The `UBERON` Ontology contains the following re-typing errors:\n",
    "- UBERON_0001009-Class/UBERON_0001009-NamedIndividual\n",
    "- UBERON_0001004-Class/UBERON_0001004-NamedIndividual\n",
    "- UBERON_0001555-Class/UBERON_0001555-NamedIndividual\n",
    "- UBERON_0000383-NamedIndividual/UBERON_0000383-Class\n",
    "- UBERON_0000029-NamedIndividual/UBERON_0000029-Class\n",
    "- UBERON_0001017-Class/UBERON_0001017-NamedIndividual\n",
    "- UBERON_0000062-Class/UBERON_0000062-NamedIndividual\n",
    "- UBERON_0000926-Class/UBERON_0000926-NamedIndividual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cls = []\n",
    "kg_classes = gets_ontology_classes(merged_onts)\n",
    "for cls in tqdm(kg_classes):\n",
    "    class_types = list(merged_onts.triples((cls, RDF.type, None)))\n",
    "    if len(class_types) > 1:\n",
    "        bad_cls += [', '.join([str(x[0]).split('/')[-1] + '-' + str(x[2]).split('#')[-1] for x in class_types])]\n",
    "        to_remove = list(merged_onts.triples((cls, RDF.type, OWL.NamedIndividual)))\n",
    "        for edge in to_remove:\n",
    "            merged_onts.remove(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Class Identifier Check  <a class=\"anchor\" id=\"identifier-check\"></a>\n",
    "***\n",
    "\n",
    "Check class identifiers to ensure consistency in identifier prefixes. For example, we want to identifiers that are incorrectly formatted like occurrences of `PRO_XXXXXXX` which should be `PR_XXXXXXX`. For all detected errors, we reformat the incorrectly formatted class identifiers. This is a tricky task to do in an automated manner and is something that should be updated if any new ontologies are added to the `PheKnowLator` build. Currently, the code below checks and logs any hits, but only fixes the following known errors: Vaccine Ontology: `PRO` which should be `PR`.\n",
    "\n",
    "#### Example Findings  \n",
    "Running this check revealed mislabeling of `2` [pROtein Ontology](https://proconsortium.org/) identifiers in the [Vaccine Ontology](http://www.violinet.org/vaccineontology/) (see [this](https://github.com/vaccineontology/VO/issues/4) GitHub issue).\n",
    "\n",
    "\n",
    "**Solution:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to list of classes and only keep hgnc identifiers\n",
    "kg_classes = set([x for x in merged_onts.subjects(RDF.type, OWL.Class)])\n",
    "class_list = [res for res in kg_classes if isinstance(res, URIRef) and 'obo/' in str(res)]\n",
    "\n",
    "# print unique identifier types for all classes in each ontology\n",
    "print('Unique Identifier Types: {}'.format(', '.join(sorted(set([x.split('/')[-1].split('_')[0] for x in class_list])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace badly formatted identifiers with the correct ones\n",
    "bad_classes = set()\n",
    "for edge in tqdm(merged_onts):\n",
    "    if 'http://purl.obolibrary.org/obo/PRO_' in str(edge[0]):\n",
    "        updated_subj = str(edge[0]).replace('http://purl.obolibrary.org/obo/PRO_', 'http://purl.obolibrary.org/obo/PR')\n",
    "        merged_onts.add((URIRef(updated_subj), edge[1], edge[2]))\n",
    "        merged_onts.remove(edge)\n",
    "        bad_classes.add(str(edge[0]))\n",
    "    if 'http://purl.obolibrary.org/obo/PRO_' in str(edge[2]):\n",
    "        updated_obj = str(edge[0]).replace('http://purl.obolibrary.org/obo/PRO_', 'http://purl.obolibrary.org/obo/PR')\n",
    "        merged_onts.add((edge[0], edge[1], URIRef(updated_obj)))\n",
    "        merged_onts.remove(edge)\n",
    "        bad_classes.add(str(edge[2]))\n",
    "\n",
    "print('The following classes were updated:\\n{}'.format('\\n'.join(bad_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Remove Obsolete and/or Deprecated Classes    <a class=\"anchor\" id=\"obsolete-classes\"></a>\n",
    "***\n",
    "\n",
    "To make sure that the ontology only contains current information, all obsolete classes and any triples that they participate in are removed from the ontologies. In addition to running the code below, it may also be necessary to check for classes that are a sub-class of `oboInOwl:ObsoleteClass`, as well as any obsolete or deprecated annotations, individuals, or `owl:ObjectProperty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get deprecated classes and triples\n",
    "dep_cls = [x[0] for x in list(merged_onts.triples((None, OWL.deprecated, Literal('true', datatype=schema.boolean))))]\n",
    "dep_triples = [(i, j, k) for i, j, k in merged_onts\n",
    "               if 'deprecated' in ', '.join([str(i).lower(), str(j).lower(), str(k).lower()])\n",
    "               and len(list(merged_onts.triples((i, RDF.type, OWL.Class)))) == 1]\n",
    "deprecated_classes = set(dep_cls + [x[0] for x in dep_triples])\n",
    "\n",
    "# get obsolete classes and triples\n",
    "obs_cls = [x[0] for x in list(merged_onts.triples((None, RDFS.subClassOf, oboinowl.ObsoleteClass)))]\n",
    "obs_triples = [(i, j, k) for i, j, k in merged_onts\n",
    "               if 'obsolete' in ', '.join([str(i).lower(), str(j).lower(), str(k).lower()])\n",
    "               and len(list(merged_onts.triples((i, RDF.type, OWL.Class)))) == 1 and '#' not in str(i)]\n",
    "obsolete_classes = set(obs_cls + [x[0] for x in obs_triples])\n",
    "\n",
    "# remove deprecated/obsolete classes\n",
    "for node in list(deprecated_classes) + list(obsolete_classes):\n",
    "    merged_onts.remove((node, None, None))\n",
    "\n",
    "print('Removed {} obsolete classes and {} deprecated classes\\n'.format(len(obsolete_classes), len(deprecated_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***\n",
    "## Normalize Classes <a class=\"anchor\" id=\"normalize-classes\"></a>\n",
    "***\n",
    "\n",
    "**Purpose:** The goal of this section is to checked the cleaned merged ontology file to ensure that there is consistency between the existing classes. To do this, we check two things: (1) [Aligning Existing Ontology Classes](#aligning-existing-ontologies); and (2) [Aligning Ontology Classes and New Edge Data](#aligning-new-data). More details for each type of check are provided below.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning Existing Ontology Classes <a class=\"anchor\" id=\"aligning-existing-ontologies\"></a>\n",
    "***\n",
    "\n",
    "**Purpose:** For this check, there are two types of checks that are performed:  \n",
    "\n",
    "*Normalize Duplicate Ontology Concepts*  \n",
    "we want to make sure that all classes that represent the same entity are connected to each other. For example, consider the following: the [Sequence Ontology](http://www.sequenceontology.org/), [ChEBI](https://www.ebi.ac.uk/chebi), and [PRotein Ontology](https://proconsortium.org/) all include terms for protein, but none of these classes are connected to each other. The solution to fixing these errors is to choose a primary concept for all duplicate scenarios and make duplicate concepts an `RDFS:subClassOf` the primary concept.\n",
    "\n",
    "*Normalize Existing Ontology Classes*  \n",
    "Checks for inconsistencies in ontology classes that overlap with non-ontology entity identifiers (e.g. if HP includes `HGNC` identifiers, but PheKnowLator utilizes `Entrez` identifiers). While there are other types of identifiers, we focus primarily on resolving the genomic types, since we have a master dictionary we can used to help with this ([`Merged_gene_rna_protein_identifiers.pkl`](https://storage.googleapis.com/pheknowlator/release_v2.0.0/build_31DEC2020/data/processed_data/Merged_gene_rna_protein_identifiers.pkl)). This can be updated in future iterations to include other types of identifiers, but given our detailed examination of the `v2.0.0` ontologies, these were the identifier types that needed repair.\n",
    "\n",
    "**Dependencies:** [`Merged_gene_rna_protein_identifiers.pkl`](https://storage.googleapis.com/pheknowlator/release_v2.0.0/build_31DEC2020/data/processed_data/Merged_gene_rna_protein_identifiers.pkl)  \n",
    "\n",
    "#### Sample Findings  \n",
    "*Normalize Duplicate Ontology Concepts*  \n",
    "The follow classes occur in all of the ontologies used in the current build and have to be normalizesd so that there are not multiple versions of the same concept:  \n",
    "\n",
    "- Gene: [VO](http://purl.obolibrary.org/obo/OGG_0000000002)  \n",
    "  - <u>Solution</u>: Make the `VO` imported `OGG` class a subclass of the `SO` gene term  \n",
    "\n",
    "- Protein: [SO](http://purl.obolibrary.org/obo/SO_0000104), [PRO](http://purl.obolibrary.org/obo/PR_000000001), [ChEBI](http://purl.obolibrary.org/obo/CHEBI_36080) \n",
    "  - <u>Solution</u>: Make the `CHEBI` and `PRO` classes a subclass of the `SO` protein term  \n",
    "  \n",
    "- Disorder: [VO](http://purl.obolibrary.org/obo/OGMS_0000045)  \n",
    "  - <u>Solution</u>: Make the `VO` imported `OGMS` class a subclass of the `MONDO` disease term  \n",
    "\n",
    "- Antigen: [VO](http://purl.obolibrary.org/obo/OBI_1110034)  \n",
    "  - <u>Solution</u>: Make the `VO` imported OBI class a subclass of the `CHEBI` antigen term  \n",
    "\n",
    "- Gelatin: [VO]('http://purl.obolibrary.org/obo/VO_0003030') \n",
    "  - <u>Solution</u>: Make the `VO` class a subclass of the `CHEBI` gelatin term \n",
    "\n",
    "- Hormone: [VO](http://purl.obolibrary.org/obo/FMA_12278) \n",
    "  - <u>Solution</u>: Make the `VO` imported `FMA` class a subclass of the `CHEBI` hormone term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***  \n",
    "**Normalize Duplicate Ontology Concepts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_onts.add((obo.OGG_0000000002, RDFS.subClassOf, obo.SO_0000704))  # fix gene class inconsistencies\n",
    "merged_onts.add((obo.PR_000000001, RDFS.subClassOf, obo.SO_0000104))  # fix protein class inconsistencies\n",
    "merged_onts.add((obo.CHEBI_36080, RDFS.subClassOf, obo.SO_0000104))  # fix protein class inconsistencies\n",
    "merged_onts.add((obo.OGMS_0000045, RDFS.subClassOf, obo.MONDO_0000001))  # fix disorder class inconsistencies\n",
    "merged_onts.add((obo.OBI_1110034, RDFS.subClassOf, obo.CHEBI_59132))  # fix antigen class inconsistencies\n",
    "merged_onts.add((obo.VO_0003030, RDFS.subClassOf, obo.CHEBI_5291))  # fix gelatin class inconsistencies\n",
    "merged_onts.add((obo.FMA_12278, RDFS.subClassOf, obo.CHEBI_24621))  # fix hormone class inconsistencies                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Normalize Existing Ontology Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download required dependencies\n",
    "url = 'https://storage.googleapis.com/pheknowlator/release_v2.0.0/build_31DEC2020/data/processed_data/Merged_gene_rna_protein_identifiers.pkl'\n",
    "if not os.path.exists(processed_data_location + 'Merged_gene_rna_protein_identifiers.pkl'):\n",
    "    data_downloader(url, processed_data_location)\n",
    "\n",
    "gene_ids = pickle.load(open(processed_data_location + 'Merged_gene_rna_protein_identifiers.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all classes in the merged knowledge graph that are not obo classes and remove them\n",
    "non_ont = set([x for x in gets_ontology_classes(merged_onts) if not str(x).startswith(str(obo))])\n",
    "hgnc, url = set([x for x in non_ont if 'hgnc' in str(x)]), 'http://www.ncbi.nlm.nih.gov/gene/'\n",
    "\n",
    "for node in tqdm(hgnc):\n",
    "    trips = list(merged_onts.triples((node, None, None))) + list(merged_onts.triples((None, None, node)))\n",
    "    node_str = 'hgnc_id_' + str(node).split('=')[-1]\n",
    "    if node_str in gene_ids.keys():\n",
    "        ent_maps = [URIRef(url + x) for x in gene_ids[node_str] if x.startswith('entrez_id_')]\n",
    "        for edge in trips:\n",
    "            if node in edge[0]:\n",
    "                for i in ent_maps:\n",
    "                    merged_onts.add((i, edge[1], edge[2]))\n",
    "            if node in edge[2]:\n",
    "                for i in ent_maps:\n",
    "                    merged_onts.add((edge[0], edge[1], i))\n",
    "            merged_onts.remove(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "**Save Cleaned Merged Ontologies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_onts.serialize(write_location + merged_ontology_file, format='xml')\n",
    "ontology_file_formatter(write_location, merged_ontology_file, './pkt_kg/libs/owltools')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "```\n",
    "@misc{callahan_tj_2019_3401437,\n",
    "  author       = {Callahan, TJ},\n",
    "  title        = {PheKnowLator},\n",
    "  month        = mar,\n",
    "  year         = 2019,\n",
    "  doi          = {10.5281/zenodo.3401437},\n",
    "  url          = {https://doi.org/10.5281/zenodo.3401437}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
